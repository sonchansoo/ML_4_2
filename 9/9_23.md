## 🔍 강의 요약
이 강의는 머신러닝의 기초가 되는 **추론 통계(Inferential Statistics)**와 **카이제곱 검정(Chi-Square Test)**에 대해 다룹니다. 샘플 데이터를 통해 전체 모집단의 특성을 추론하는 방법과, 특히 두 범주형 변수 간의 관련성을 통계적으로 검증하는 카이제곱 검정의 원리, 계산 방법, 그리고 Python을 이용한 실제 구현까지 학습합니다.

## 💡 핵심 포인트
- **추론 통계 (Inferential Statistics)**: 샘플(Sample)을 분석하여 모집단(Population)의 특성을 추론하는 통계적 방법입니다.
- **카이제곱 검정 (Chi-Square Test)**: 두 개의 **범주형(Categorical)** 변수 간에 통계적으로 유의미한 연관성이 있는지를 검증하는 데 사용됩니다.
- **가설 검정의 5단계**: `가설 설정` → `유의 수준 설정` → `검정 통계량 계산` → `임계값 확인` → `결론 도출`의 과정을 따릅니다.
- **귀무가설(H0)과 대립가설(H1)**: 귀무가설은 '두 변수 간에 연관이 없다'는 가설이며, 카이제곱 검정은 이 귀무가설을 기각할 수 있는지 확인하는 과정입니다.
- **p-value**: 계산된 결과가 우연히 발생했을 확률을 의미하며, 보통 유의 수준(alpha) 0.05보다 작으면 귀무가설을 기각하고 '두 변수는 연관이 있다'고 결론 내립니다.

## 세부 내용 📚
### 1️⃣ 추론 통계 (Inferential Statistics)의 기본 개념
- **추론 통계란?** 📊
  - 전체 데이터를 모두 조사하기 어려울 때, 일부 데이터(샘플)를 추출하여 분석하고 그 결과를 바탕으로 전체(모집단)의 특성을 예측하고 일반화하는 방법입니다.
- **추론 통계의 핵심 요소** 🔑
  - **Hypothesis (가설)**: 통계적으로 검증하고자 하는 주장. `귀무가설(H0)`과 `대립가설(H1)`로 나뉩니다.
  - **Level of Significance (유의 수준, α)**: 가설을 기각하는 기준이 되는 확률값으로, 보통 0.05 (5%)를 사용합니다.
  - **Degree of Freedom (자유도, df)**: 통계량 계산 시 자유롭게 변할 수 있는 값의 수입니다. 카이제곱 검정에서는 `(행의 수 - 1) * (열의 수 - 1)`로 계산됩니다.
  - **Calculated Value (계산된 값/검정 통계량)**: 실제 데이터를 바탕으로 계산된 통계 값입니다.
  - **Critical Value (임계값)**: 귀무가설의 기각 여부를 결정하는 경계 값입니다.

### 2️⃣ 카이제곱 검정 (Chi-Square Test)의 이해
- **카이제곱 검정이란?** 📝
  - 관찰된 빈도(Observed Frequency)와 기대 빈도(Expected Frequency)의 차이를 비교하여 두 범주형 변수 간의 연관성을 분석하는 통계적 검정 방법입니다.
  - Karl Pearson에 의해 1900년대 초에 개발되었습니다.
- **언제 사용하나요?** 🤔
  - 성별에 따른 선호하는 동물(개/고양이)의 차이가 있는지, 혹은 휴가 유형(해변/크루즈) 선호도에 차이가 있는지 등 두 범주형 데이터 간의 관계를 알고 싶을 때 유용합니다.
- **카이제곱 검정의 한계** ⚠️
  - 관계의 **강도(Strength)**나 방향에 대한 정보는 제공하지 않습니다.
  - 샘플 크기에 민감하여, 샘플이 매우 크면 사소한 차이도 통계적으로 유의하게 나올 수 있습니다.

### 3️⃣ 카이제곱 검정 계산 단계 (예제: 성별과 동물 선호도)
1.  **가설 설정**
    - **귀무가설 (H0)**: 성별과 선호하는 동물 사이에는 연관이 없다 (독립적이다).
    - **대립가설 (H1)**: 성별과 선호하는 동물 사이에는 연관이 있다 (종속적이다).
2.  **기댓값(Expected Value) 계산**
    - 각 셀에 대해 `(해당 행의 합계 * 해당 열의 합계) / 전체 합계` 공식을 사용하여 기댓값을 계산합니다.
3.  **카이제곱 통계량(χ²) 계산**
    - 각 셀마다 `(관측값 - 기댓값)² / 기댓값`을 계산한 후, 모든 셀의 값을 더합니다.
4.  **자유도(df) 및 임계값(Critical Value) 확인**
    - 예제(2x2 테이블)의 자유도는 `(2-1) * (2-1) = 1`입니다.
    - 유의 수준 0.05와 자유도 1을 기준으로 카이제곱 분포표에서 임계값을 찾습니다 (예: 3.841).
5.  **결론 도출**
    - **방법 1 (임계값 비교)**: `계산된 통계량(4.102) > 임계값(3.841)`이므로 귀무가설을 기각합니다.
    - **방법 2 (p-value 비교)**: 계산된 p-value(0.043)가 `유의 수준(0.05)`보다 작으므로 귀무가설을 기각합니다.
    - **결론**: 성별과 동물 선호도 사이에는 통계적으로 유의미한 연관이 있습니다.

### 4️⃣ Python을 이용한 카이제곱 검정
- **SciPy 라이브러리 활용** 💻
  - `scipy.stats`의 `chi2_contingency` 함수를 사용하면 카이제곱 통계량, p-value, 자유도, 기댓값을 한 번에 계산할 수 있습니다.
- **코드 예시**
  ```python
  from scipy.stats import chi2_contingency

  # 관측 데이터 (예: 남/여, 고양이/개 선호도)
  table = [[207, 282], [231, 242]]

  # 카이제곱 검정 수행
  stat, p, dof, expected = chi2_contingency(table)

  print(f"카이제곱 통계량: {stat}")
  print(f"p-value: {p}")
  print(f"자유도: {dof}")

  # 결과 해석
  alpha = 0.05
  if p <= alpha:
      print("귀무가설 기각: 두 변수는 연관이 있습니다.")
  else:
      print("귀무가설 채택: 두 변수는 독립적입니다.")
  ```

## 오늘의 연습문제 📝
- **문제 1**: 카이제곱 검정에서 귀무가설(H0)이 '두 변수는 서로 연관이 있다'라고 설정하는 것이 맞을까요? 아니라면 그 이유는 무엇일까요?
- **문제 2**: 강의 자료 21페이지의 '성별에 따른 휴가 선호도' 예제 데이터를 사용하여, 손으로 직접 카이제곱 통계량을 계산해보고, 유의 수준 0.05에서 귀무가설을 기각할 수 있는지 판단해보세요. (자유도=1, 임계값=3.841)
  - 데이터: `[[209, 280], [225, 248]]`
- **문제 3**: 카이제곱 검정은 두 변수 간의 관계 유무는 알려주지만, 그 관계가 얼마나 강한지에 대한 정보는 제공하지 않습니다. 이처럼 카이제곱 검정이 가지는 한계점 두 가지를 더 설명해보세요.
