## 🔍 강의 요약
이번 강의에서는 OpenCV의 기본 이미지 처리를 넘어, 실제 컴퓨터 비전 애플리케이션을 제작하는 데 필수적인 고급 기능들을 다룹니다. 비디오 파일을 읽고 쓰는 방법, 웹캠을 이용한 실시간 영상 처리, 그리고 키보드, 마우스, 트랙바(슬라이더)를 활용하여 사용자와 상호작용하는 GUI(Graphical User Interface)를 만드는 방법을 학습합니다. 또한, 처리 결과를 시각적으로 표현하기 위한 오버레이 및 주석 기능과 함께, 더 복잡한 프로젝트를 위해 MediaPipe와 같은 외부 라이브러리를 연동하는 방법도 소개합니다.

## 💡 핵심 포인트
- **비디오 처리**: `cv2.VideoCapture`와 `cv2.VideoWriter`를 사용하여 비디오 파일을 읽고 저장하며, 웹캠을 실시간으로 제어할 수 있습니다.
- **상호작용의 핵심**: `cv2.waitKey()` 함수는 단순히 프로그램을 잠시 멈추는 것이 아니라, GUI 창을 새로고침하고 키보드 입력을 받아 프로그램을 제어하는 데 필수적입니다.
- **동적 GUI**: `cv2.createTrackbar`(슬라이더)와 `cv2.setMouseCallback`(마우스 이벤트)을 이용해 사용자가 실시간으로 프로그램의 파라미터를 변경하거나 특정 영역을 선택하는 등 동적인 제어가 가능합니다.
- **Callback vs. Polling**: 정적인 이미지 처리에는 이벤트 발생 시 호출되는 **Callback** 방식이 유용하지만, 계속해서 프레임이 변하는 비디오 처리에는 루프 내에서 직접 값을 확인하는 **Polling** (`getTrackbarPos`) 방식이 적합합니다.
- **결과 시각화**: `cv2.rectangle`, `cv2.putText` 등의 함수를 사용해 감지된 객체나 주요 정보를 비디오 화면에 직접 그려(Overlay & Annotation) 결과를 명확하게 전달할 수 있습니다.
- **기능 확장**: MediaPipe와 같은 강력한 외부 라이브러리를 활용하면 복잡한 기능(손, 자세, 얼굴 인식 등)을 쉽게 구현하여 OpenCV 프로젝트의 수준을 높일 수 있습니다.

## 세부 내용 📚
### 1️⃣ 비디오 입출력 (Video I/O) 📹
- **비디오란?**: 비디오는 여러 장의 정적 이미지(프레임, Frame)가 연속적으로 빠르게 재생되어 움직이는 것처럼 보이는 것입니다.
- **비디오 읽기**: `cv2.VideoCapture("파일경로")` 또는 `cv2.VideoCapture(0)` (기본 웹캠)을 사용하여 비디오 스트림을 엽니다. `cap.read()` 메서드로 각 프레임을 순차적으로 읽어옵니다.
- **비디오 쓰기**: `cv2.VideoWriter` 객체를 생성하여 비디오를 저장합니다. 이때 코덱(e.g., 'XVID'), 초당 프레임 수(fps), 프레임 크기를 지정해야 합니다. `out.write(frame)` 메서드로 각 프레임을 파일에 씁니다.

### 2️⃣ 키보드 및 GUI 제어 🖱️
- **`cv2.waitKey(delay)`**: 지정된 `delay`(밀리초) 동안 키 입력을 기다립니다.
    - `delay=0`이면 키 입력이 있을 때까지 무한정 기다립니다.
    - 반환값은 입력된 키의 ASCII 코드이며, 이를 이용해 `if key == ord('q'):` 와 같이 프로그램 흐름을 제어할 수 있습니다.
    - 이 함수가 호출되어야 `cv2.imshow`로 열린 창이 새로고침됩니다.
- **트랙바 (Trackbar/Slider)**: `cv2.createTrackbar(이름, 창이름, 초기값, 최대값, 콜백함수)`를 통해 생성합니다. 사용자가 슬라이더를 움직이면 지정된 콜백 함수가 자동으로 호출되어 특정 작업을 수행합니다.
- **Callback 함수**: 특정 이벤트(슬라이더 이동, 마우스 클릭 등)가 발생했을 때 시스템에 의해 자동으로 호출되는 함수입니다.
- **Callback vs. Polling**:
    - **Callback**: 이미지에 트랙바를 적용할 때 유용합니다. 슬라이더 값이 바뀔 때만 이미지를 다시 처리하면 됩니다.
    - **Polling**: 비디오에 트랙바를 적용할 때 사용합니다. 비디오는 매 순간 프레임이 바뀌므로, `while` 루프 안에서 `cv2.getTrackbarPos()`를 통해 현재 슬라이더 값을 직접 가져와(polling) 현재 프레임에 적용해야 합니다.

### 3️⃣ 마우스 제어 (Mouse Control) 🐭
- **마우스 이벤트 처리**: `cv2.setMouseCallback(창이름, 콜백함수)`를 사용하여 마우스 이벤트를 처리할 콜백 함수를 등록합니다.
- **마우스 이벤트 종류**:
    - `EVENT_LBUTTONDOWN`: 왼쪽 버튼 누름
    - `EVENT_MOUSEMOVE`: 마우스 이동
    - `EVENT_LBUTTONUP`: 왼쪽 버튼 뗌
- **활용**: 콜백 함수는 이벤트 종류, 마우스 좌표(x, y) 등의 정보를 받아옵니다. 이를 활용해 마우스 드래그로 관심 영역(ROI, Region of Interest)을 선택하거나, 특정 위치에 도형을 그리는 등의 상호작용을 구현할 수 있습니다.

### 4️⃣ 오버레이 및 주석 (Overlay & Annotation) 🎨
- **결과 시각화**: 컴퓨터 비전의 분석 결과를 이미지나 비디오 위에 직접 그려서 보여주는 기능입니다.
- **주요 함수**:
    - `cv2.line()`: 선 그리기
    - `cv2.rectangle()`: 사각형 그리기
    - `cv2.circle()`: 원 그리기
    - `cv2.putText()`: 텍스트 쓰기
- **투명 오버레이**: `cv2.addWeighted()` 함수를 사용하면 두 이미지(원본과 그래픽 오버레이)를 특정 가중치로 합성하여 반투명한 효과를 만들 수 있습니다.

### 5️⃣ OpenCV 확장: MediaPipe 소개 🚀
- **MediaPipe**: Google에서 개발한 경량 프레임워크로, 실시간으로 자세, 손, 얼굴 랜드마크 등을 감지하는 강력한 모델들을 제공합니다.
- **주요 기능**:
    - **Body Pose (33개 랜드마크)**: 피트니스 코치, 행동 인식
    - **Hand Pose (21개 랜드마크)**: 제스처 컨트롤, 가상 드로잉
    - **Face Mesh (468개 랜드마크)**: AR 필터, 얼굴 트래킹
- **연동**: OpenCV로 웹캠 영상을 받아와 MediaPipe 모델로 처리한 후, 그 결과(랜드마크)를 다시 OpenCV의 그리기 함수를 이용해 화면에 표시하는 방식으로 쉽게 통합할 수 있습니다.

## 오늘의 연습문제 📝
- **문제 1**: 웹캠을 열고, 's' 키를 누르면 현재 화면을 'capture.png'라는 이름으로 저장하고, 'q' 키를 누르면 프로그램이 종료되도록 만들어 보세요.
- **문제 2**: 이미지를 하나 불러온 후, 'Grayscale'이라는 이름의 트랙바를 추가하세요. 트랙바의 값(0 또는 1)에 따라 이미지가 컬러와 흑백으로 실시간 전환되도록 구현해 보세요. (힌트: 트랙바 값이 1일 때 `cv2.cvtColor` 사용)
- **문제 3**: 웹캠 영상을 실시간으로 화면에 보여주면서, 사용자가 마우스 왼쪽 버튼을 클릭하고 드래그하는 동안 녹색 사각형이 그려지도록 만들어 보세요. 마우스 버튼에서 손을 떼면 사각형 그리기가 멈춰야 합니다.
