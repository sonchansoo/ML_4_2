## 🔍 강의 요약

이번 강의에서는 추천 시스템의 핵심 알고리즘인 협업 필터링(Collaborative Filtering)에 대해 심도 있게 다룹니다. 특히, 메모리 기반 방법론 중 하나인 **아이템 기반 협업 필터링(Item-Based Collaborative Filtering)**의 개념과 계산 과정을 구체적인 예시를 통해 학습합니다. 이후, 메모리 기반 방법의 한계를 극복하기 위한 **모델 기반(Model-Based)** 접근법으로 넘어가, 차원 축소 기법인 **SVD(Singular Value Decomposition)**와 이를 응용한 **Matrix Factorization**의 원리를 배웁니다. 마지막으로 협업 필터링의 대안인 **콘텐츠 기반 필터링(Content-Based Filtering)**의 개념을 간략히 소개하며 마무리합니다.

## 💡 핵심 포인트

-   **Item-Based Collaborative Filtering**: 아이템 간의 유사도(e.g., Cosine Similarity)를 계산하고, 이를 가중치로 사용하여 사용자가 아직 평가하지 않은 아이템의 평점을 예측합니다.
-   **Model-Based Collaborative Filtering**: 대규모의 희소한(sparse) 데이터를 처리하기 위해 데이터의 잠재적인 패턴을 학습하는 모델을 구축합니다. 대표적으로 SVD와 Matrix Factorization이 있습니다.
-   **SVD (Singular Value Decomposition)**: 고차원의 사용자-아이템 행렬을 저차원의 행렬(U, Σ, Vᵀ)로 분해하여 데이터의 잠재 요인(Latent Factor)을 추출하는 강력한 차원 축소 기법입니다.
-   **Matrix Factorization (MF)**: SVD와 유사하지만, 관측된 평점 데이터만을 사용하여 사용자 및 아이템의 잠재 요인 행렬을 학습합니다. SVD의 결측치(missing value) 문제를 효과적으로 해결하여 실제 추천 시스템에서 널리 사용됩니다.
-   **Content-Based Filtering**: 아이템 자체의 콘텐츠(속성)와 사용자 프로필을 분석하여 유사한 아이템을 추천하는 방식으로, 협업 필터링의 Cold-Start 문제를 해결하는 데 강점이 있습니다.

## 세부 내용 📚

### 1️⃣ 아이템 기반 협업 필터링 (Item-Based Collaborative Filtering)

-   **개념**: "이 아이템을 좋아한 사용자는 다른 유사한 아이템도 좋아할 것이다"라는 가정에 기반합니다.
-   **계산 과정**:
    1.  **아이템 간 유사도 계산**: 모든 아이템 쌍에 대해 유사도를 계산합니다. 주로 코사인 유사도(Cosine Similarity)가 사용됩니다.
        -   `코사인 유사도`: 두 아이템의 평점 벡터를 다차원 공간의 벡터로 보고, 두 벡터 사이의 각도의 코사인 값을 이용해 유사도를 측정합니다.
    2.  **이웃(Neighbor) 선정**: 예측하려는 아이템과 가장 유사한 k개의 아이템(Nearest Neighbors)을 선정합니다.
    3.  **평점 예측**: 선정된 이웃 아이템들에 대한 대상 사용자의 평점을 이용해 가중 평균(Weighted Sum)을 계산하여 최종 평점을 예측합니다.
        -   `예측 공식`: `R(m, u) = {Σ [S(m, j) * R(j, u)]} / {Σ S(m, j)}`
            -   `R(m, u)`: 사용자 u의 아이템 m에 대한 예측 평점
            -   `S(m, j)`: 아이템 m과 이웃 아이템 j의 유사도
            -   `R(j, u)`: 사용자 u의 이웃 아이템 j에 대한 실제 평점

### 2️⃣ 모델 기반 방법론: SVD와 Matrix Factorization

-   **등장 배경**: 메모리 기반 방법은 데이터가 방대해질수록 계산량과 메모리 사용량이 기하급수적으로 증가하는 확장성(Scalability) 문제가 있습니다. 이를 해결하기 위해 모델 기반 방법이 등장했습니다.
-   **Netflix Prize**: 2006년 넷플릭스가 개최한 추천 알고리즘 경진대회로, 이 대회를 통해 SVD와 Matrix Factorization 기법이 크게 발전하고 주목받게 되었습니다.

#### 🤖 SVD (Singular Value Decomposition)

-   **개념**: 사용자-아이템 행렬 A를 3개의 행렬(U, Σ, Vᵀ)의 곱으로 분해하는 기법입니다.
    -   `A (m x n)`: 원본 사용자-아이템 행렬
    -   `U (m x m)`: 사용자의 잠재 요인을 나타내는 직교 행렬 (Left Singular Vectors)
    -   `Σ (m x n)`: 데이터의 중요도를 나타내는 특이값(Singular Value)을 대각성분으로 갖는 대각 행렬
    -   `Vᵀ (n x n)`: 아이템의 잠재 요인을 나타내는 직교 행렬 (Right Singular Vectors)
-   **차원 축소 (Truncated SVD)**: Σ 행렬에서 중요도가 낮은 특이값들을 제거하고, 이에 맞춰 U와 Vᵀ 행렬의 차원도 줄여(Truncate) 데이터를 압축하고 노이즈를 제거합니다. 이를 통해 더 적은 데이터로 효율적인 예측이 가능해집니다.
-   **잠재 요인 (Latent Factor)**: SVD를 통해 추출된 차원은 사용자의 취향이나 아이템의 장르, 분위기 등 명시적으로는 드러나지 않는 숨겨진 의미(Hidden Semantics)를 나타냅니다.

#### 🤖 Matrix Factorization (MF)

-   **개념**: SVD의 가장 큰 단점은 행렬에 빈 값(결측치)이 없어야 한다는 점입니다. MF는 이 문제를 해결하기 위해, 존재하는 평점만을 가지고 사용자 잠재 요인 행렬(U)과 아이템 잠재 요인 행렬(Vᵀ)을 학습하여 원본 행렬을 근사(Approximate)합니다.
    -   `A ≈ U x Vᵀ`
-   **평점 예측**: 특정 사용자와 아이템의 평점은 해당 사용자의 벡터와 아이템의 벡터를 내적(Dot Product)하여 예측합니다.
-   **학습**: 실제 평점과 예측 평점의 오차(Loss)를 최소화하는 방향으로 경사 하강법(Gradient Descent) 등의 최적화 알고리즘을 사용해 U와 Vᵀ를 반복적으로 업데이트하며 학습합니다.

### 3️⃣ 협업 필터링 vs. 콘텐츠 기반 필터링

| 구분 | 협업 필터링 (Collaborative Filtering) | 콘텐츠 기반 필터링 (Content-Based Filtering) |
| :--- | :--- | :--- |
| **기반 데이터** | 사용자-아이템 상호작용 (평점, 클릭 등) | 아이템의 속성(장르, 감독 등), 사용자 프로필 |
| **장점** | - 구현이 간단<br>- 숨겨진 패턴 발견 가능 | - Cold-Start 문제 없음<br>- 새로운 아이템 추천 가능<br>- 추천 이유 설명 가능 |
| **단점** | - Cold-Start 문제<br>- 데이터 희소성(Sparsity) 문제<br>- 인기 편향(Popularity Bias) | - 콘텐츠 분석의 어려움<br>- 제한된 추천(Serendipity 부족) |

## 오늘의 연습문제 📝

-   **문제 1**: 아이템 기반 협업 필터링과 사용자 기반 협업 필터링의 핵심적인 차이점은 무엇이며, 일반적으로 어떤 상황에서 아이템 기반 방식이 더 나은 성능을 보일 수 있는지 설명해보세요.
-   **문제 2**: 추천 시스템에서 전통적인 SVD 대신 Matrix Factorization 기법이 더 널리 사용되는 주된 이유는 무엇인가요?
-   **문제 3**: SVD를 영화 추천 시스템에 적용했을 때, 분해된 행렬에서 추출되는 '잠재 요인(Latent Factor)'은 구체적으로 어떤 의미를 가질 수 있을지 예시를 들어 설명해보세요.
