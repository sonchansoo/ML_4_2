## 🔍 강의 요약

이 강의는 대규모 데이터셋에서 항목 간의 흥미로운 관계를 발견하는 머신러닝 기법인 **연관 규칙 탐사(Association Rule Mining)**에 대해 설명합니다. 주로 **Apriori 알고리즘**을 중심으로, `Support`(지지도), `Confidence`(신뢰도), `Lift`(향상도)와 같은 규칙의 강도를 측정하는 핵심 지표들을 다룹니다. 또한, 추천 시스템의 다른 접근 방식인 **콘텐츠 기반 필터링(Content-Based Filtering)**과 비교하여 각 방법의 특징과 장단점을 소개합니다.

## 💡 핵심 포인트

-   **연관 규칙 탐사 (Association Rule Mining)**: "어떤 항목이 함께 발생하는가"에 대한 패턴을 찾는 기술입니다. (예: {기저귀}를 구매하면 {맥주}를 구매한다)
-   **Apriori 알고리즘**: 최소 지지도(`min-support`)를 이용해 빈번하게 발생하는 아이템 셋(Frequent Itemset)을 효율적으로 찾아내는 알고리즘입니다. "빈번하지 않은 아이템 셋의 모든 상위 집합 또한 빈번하지 않다"는 원리를 사용해 후보군을 줄여나갑니다.
-   **Support (지지도)**: 전체 거래 중 특정 아이템 셋이 포함된 거래의 비율입니다.
    -   `Support(X) = (X를 포함하는 트랜잭션 수) / (전체 트랜잭션 수)`
-   **Confidence (신뢰도)**: X를 포함한 거래 중에서 Y도 함께 포함될 조건부 확률입니다.
    -   `Confidence(X → Y) = Support(X ∪ Y) / Support(X)`
-   **Lift (향상도)**: X의 구매가 Y의 구매에 미치는 영향을 측정하는 지표입니다. 1보다 크면 양의 상관관계를 의미합니다.
    -   `Lift(X → Y) = Confidence(X → Y) / Support(Y)`
-   **콘텐츠 기반 필터링 (Content-Based Filtering)**: 사용자가 과거에 선호했던 아이템의 '특징(feature)'을 기반으로 유사한 아이템을 추천하는 방식입니다.

## 세부 내용 📚

### 1️⃣ 연관 규칙 탐사 (Association Rule Mining) 🛒

-   **정의**: 대규모 데이터베이스에서 "무엇이 무엇과 함께 가는가"에 대한 유용한 패턴(규칙)을 발견하는 과정입니다.
-   **초기 활용**: `Market Basket Analysis`(장바구니 분석)에서 고객의 구매 패턴을 파악하기 위해 처음 사용되었습니다.
-   **핵심 용어**:
    -   `Transaction`: 함께 구매된 아이템들의 집합 (예: {빵, 치즈, 우유}).
    -   `Itemset`: 하나 이상의 아이템으로 구성된 집합.
    -   `Association Rule`: `{X} → {Y}` 형태로 표현되는 규칙.
        -   `Antecedent` (선행항): 규칙의 조건 부분 (X).
        -   `Consequent` (후행항): 규칙의 결과 부분 (Y).

### 2️⃣ 규칙 강도 측정 지표 📊

연관 규칙의 유용성을 평가하기 위해 세 가지 주요 지표가 사용됩니다.

-   **Support (지지도)**: 아이템 셋이 얼마나 자주 발생하는지를 나타냅니다.
-   **Confidence (신뢰도)**: 규칙이 얼마나 신뢰할 수 있는지를 나타냅니다.
-   **Lift (향상도)**: 두 아이템 간의 상관관계를 측정합니다.
    -   `Lift = 1`: X와 Y는 독립적 관계입니다.
    -   `Lift > 1`: X와 Y는 양의 상관관계 (함께 구매될 가능성 높음).
    -   `Lift < 1`: X와 Y는 음의 상관관계 (함께 구매될 가능성 낮음).

### 3️⃣ Apriori 알고리즘 ⚙️

-   **문제점**: 가능한 모든 규칙을 생성하고 계산하는 `Brute-force` 방식은 아이템 수가 증가하면 계산량이 기하급수적으로 늘어나 비효율적입니다.
-   **핵심 원리 (Apriori Principle)**:
    > 만약 어떤 아이템 셋이 빈번하지 않다면(즉, 최소 지지도를 넘지 못한다면), 그 아이템 셋을 포함하는 더 큰 아이템 셋(superset) 역시 빈번하지 않다.

-   **알고리즘 2단계**:
    1.  **빈번한 아이템 셋 찾기 (Find Frequent Itemsets)**:
        -   `min-support`(최소 지지도) 기준값을 설정합니다.
        -   개별 아이템(1-itemset)부터 시작하여 `min-support`를 만족하는 것만 남깁니다.
        -   이전 단계에서 살아남은 아이템 셋들을 조합하여 다음 크기의 후보 아이템 셋을 만들고, 다시 `min-support`를 기준으로 가지치기(pruning)를 반복합니다.
    2.  **연관 규칙 생성 (Generate Association Rules)**:
        -   1단계에서 찾은 빈번한 아이템 셋들을 기반으로 가능한 모든 규칙을 만듭니다.
        -   `min-confidence`(최소 신뢰도) 기준값을 설정하고, 이 기준을 통과하는 규칙만을 최종 결과로 선택합니다.

### 4️⃣ 콘텐츠 기반 필터링 (Content-Based Filtering) 🎬

-   **개념**: 사용자의 과거 행동 데이터와 아이템의 고유한 특징(feature)을 활용하여 추천하는 방식입니다.
-   **동작 방식**:
    1.  사용자가 선호한 아이템(예: 영화)의 특징(장르, 감독, 배우 등)을 분석합니다.
    2.  이 특징들을 바탕으로 사용자 프로필(User Profile)을 생성합니다.
    3.  사용자 프로필과 유사한 특징을 가진 다른 아이템들을 추천합니다.
-   **장점**:
    -   다른 사용자의 데이터가 필요 없어 `Cold Start` 문제에 강합니다.
    -   새롭거나 인기가 없는 아이템도 추천이 가능합니다.
    -   추천의 이유를 설명하기 용이합니다. (예: "액션 장르를 좋아하셔서 이 영화를 추천합니다.")
-   **단점**:
    -   아이템의 특징을 추출하고 분석하는 과정이 복잡할 수 있습니다.
    -   사용자가 과거에 접해보지 않은 새로운 장르의 아이템은 추천하기 어렵습니다.

## 오늘의 연습문제 📝

-   **문제 1**: 아래의 5개 트랜잭션 데이터가 주어졌을 때, 아이템 셋 `{우유, 기저귀}`의 `Support`(지지도)를 계산하세요.
    -   T1: {빵, 우유}
    -   T2: {빵, 기저귀, 맥주, 계란}
    -   T3: {우유, 기저귀, 맥주, 콜라}
    -   T4: {빵, 우유, 기저귀, 맥주}
    -   T5: {빵, 우유, 기저귀, 콜라}

-   **문제 2**: 문제 1의 데이터를 사용하여, 연관 규칙 `{우유} → {기저귀}`의 `Confidence`(신뢰도)를 계산하세요.

-   **문제 3**: Apriori 알고리즘이 `Brute-force` 방식보다 효율적인 이유를 **Apriori 원리**를 사용하여 설명해 보세요.
