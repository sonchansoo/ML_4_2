## 🔍 강의 요약

이번 강의에서는 기계 학습의 두 가지 주요 모델인 **나이브 베이즈 분류기(Naïve Bayesian Classifier)**와 **마르코프 모델(Markov Model)**에 대해 학습합니다. 나이브 베이즈는 베이즈 정리를 기반으로 각 특징(feature)이 서로 독립적이라고 가정하여 확률을 계산하는 간단하면서도 강력한 분류 모델입니다. 마르코프 모델은 현재 상태가 이전 상태에만 의존한다는 '마르코프 속성'을 이용해 시간 순서나 순차적 데이터의 패턴을 분석하는 모델로, 상태를 관찰할 수 있는 마르코프 체인과 관찰할 수 없는 히든 마르코프 모델(HMM)로 나뉩니다.

## 💡 핵심 포인트

-   **나이브 베이즈 분류기**: 베이즈 정리를 활용하며, 모든 특징이 클래스에 대해 **조건부로 독립적(conditionally independent)**이라고 '순진하게(naïve)' 가정하는 모델입니다.
-   **조건부 독립 가정**: 복잡한 확률 계산을 각 특징의 확률을 곱하는 간단한 형태로 만들어 계산을 매우 효율적으로 만듭니다.
-   **라플라스 수정 (Laplace Correction)**: 훈련 데이터에 없는 조합이 발생하여 확률이 0이 되는 문제를 방지하기 위해, 분자에 작은 값(보통 1)을 더해주는 기법입니다.
-   **마르코프 모델**: 시간이나 순서에 따라 변하는 상태를 분석하는 확률 모델입니다.
-   **마르코프 속성 (Markov Property)**: 특정 시점(t+1)의 상태는 바로 직전 시점(t)의 상태에만 영향을 받는다는 핵심 원칙입니다.
-   **마르코프 체인 vs. HMM**: 상태를 직접 관찰할 수 있으면 **마르코프 체인**, 상태는 숨겨져 있고 결과만 관찰할 수 있으면 **히든 마르코프 모델(HMM)**을 사용합니다.

## 세부 내용 📚

### 1️⃣ 나이브 베이즈 분류기 (Naïve Bayesian Classifier) 🧠

-   **기본 원리**: 베이즈 정리를 기반으로 특정 데이터가 어떤 클래스에 속할 확률을 계산합니다.
    -   `P(Y|X) = (P(X|Y) * P(Y)) / P(X)`
    -   `P(Y|X)`: 사후 확률 (Posterior) - 데이터 X가 주어졌을 때 클래스 Y일 확률 (우리가 구하고자 하는 것)
    -   `P(X|Y)`: 가능도 (Likelihood) - 클래스 Y에서 데이터 X가 나타날 확률
    -   `P(Y)`: 사전 확률 (Prior) - 데이터와 무관하게 클래스 Y가 나타날 확률
    -   `P(X)`: 증거 (Evidence) - 데이터 X가 나타날 확률

-   **'나이브(Naïve)' 가정의 의미**:
    -   일반적으로 데이터의 특징(X1, X2, ...)들은 서로 영향을 줄 수 있지만, 나이브 베이즈는 모든 특징이 **클래스(Y)에 대해 독립적**이라고 가정합니다.
    -   이 가정 덕분에 복잡한 결합 확률 `P(X1, X2, ... | Y)`를 `P(X1|Y) * P(X2|Y) * ...` 와 같이 개별 확률의 곱으로 간단하게 계산할 수 있습니다.
    -   **장점**: 계산이 매우 빠르고, 적은 양의 훈련 데이터로도 좋은 성능을 보입니다.

-   **계산 예시: 테니스 경기 예측 🎾**
    1.  **학습 단계 (Learning Phase)**: 훈련 데이터를 바탕으로 각 속성(날씨, 온도 등)에 대한 빈도 테이블을 만듭니다.
        -   전체 경기 중 'Yes'와 'No'의 확률(사전 확률)을 계산합니다. (예: P(Play=Yes) = 9/14)
        -   'Yes'일 때 날씨가 'Sunny'일 확률, 'No'일 때 날씨가 'Sunny'일 확률 등 조건부 확률을 계산합니다. (예: P(Outlook=Sunny | Play=Yes) = 2/9)
    2.  **테스트 단계 (Test Phase)**: 새로운 데이터가 주어지면, 학습된 확률들을 곱하여 'Yes'일 확률과 'No'일 확률을 각각 계산합니다.
        -   `P(Yes|X') ∝ P(Sunny|Yes) * P(Cool|Yes) * P(High|Yes) * P(Strong|Yes) * P(Yes)`
        -   `P(No|X') ∝ P(Sunny|No) * P(Cool|No) * P(High|No) * P(Strong|No) * P(No)`
    3.  **결정**: 두 확률 중 더 높은 쪽으로 클래스를 예측합니다.

-   **라플라스 수정 (Laplace Correction)의 필요성**:
    -   만약 훈련 데이터에서 'Yes'일 때 날씨가 'Overcast'인 경우가 한 번도 없었다면, `P(Overcast|Yes)`는 0이 됩니다.
    -   이 경우, 다른 모든 조건이 완벽해도 전체 확률이 0이 되어버리는 문제가 발생합니다.
    -   이를 방지하기 위해 분자에 1을, 분모에 속성의 종류 개수를 더해 확률이 0이 되는 것을 막습니다.

### 2️⃣ 마르코프 모델 (Markov Model) ⛓️

-   **기본 개념**: 시간이나 순서에 따른 상태 변화를 분석하는 확률적 모델입니다. (예: 오늘의 날씨가 내일의 날씨에 영향을 주는 경우)

-   **마르코프 속성 (Markov Property)**:
    -   "미래는 오직 현재에만 의존한다."
    -   즉, t+1 시점의 상태 확률은 t-1, t-2 등 과거의 모든 상태가 아닌, 오직 t 시점의 상태에 의해서만 결정됩니다.
    -   `P(Xt+1 | Xt, Xt-1, ..., X0) = P(Xt+1 | Xt)`

-   **주요 구성 요소**:
    -   **상태 (States)**: 시스템이 가질 수 있는 유한한 개수의 상태 (예: 맑음, 비)
    -   **전이 확률 (Transition Probability)**: 한 상태에서 다른 상태로 변할 확률. 이를 행렬로 나타낸 것이 **전이 행렬(Transition Matrix)**입니다.
        -   예시 (날씨):
            -   오늘 비 -> 내일 비 (0.4)
            -   오늘 비 -> 내일 맑음 (0.6)
            -   오늘 맑음 -> 내일 비 (0.2)
            -   오늘 맑음 -> 내일 맑음 (0.8)

-   **마르코프 체인 vs. 히든 마르코프 모델 (HMM)**:
    -   **마르코프 체인 (Markov Chain)**: 각 시점의 상태를 **직접 관찰**할 수 있습니다. (예: 매일의 날씨를 기록하는 경우)
    -   **히든 마르코프 모델 (HMM)**: 상태는 **숨겨져(hidden)** 있고, 우리는 그 상태에서 생성된 **결과(observation)만 관찰**할 수 있습니다.
        -   **예시 (항아리와 공)**: 3개의 항아리(상태)가 있고, 각 항아리에는 다른 색의 공들이 들어있습니다. 우리는 어떤 항아리에서 공을 꺼내는지 보지 못하고, 꺼내진 공의 색깔(결과) 순서만 볼 수 있습니다. HMM은 이 공 색깔 순서를 보고 "세 번째 공은 1번 항아리에서 나왔을 확률이 가장 높다"와 같이 숨겨진 상태를 추론하는 데 사용됩니다.

## 오늘의 연습문제 📝

-   **문제 1**: 나이브 베이즈 분류기에서 "나이브(naïve)"라는 가정이 무엇을 의미하며, 이 가정이 모델에 어떤 장점을 주는지 설명해 보세요.

-   **문제 2**: 아래는 독감(Flu) 진단 데이터의 일부입니다. '열(Fever)=High', '콧물(Sinus)=No'인 새로운 환자가 독감에 걸렸을 확률과 걸리지 않았을 확률을 나이브 베이즈 방식으로 각각 계산하고, 최종 진단을 예측해 보세요. (단, 라플라스 수정은 적용하지 않습니다.)

| 독감(Flu) | 열(Fever) | 콧물(Sinus) |
| :---: | :---: | :---: |
| Yes | High | Yes |
| Yes | Mid | Yes |
| No | High | No |
| No | Mid | Yes |

-   **문제 3**: 어떤 학생의 하루 상태가 '공부함(Study)'과 '안함(Play)' 두 가지뿐이라고 가정합시다. 이 학생의 상태 변화에 대한 전이 확률이 다음과 같을 때, 이를 마르코프 모델의 **전이 행렬(Transition Matrix)**로 표현해 보세요.
    -   오늘 공부했다면, 내일도 공부할 확률: 70%
    -   오늘 공부했다면, 내일은 놀 확률: 30%
    -   오늘 놀았다면, 내일 공부할 확률: 50%
    -   오늘 놀았다면, 내일도 놀 확률: 50%
