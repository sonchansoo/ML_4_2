## 🔍 강의 요약
이번 강의에서는 클러스터링의 품질을 평가하는 다양한 측정 방법과 대표적인 분할 기반 클러스터링 알고리즘에 대해 학습합니다. 클러스터링의 성능을 객관적으로 평가하기 위한 Elbow Method, Silhouette Index, Purity 등의 개념을 이해하고, 각 방법의 장단점을 파악합니다. 또한, K-Means 알고리즘을 시작으로 범주형 데이터를 위한 K-modes, 그리고 이상치에 강건한 K-medoids 계열 알고리즘(PAM, CLARA, CLARANS)들의 작동 원리와 특징을 비교 분석합니다.

## 💡 핵심 포인트
- **클러스터링 품질 측정**: 최적의 클러스터 개수(k)가 사전에 주어지지 않으므로, 결과의 품질을 측정하는 것은 매우 중요합니다.
- **Elbow Method**: 클러스터 개수(k)를 늘려가며 관성(inertia)의 변화를 그래프로 확인하고, 기울기가 급격히 완만해지는 '팔꿈치' 지점을 최적의 k로 선택하는 방법입니다.
- **Silhouette Index**: 각 데이터가 자신의 클러스터에 얼마나 잘 속해 있고, 다른 클러스터와는 얼마나 잘 분리되어 있는지를 나타내는 지표입니다. 값이 1에 가까울수록 좋습니다.
- **K-Means vs. K-medoids**: K-Means는 클러스터의 중심점으로 평균(centroid)을 사용하지만, K-medoids는 실제 데이터 포인트(medoid)를 사용하므로 이상치(outlier)에 더 강건한 특징이 있습니다.
- **K-modes**: K-Means를 범주형 데이터에 적용할 수 있도록 변형한 알고리즘으로, 평균 대신 최빈값(mode)을 클러스터의 중심으로 사용합니다.
- **K-medoids 알고리즘**: PAM은 가장 기본적인 K-medoids 알고리즘이며, CLARA와 CLARANS는 대용량 데이터 처리를 위해 PAM을 샘플링 기반으로 개선한 알고리즘입니다.

## 세부 내용 📚
### 1️⃣ 클러스터링 품질 측정 방법 📊
- **어려움**: 최적의 클러스터 개수(k)를 미리 알기 어렵고, 좋은 클러스터링의 기준이 애플리케이션과 데이터셋에 따라 달라지기 때문에 품질 측정이 어렵습니다.
- **주요 측정 지표**:
    - **Elbow Method**:
        - K-Means 클러스터링 결과에 주로 적용됩니다.
        - 클러스터 내 데이터 포인트와 중심(centroid) 간의 평균 거리(또는 관성)를 계산합니다.
        - k값이 증가함에 따라 거리는 계속 감소하지만, 특정 k값에서 감소율이 급격히 둔화되는 지점(elbow)을 최적의 k로 판단합니다.
    - **Silhouette Index**:
        - 개별 데이터 포인트에 대한 실루엣 계수를 계산하여 평균냅니다.
        - `a(i)`: i번째 데이터와 같은 클러스터 내 다른 데이터들과의 평균 거리
        - `b(i)`: i번째 데이터와 가장 가까운 다른 클러스터의 모든 데이터들과의 평균 거리
        - 실루엣 계수 `s(i) = (b(i) - a(i)) / max(a(i), b(i))`
        - 점수가 +1에 가까우면 클러스터가 명확히 구분됨을, 0에 가까우면 클러스터가 겹침을, 음수이면 잘못된 클러스터에 할당되었을 가능성을 의미합니다.
    - **Purity**:
        - 정답 레이블이 있는 경우에만 사용 가능한 외부 평가 지표입니다.
        - 각 클러스터를 가장 빈번하게 나타나는 클래스에 할당한 후, 정확히 할당된 데이터의 비율을 계산하여 순도를 측정합니다.

### 2️⃣ 분할 기반 클러스터링 알고리즘 🧩
- **기본 개념**: 전체 데이터를 k개의 클러스터로 분할하며, 특정 기준(예: 제곱 오차의 합)을 최적화하는 것을 목표로 합니다.
- **K-Means Algorithm**:
    - **장점**: 구현이 간단하고 대용량 데이터에 대해 비교적 효율적입니다.
    - **단점**:
        - 평균을 사용하므로 이상치(outlier)에 민감합니다.
        - 평균을 정의할 수 없는 범주형 데이터에는 적용이 불가능합니다.
        - 클러스터 개수 k를 사전에 지정해야 합니다.
- **K-modes Algorithm**:
    - K-Means를 범주형 데이터용으로 수정한 버전입니다.
    - 클러스터의 중심으로 평균(mean) 대신 최빈값(mode)을 사용합니다.
    - 데이터 간의 거리는 속성값이 일치하지 않는 개수를 세는 Hamming Distance를 사용합니다.
- **K-medoids Algorithm**:
    - 클러스터의 중심으로 실제 데이터 포인트인 'medoid'를 사용합니다.
    - 이상치의 영향을 덜 받기 때문에 K-Means보다 강건합니다.
    - **PAM (Partitioning Around Medoids)**:
        - 초기 medoid를 임의로 선택한 후, medoid가 아닌 객체와 교체하며 총비용(거리의 합)이 감소하는지 반복적으로 확인합니다.
        - 작은 데이터셋에는 효과적이지만, 모든 객체와의 교체를 고려하므로 대용량 데이터에는 비효율적입니다.
    - **CLARA (Clustering Large Applications)**:
        - 전체 데이터셋 대신 여러 개의 랜덤 샘플을 추출하고, 각 샘플에 PAM을 적용하여 최상의 클러스터링 결과를 선택합니다.
        - PAM보다 대용량 데이터 처리에 용이하지만, 샘플링 품질에 따라 성능이 좌우됩니다.
    - **CLARANS (Clustering Algorithm based on Randomized Search)**:
        - CLARA처럼 샘플링을 활용하지만, 무작위로 이웃 노드(medoid 하나만 다른 집합)를 탐색하며 지역 최적해(local optima)를 찾는 더 정교한 방식입니다.
        - PAM과 CLARA보다 효율적이고 높은 품질의 클러스터링을 제공합니다.

## 오늘의 연습문제 📝
- **문제 1**: K-Means와 K-medoids 알고리즘의 가장 큰 차이점은 무엇이며, 어떤 상황에서 K-medoids를 사용하는 것이 더 유리할까요?
- **문제 2**: Elbow Method와 Silhouette Index는 클러스터링에서 최적의 클러스터 개수(k)를 찾는 데 사용됩니다. 두 방법의 작동 원리를 설명하고, 각각의 장단점을 비교해 보세요.
- **문제 3**: 범주형 데이터(categorical data)를 클러스터링해야 할 때 K-Means 알고리즘을 직접 적용하기 어려운 이유는 무엇이며, 이를 해결하기 위한 K-modes 알고리즘은 어떤 방식으로 작동하는지 설명해 주세요.
