제공해주신 PDF 파일의 내용을 바탕으로, 고유명사(알고리즘 이름, 라이브러리 명, 특정 데이터셋 이름 등)는 원문 그대로 유지하고 나머지 내용을 한국어로 번역하여 정리해 드립니다.

---

**Page 1**
빠른 복습
데이터 사이언스:
클러스터링 품질 척도
Ok-Ran Jeong
2025년 가을

**Page 2**
클러스터링 품질 측정
◼ 매우 어려움, 왜냐하면
◼ 클러스터(그룹)의 수를 미리 알 수 없고,
◼ 허용 가능한 클러스터링은 애플리케이션과 데이터셋에 따라 다르기 때문임.

**Page 3**
K-Means 클러스터링 알고리즘 결과 (서로 다른 k 사용)
어느 것이 더 나은가?

**Page 4**
다양한 클러스터링 알고리즘의 결과
어느 것이 최고인가?

**Page 5**
사용되는 몇 가지 정량적 척도
◼ 클러스터링의 품질을 파악하기 위해 다음을 포함하여 많은 것들이 제안되었음.
◼ 최대 클러스터 간 거리
◼ 최소 클러스터 내 거리
◼ 클러스터의 오차 제곱합
◼ 최대 반경 (객체에서 클러스터 중심점(centroid)까지)
◼ 평균 반경
◼ ….

**Page 6**
최적의 클러스터 수를 결정하는 방법
◼ Elbow 기법
◼ Silhouette 지수
◼ Purity (순도)
◼ Dunn 지수
◼ Davies-Bouldin 지수

**Page 7**
Elbow 기법
◼ K-Means 클러스터링 결과에 적용됨.
◼ k의 후보 값 범위를 선택한 다음, 각 k 값을 사용하여 K-Means 클러스터링을 적용함.
◼ 클러스터 내의 점들과 중심점 사이의 평균 거리를 구하고 이를 그래프로 나타냄.
◼ 그래프에서 평균 거리가 급격하게 떨어지는 k 값을 선택함.

**Page 8**
“Elbow(팔꿈치)” 지점 선택 (1/2)
◼ 그래프의 x축은 클러스터 수(k)이고, y축은 클러스터 내의 중심점과 데이터 포인트 간의 평균 거리임.
◼ 클러스터 수(k)가 증가함에 따라 평균 거리는 감소함.
◼ 최적의 클러스터 수(k)를 찾으려면 그래프를 관찰하여 거리가 급격하고 가파르게 떨어지는 k 값을 찾음.
◼ 팔꿈치(elbow)가 발생하는 곳이 최적의 k임.

**Page 9**
“Elbow” 지점 선택 (2/2)
◼ k=2, 3, 4일 때 평균 거리가 급격히 감소함.
◼ 아래 그래프에서 k=2, 3, 4일 때 형성된 클러스터와 평균 거리를 관찰하시오.
◼ 이 데이터는 2차원이므로 시각화하기 쉽고 최적의 k 값인 k=4를 선택하기 쉬움.

**Page 10**
Inertia(관성)와 Distortion(왜곡)
◼ Inertia는 데이터셋이 K-Means에 의해 얼마나 잘 클러스터링되었는지 측정함.
◼ 각 데이터 포인트와 그 중심점 사이의 거리를 측정하고, 이 거리를 제곱한 다음, 하나의 클러스터 전체에 대해 이 제곱들을 합하여 계산함.
◼ 좋은 모델은 낮은 Inertia와 적은 수의 클러스터(K)를 가진 모델임.
◼ Distortion은 각 클러스터의 중심점으로부터의 유클리드 제곱 거리의 평균임.

**Page 11**
Elbow 기법을 위한 Python 코드 (1/4)
◼ (링크 생략)
◼ IRIS 데이터셋 사용
(코드 생략 - 라이브러리 임포트 및 데이터 로드)

**Page 12**
Elbow 기법을 위한 Python 코드 (2/4)
# for 루프를 사용하여 다양한 클러스터(k) 범위에 대해 K-Means를 실행하고
distortions를 리스트에 수집함
(코드 생략)

**Page 13**
Elbow 기법을 위한 Python 코드 (3/4)
# K-Means의 distortions를 그래프로 그림
(코드 생략)

**Page 14**
Elbow 기법을 위한 Python 코드 (4/4)
Elbow는 k=3에 있음.

**Page 15**
Silhouette 지수
◼ (링크 생략)
◼ (링크 생략)

**Page 16**
Silhouette 지수
◼ 이것은 K-Means 클러스터링 결과에 적용됨.
◼ Silhouette 지수(값, 점수)는 객체가 다른 클러스터에 비해 자신의 클러스터와 얼마나 유사한지를 나타내는 척도임.
◼ 모든 샘플에 대한 Silhouette 계수의 평균임.
◼ 대부분의 객체가 높은 값을 가지면 클러스터링 구성이 적절한 것임. 많은 점들이 낮거나 음수 값을 가지면 클러스터링 구성에 클러스터가 너무 많거나 너무 적은 것일 수 있음.

**Page 17**
데이터 포인트에 대한 Silhouette 계수
◼ i번째 포인트의 Silhouette 계수를 찾는 단계:
◼ 1. a(i) 계산: 해당 포인트와 같은 클러스터 내의 다른 모든 포인트 간의 평균 거리.
◼ 2. b(i) 계산: 해당 포인트와 다른 모든 클러스터 내의 포인트 간의 평균 거리.
◼ 3. s(i) 계산: 아래 공식을 사용하여 i번째 포인트의 Silhouette 계수 계산.
(공식 생략)

**Page 18**
참고: a(i), b(i)의 의미
(그림 설명: a(i)는 클러스터 내 평균 거리, b(i)는 이웃 클러스터와의 평균 거리)

**Page 19**
평균 Silhouette 점수 계산 및 플로팅
◼ 데이터셋의 각 포인트에 대한 Silhouette 계수를 계산한 후, 모든 k에 대해 평균 Silhouette 점수를 계산함.
AverageSilhouette = mean{S(i)}
◼ 그런 다음 average_silhouette와 K 사이의 그래프를 그림.
◼ 이 척도는 [-1, 1] 범위를 가짐.
◼ 주요 포인트:
◼ +1은 클러스터들이 서로 잘 떨어져 있고 명확하게 구별됨을 나타냄.
◼ 0 (또는 0에 가까움)은 클러스터들이 겹침을 나타냄.
◼ < 0은 해당 샘플들이 잘못된 클러스터에 할당되었거나 이상치(outliers)일 수 있음을 나타냄.

**Page 20**
Silhouette 점수에 대한 Scikit-learn 지원
◼ (링크 생략)
(코드 생략 - KMeans 모델 생성, 학습, Silhouette 점수 계산)

**Page 21**
최적의 “k” 찾기
◼ Elbow 기법과 유사하게, k(클러스터 수)의 후보 값 범위를 선택한 다음, 각 k 값에 대해 K-Means 클러스터링을 훈련함.
◼ 각 K-Means 클러스터링 모델에 대해 Silhouette 점수를 그래프로 나타내고 각 클러스터의 변동 및 이상치를 관찰함.
◼ 아래에서 k=4일 때 Silhouette 점수가 가장 높으므로 최적임.

**Page 22**
참고: 플롯을 위한 Python 코드
◼ (링크 생략)
(코드 생략 - 다양한 k에 대해 Silhouette 점수 계산 및 플로팅)

**Page 23**
Silhouette 플롯 분석 (1/2)
◼ k=2, 3, 4, 5, 6에 대한 5개의 플롯
(그림 설명: 클러스터 레이블, 평균 Silhouette 점수 표시)

**Page 24**
Silhouette 플롯 분석 (2/2)
◼ Silhouette 플롯은 n_cluster 값 3이 나쁜 선택임을 보여줌. cluster_label=1인 클러스터의 모든 포인트가 평균 이하의 Silhouette 점수를 가지기 때문임.
◼ n_cluster 값 5는 나쁜 선택임. cluster_label=2와 4인 클러스터의 모든 포인트가 평균 이하의 Silhouette 점수를 가지기 때문임.
◼ n_cluster 값 6은 나쁜 선택임. cluster_label=1, 2, 4, 5인 클러스터의 모든 포인트가 평균 이하의 Silhouette 점수를 가지며, 이상치도 존재하기 때문임.
◼ 2와 4 사이에서 결정하는 것은 명확하지 않음.
◼ n_clusters=2일 때 cluster_label=1인 클러스터는 3개의 하위 클러스터가 하나의 큰 클러스터로 그룹화되어 두꺼움.
◼ n_clusters=4일 때, 모든 플롯이 비슷한 두께를 가지므로 비슷한 크기이며, 최적의 ‘k’로 간주될 수 있음.

**Page 25**
Purity (순도)
◼ (링크 생략)
◼ Purity를 계산하려면,
◼ 1. 각 클러스터는 해당 클러스터에서 가장 빈번한 클래스에 할당됨.
◼ 2. 이 할당의 정확도는 올바르게 할당된 문서의 수를 세고 전체 샘플 수로 나누어 측정함.

**Page 26**
개념 설명 그림
(그림 설명: 클러스터 품질에 대한 외부 평가 기준으로서의 Purity. 세 클러스터에 대한 다수 클래스와 다수 클래스의 멤버 수: x, 5 (클러스터 1); o, 4 (클러스터 2); diamond, 3 (클러스터 3). Purity는 (1/17) × (5 + 4 + 3) ≈ 0.71.)

**Page 27**
공식
(공식 생략)
여기서 Ω는 클러스터들의 집합이고 C는 클래스들의 집합임.

**Page 28**
Python 코드
(코드 생략 - Purity 점수 계산 함수)

**Page 29**
서브모듈 종료

**Page 30**
머신 러닝:
클러스터링 알고리즘 – 분할(Partitioning)
Ok-Ran Jeong
2025년 가을

**Page 31**
클러스터링 알고리즘
◼ K-Means 클러스터링 (다루었음)
◼ 계층적 병합 클러스터링 (다루었음)
◼ 분할 기반 클러스터링 (다룰 예정)
◼ 기댓값 최대화(Expectation Maximization) 클러스터링 (다룰 예정)
◼ DBSCAN (다룰 예정)
◼ OPTICS, BIRCH, ...

**Page 32**
감사의 말
(참고 자료 링크 생략)

**Page 33**
분할 알고리즘: 기본 개념 (1/2)
◼ 예: k-means, k-modes, k-medoids, …
◼ 공통 개념
◼ n개의 객체를 k개의 클러스터로 분할하고,
◼ 선택한 분할 기준을 최적화함 (예: 제곱 오차(거리) 최소화)
◼ 클러스터의 제곱 오차
mi는 Ci의 평균(중심점)임
◼ 모든 클러스터의 제곱 오차

**Page 34**
예시: 클러스터 i의 제곱 오차
(그림 및 계산 설명: 중심점 mi와 각 점 P1, P2, P3 사이의 거리 제곱 합 계산)
centroid: 존재하지 않는 데이터 포인트

**Page 35**
분할 알고리즘: 기본 개념 (2/2)
◼ 전역 최적해를 찾으려면 가능한 모든 분할을 검사해야 함.
◼ kn 가지의 가능한 분할 (k 클러스터, n 객체) -- 너무 비용이 많이 듦!
◼ 휴리스틱(heuristic) 방법을 사용함.
◼ 가능한 모든 분할 중 작은 부분집합만 고려함
◼ k-means: 각 클러스터는 클러스터의 중심(center)으로 표현됨. (일반적으로 중심은 클러스터 내의 객체 중 하나가 아님.)
◼ k-medoids: 각 클러스터는 클러스터 내의 객체 중 하나(medoid)로 표현됨.

**Page 36**
로드맵: 분할 알고리즘
◼ K-means (매우 빠르게 언급)
◼ K-modes
◼ K-medoids
◼ PAM
◼ CLARA
◼ CLARANS

**Page 37**
K-Means 알고리즘
◼ 초기화
◼ k개의 객체를 초기 클러스터 중심(centroids)으로 임의 선택함.
◼ 반복 (어떤 클러스터에도 변화가 없을 때까지)
◼ 각 객체 Oi에 대해
◼ Oi와 k개의 중심점 사이의 거리를 계산함
◼ Oi를 가장 가까운 중심점을 가진 클러스터에 (재)할당함
◼ 현재 할당을 기반으로 클러스터 중심점을 업데이트함

**Page 38**
K-Means 알고리즘의 장점
◼ 대규모 데이터셋에 대해 비교적 효율적임
◼ O(tkn) 여기서 n은 객체 수, k는 클러스터 수, t는 반복 횟수; 보통 k, t << n

**Page 39**
K-Means 알고리즘의 약점
◼ 평균이 정의될 수 있는 경우에만 적용 가능; 즉, 범주형 데이터에는 적용 불가.
◼ 대신 k-modes 알고리즘 사용.
◼ 노이즈 데이터와 이상치(outliers)를 처리할 수 없음
◼ 대신 k-medoids 알고리즘 사용.
◼ 클러스터 수 k를 미리 지정해야 함
◼ 대신 계층적 알고리즘이나 밀도 기반 알고리즘 사용.

**Page 40**
K-Means 알고리즘의 변형
◼ k-means 변형의 측면들
◼ 초기 k 중심점 선택
◼ 예: 가장 먼 k개의 점 선택
◼ 거리 척도
◼ 예: 맨해튼 거리 사용
◼ 클러스터 평균 계산 전략
◼ 예: 평균을 점진적으로 업데이트

**Page 41**
로드맵: 분할 알고리즘
◼ K-means (매우 빠르게 언급)
◼ K-modes
◼ K-medoids
◼ PAM
◼ CLARA
◼ CLARANS

**Page 42**
k-modes 알고리즘
◼ 클러스터의 평균(means)을 최빈값(modes)으로 대체
◼ 통계학에서 값 집합의 최빈값은 가장 자주 발생하는 값임.
◼ 예: 집합 {a, b, a, a, c, b}의 최빈값은 가장 빈번한 값 a임. (값 집합에 최빈값이 하나 이상 있을 수 있음).
◼ mode, mode vector
◼ 클러스터 내 m개 속성의 n개 레코드가 주어졌을 때, 각 속성의 최빈값은 해당 속성에 대해 가장 빈번한 값임.
◼ 모드 벡터(mode vector)는 n개 레코드에 대한 m개 최빈값의 집합임.

**Page 43**
예시
(표 설명: item, weather, sales 속성에 대한 데이터와 각 속성의 최빈값(mode)을 보여줌)
mode vector: (coffee, hot, good)

**Page 44**
클러스터 Modes
◼ k-modes 클러스터링에서 클러스터 중심은 모드 벡터로 표현됨.
◼ 클러스터의 모드 벡터는 클러스터 내 각 객체와 클러스터 중심 간의 거리 합을 최소화함.

**Page 45**
K-modes 클러스터링: 알고리즘
◼ 1단계
◼ 초기 클러스터 중심(modes)으로 k개의 고유한 객체를 무작위로 선택함.
◼ 2단계
◼ 각 객체와 클러스터 모드 벡터 사이의 거리를 계산함.
◼ 객체와의 거리가 가장 짧은 중심을 가진 클러스터에 객체를 할당함.
◼ 모든 객체가 클러스터에 할당될 때까지 이 단계를 반복함.
◼ 3단계
◼ 각 클러스터에 대해 새로운 모드 벡터를 선택하고 이전 모드 벡터와 비교함.
◼ 다르면 2단계로 돌아가고, 그렇지 않으면 중지함.

**Page 46**
거리 함수 (1/2)
◼ X와 Y를 m개의 범주형 속성을 가진 두 객체라고 하자.
(수식 생략)
◼ 두 객체 X와 Y 사이의 거리(또는 비유사성)는 다음과 같이 정의됨.
(수식 생략)

**Page 47**
거리 함수 (2/2)
◼ 함수 d(X,Y)는 종종 Hamming 거리라고 불리며, 이는 단순 일치 비유사성 척도임.
◼ X와 Y 사이의 범주형 값 불일치 수가 클수록 두 객체는 더 비유사함.

**Page 48**
참고: Hamming 거리
◼ Richard Hamming (1915-1998)의 이름을 따서 명명됨
◼ 이진 및 범주형 데이터에서 서로 다른 속성 값의 수
◼ (1011101)과 (1001001) 사이의 거리는 2임.
◼ (2143896)과 (2233796) 사이의 거리는 3임.
◼ (toned)와 (roses) 사이의 거리는 3임.
3비트 이진 큐브 100->011 거리는 3 (빨간 경로)
010->111 거리는 2 (파란 경로)

**Page 49**
예시: 모드 벡터 간의 거리
(표 설명: 두 데이터셋의 모드 벡터 간 거리 계산 예시)
모드 벡터-1: (coffee, hot, good)
모드 벡터-2: (coffee, warm, good)
두 모드 벡터 사이의 거리: (0 + 1 + 0 = 1)

**Page 50**
클러스터 중심까지의 거리
◼ k-modes를 위한 거리 함수는 객체 X와 클러스터 l의 중심 Zl 사이의 비유사성 척도를 정의함.
(수식 생략)
여기서 zj는 Zl의 속성 j의 범주형 값,
nl은 클러스터 l의 객체 수,
nrj는 속성 값이 r인 객체의 수임.
◼ 객체의 범주형 값이 클러스터 중심의 값과 같을 때, 그 거리는 클러스터 내 범주형 값의 빈도에 따라 달라짐.

**Page 51**
예시: 클러스터 중심까지의 거리
(그림 설명: 클러스터 내 데이터와 현재 중심, 새로운 객체 간의 거리 계산)
새로운 모드 벡터와 클러스터 중심 사이의 거리:
(1 + (1-1/2) + 1 = 2.5)

**Page 52**
예시: 새로운 중심(모드 벡터) 계산
(그림 설명: 3개의 모드 벡터를 가진 클러스터에서 새로운 중심 계산)
다음 반복을 시작하기 전에 새로운 중심을 계산함.

**Page 53**
K-Modes 목적 함수
◼ 클러스터링 과정은 다음 목적 함수를 최소화함.
(수식 생략)
여기서 U는 n x k 분할 행렬,
Z는 모드 벡터들의 집합,
거리 함수 d(.,.)는 앞서 정의한 바와 같음.

**Page 54**
로드맵: 분할 알고리즘
◼ K-means (매우 빠르게 언급)
◼ K-modes
◼ K-medoids
◼ PAM
◼ CLARA
◼ CLARANS

**Page 55**
참고: “-oid”의 의미
◼ “~와 같은”, “유사함”
◼ centroid (중심점)
◼ medoid (대표 객체)
◼ android (인간의 외모를 가진 로봇)
◼ humanoid (인간의 외모를 가진)

**Page 56**
k-Medoids 클러스터링
◼ k개의 대표 객체, 즉 medoids를 찾음
◼ k-means에서 클러스터 중심은 존재하지 않는 객체임.
◼ k-medoids에서 클러스터 중심은 존재하는 객체임.
◼ 3가지 알고리즘
◼ PAM, CLARA, CLARANS
(그림 설명: k-means와 k-medoids의 차이 비교)

**Page 57**
참고: 데이터 포인트는 벡터임
◼ medoid를 포함한 각 데이터 포인트는 m개 요소의 벡터임.
◼ (예) (0.25, 0.13, 0.32, 0.34) : C언어, 수학, 미술, 국어 시험 점수 스케일링 됨.
◼ 수치 데이터와 범주형 데이터를 포함할 수 있음.
◼ 이 경우, 예를 들어 Gower 거리 등을 사용하여 두 데이터 포인트 간의 거리를 측정함.

**Page 58**
참고: Gower 거리
◼ (링크 생략)
◼ 두 레코드가 얼마나 다른지 측정하는 데 사용할 수 있음.
◼ 레코드는 논리형, 수치형, 범주형 또는 텍스트 데이터의 조합을 포함할 수 있음.
◼ 거리는 항상 0(동일함)과 1(최대로 다름) 사이의 숫자임.

**Page 59**
PAM (Partitioning Around Medoids)
◼ 초기 medoids로 k개의 객체를 임의로 선택함.
◼ 클러스터에 변화가 없을 때까지 반복
◼ 각 객체를 가장 가까운 medoid를 가진 클러스터에 (재)할당함
◼ k-medoids의 품질을 개선함.
(medoid가 아닌 객체 Orandom을 무작위로 선택하고, medoid를 Orandom과 교환했을 때의 총 비용을 계산하여 비용이 감소하면 두 객체를 교환함.)
◼ 작은 데이터셋(예: 5개 클러스터의 100개 객체)에는 효과적이지만, 중간 및 대규모 데이터셋에는 효율적이지 않음.

**Page 60**
PAM 알고리즘 예시
(그림 설명: PAM 알고리즘의 단계별 진행 과정 시각화. 초기 medoid 선택, 할당, 총 비용 계산, 교환 시도 등)
총 비용 = 20
총 비용 = 26
루프 실행: 변화가 없을 때까지
O와 Orandom 교환
품질이 향상되면
교환에 대한 총 비용 계산

**Page 61**
Swapping (교환)
◼ medoid m을 non-medoid 객체 h와 교환함.
◼ medoid m과 non-medoid 객체 h의 각 쌍에 대해, h가 m보다 medoid로서 더 나은지 측정함.

**Page 62**
Swapping Cost (교환 비용)
◼ 목적 함수로 제곱 오차 기준을 사용함.
(여기서 Ci는 클러스터, p는 클러스터 내의 객체, mi는 Ci의 medoid임)
◼ Eh - Em 계산
◼ Em - 현재 총 비용 (medoid m 사용 시)
◼ Eh - non-medoid h를 medoid m과 교환한 후의 총 비용.
◼ 음수 (Eh - Em)는 교환이 클러스터 품질을 향상시킴을 의미함.

**Page 63**
PAM 워크스루 (1/5)
◼ (링크 생략)
◼ 데이터셋 및 목표: 10개 포인트 데이터, k=2
(표: x, y 좌표 데이터)

**Page 64**
PAM 워크스루 (2/5)
◼ 데이터 플로팅
◼ 초기 2개 클러스터(C1 (3,4) 및 C2 (7,4))를 무작위로 선택

**Page 65**
PAM 워크스루 (3/5)
◼ 맨해튼 거리를 사용하여 각 non-medoid와 2개의 medoids 사이의 거리(비유사성)를 계산함.
◼ 포인트 1, 2, 5는 C1으로 이동
◼ 포인트 0, 3, 6, 7, 8은 C2로 이동
◼ 총 비용 (거리, 오차)
= cost C1 + cost C2
= (3+4+4) + (2+2+3+1+1)
= 20

**Page 66**
PAM 워크스루 (4/5)
◼ 하나의 non-medoid (7,3)을 새로운 (잠재적) medoid로 선택하고 총 비용을 다시 계산함.
(그림 설명: 새로운 C2 후보 표시)

**Page 67**
PAM 워크스루 (5/5)
◼ 결과
포인트 1, 2, 5는 C1에 있음
포인트 0, 3, 4, 6, 8은 C2에 있음
총 비용 = cost C1 + cost C2
= (3+4+4) + (3+3+1+2+2)
= 22
◼ 교환 비용
= 새 비용 – 옛 비용
= 22 – 20 = 2 > 0
◼ 교환은 이익이 되지 않으므로; 교환은 이루어지지 않음.

**Page 68**
연습문제
◼ 워크스루에서 사용된 것 외에 다른 2개의 무작위 non-medoids(각 클러스터에서 하나씩)를 사용하여 시도해보시오.
◼ 과정을 보여주시오.

**Page 69**
PAM의 장점과 약점
◼ PAM은 이상치(outliers)가 있을 때 k-means보다 더 강건함(robust). 왜냐하면 medoid는 평균(mean)보다 이상치나 다른 극단적인 값에 덜 영향을 받기 때문임.
◼ PAM은 작은 데이터셋에는 효율적으로 작동하지만 대규모 데이터셋에는 확장이 잘 되지 않음.
◼ 각 반복마다 O(k(n-k)^2), 여기서 n은 데이터 객체 수, k는 클러스터 수.
◼ CLARA와 CLARANS는 medoids를 더 빠르게 찾음.

**Page 70**
연습문제
◼ 이상치는 머신 러닝과 데이터 사이언스에 도전 과제를 제시함.
◼ 이상치가 포함된 작은 예제 데이터셋을 만들고 이상치가 k-Means보다 PAM에 덜 영향을 미치는 방식을 보여주시오.

**Page 71**
CLARA (Clustering Large Applications)
◼ Clara는 데이터셋의 여러 무작위 샘플을 추출하고, 각 샘플에 PAM을 적용하여 최상의 클러스터링을 출력으로 제공함.
◼ 전체 데이터셋에 대한 PAM의 철저한 계산을 피함.
◼ PAM보다 더 큰 데이터셋을 처리할 수 있음 (예: 10개 클러스터의 1,000개 객체).
◼ 효율성과 효과성은 샘플링에 달려 있음.
◼ CLARA는 S+와 같은 통계 분석 패키지에 내장되어 있음.

**Page 72**
CLARA 알고리즘
◼ mincost를 큰 숫자로 설정;
◼ q번 반복 // q개의 샘플 추출
◼ 데이터셋 D에서 s개의 객체를 무작위로 추출하여 샘플 S 생성
◼ PAM 알고리즘을 적용하여 S에서 medoids 집합 M 생성
◼ cost(M,D) 계산
◼ if cost(M, D) < mincost
{mincost = cost(M, D);
bestset = M;}
◼ 반복 종료;
◼ bestset 반환;

**Page 73**
CLARA의 약점
◼ 효율성은 샘플 크기, 샘플 수, 샘플 품질에 달려 있음.
◼ 샘플의 좋은 클러스터링이 샘플이 편향된 경우 전체 데이터셋의 좋은 클러스터링을 나타내지 않을 수 있음.
◼ 어떤 객체가 최고의 k-medoids 중 하나이지만 샘플링 중에 선택되지 않으면, CLARA는 결코 최고의 클러스터링을 찾지 못할 것임.

**Page 74**
CLARANS (Clustering Algorithm based on Randomized Search)
◼ (링크 생략)
◼ Raymond Ng 및 Jiawei Han (2002)
◼ Python 라이브러리
◼ from pyclustering.cluster.clarans import clarans;

**Page 75**
핵심 개념
◼ CLARA와 마찬가지로 전체 데이터셋 대신 샘플을 사용함.
◼ 각 샘플에 대해 많은 노드를 생성함. 여기서 각 노드는 k개의 medoids 집합임.
(예: 아래 다이어그램의 2개의 빨간 다이아몬드)
◼ medoid를 다른 medoid와 교환하여 총 비용을 낮출 기회를 찾기 위해 스마트한 방식으로 노드를 검색함.

**Page 76**
정의: 인접 노드/이웃
◼ 두 노드가 하나의 medoid만 다르면 인접(이웃)함.
◼ 모든 노드는 k(n-k)개의 인접 노드를 가짐; n-k개의 이웃, k개의 medoids 각각에 대해 하나씩. n은 (잠재적) medoids의 총 수임.
(그림 설명: 노드 간의 이웃 관계 설명)

**Page 77**
CLARANS 알고리즘 개요
◼ 1단계: k개의 데이터 포인트를 초기 k-medoids로 선택함.
k-medoids 주위에 k개의 클러스터를 형성함.
◼ 2단계: 무작위 medoid x를 선택함 (현재 medoid라고 함).
다음 검색을 max_neighbors 횟수만큼 반복함.
◼ k-medoids 중 하나가 아닌 현재 medoid의 무작위 이웃을 선택함.
◼ 그것이 현재 medoid를 대체해야 하는지 결정함.
◼ 이웃이 총 비용을 낮추면, 그것을 새로운 현재 medoid로 만들고 무작위 검색 루프를 다시 시작함;
◼ 그렇지 않으면, 현재 노드가 지역 최적해로 남고; 검색을 계속함.
◼ 다른 지역 최적해를 찾기 위해 무작위로 선택된 다른 medoid로 다시 시작함.
이것을 L번 반복함.
◼ L개의 지역 최적 노드가 발견되면, 그중 가장 좋은 지역 최적 노드를 반환함.

**Page 78**
(CLARANS 알고리즘의 2단계) (더 정밀하게)
◼ mincost를 큰 숫자로 설정;
◼ i=1부터 numlocal까지 반복 // numlocal개의 지역 최적해 찾기
◼ 그래프에서 현재 노드 C로 노드를 무작위 선택;
◼ j = 1; // 이웃 수
◼ 반복
C의 이웃 N을 무작위 선택;
if Cost(N,D)<Cost(C,D)
N을 현재 노드 C로 할당;
j = 1;
else j++;
endif;
◼ j > maxNeighbors일 때까지
◼ 해당되는 경우 mincost를 Cost(C,D)와 bestnode로 업데이트;
◼ 반복 종료
◼ bestnode 반환;
(말풍선: 두 노드의 비용 차이를 계산함)

**Page 79**
Clarans 2단계의 흐름도
(흐름도 설명: CLARANS 알고리즘의 로직 흐름 시각화)

**Page 80**
CLARANS 대 PAM/CLARA
◼ 대 PAM
◼ 대규모 및 중간 규모 데이터셋의 경우, CLARANS가 PAM보다 훨씬 효율적임.
◼ 소규모 데이터셋의 경우, CLARANS가 PAM보다 성능이 훨씬 뛰어남. (* CLARANS가 PAM보다 덜 무작위적으로 교환 medoids를 선택하기 때문)
◼ 대 CLARA
◼ CLARANS는 항상 CLARA가 찾은 것보다 더 나은 품질의 클러스터링을 찾을 수 있음.
◼ CLARANS는 CLARA보다 훨씬 더 많은 시간을 사용할 수 있음.
◼ 사용된 시간이 같을 때, CLARANS가 여전히 CLARA보다 더 나음.

**Page 81**
(그래프 설명: 런타임 비교 그래프)
n=80일 때, CLARANS는 PAM보다 5배 빠르면서 클러스터 품질은 동일함.

**Page 82**
모듈 종료

**Page 83**
머신 러닝:
클러스터링 알고리즘 –
기댓값 최대화(Expectation-Maximization)
(가우시안 혼합 모델, Gaussian Mixture Model)
Ok-Ran Jeong
2025년 가을

**Page 84**
감사의 말
(참고 자료 링크 생략)

**Page 85**
K-Means (간단히 다시 보기)
◼ k-means 알고리즘을 사용하여 다음 데이터 포인트들을 클러스터링하시오.

**Page 86**
클러스터의 구형 모양
◼ K-means 클러스터링은 각 클러스터에 대해 구형 모양을 결과로 함. (예: 아래의 3개 구형 클러스터)
◼ 원 위의 모든 점은 원의 중심에서 같은 거리에 있음.

**Page 87**
구형 모양과 하드 클러스터링
◼ 데이터에 대한 구형 가정(클러스터 중심까지의 거리)은 하드 클러스터링으로 이어짐.
◼ (즉) 데이터 포인트 x는 서로 다른 확률을 가진 두 개 이상의 클러스터가 아니라 오직 하나의 클러스터에만 속함.

**Page 88**
EM 클러스터링
◼ 높은 수준에서 k-means와 매우 유사함
◼ 포인트 할당과 클러스터 중심 재계산 사이를 반복함.
◼ k-means와 EM 클러스터링의 두 가지 주요 차이점:
◼ EM은 타원형 클러스터를 가정함 (구형 대신).
◼ EM은 “소프트” 클러스터링 알고리즘임; 데이터를 특정 확률로 클러스터에 할당함.

**Page 89**
예시
이 데이터 포인트들을 클러스터링하시오.

**Page 90**
K-Means: 하드, 구형 클러스터

**Page 91**
EM 클러스터링: 소프트, 타원형 클러스터
p(red) = 0.8
p(blue) = 0.2
p(red) = 0.9
p(blue) = 0.1

**Page 92**
EM 클러스터링 알고리즘
◼ k개 클러스터에 대한 초기 클러스터 중심으로 시작함.
◼ 수렴할 때까지 반복
◼ 각 클러스터에 포인트를 소프트 할당 (E 단계)
각 데이터 포인트가 각 클러스터에 속할 확률 θc에 기초함
◼ 클러스터 중심 재계산 (M 단계)
θc에 대한 새로운 클러스터 매개변수 계산
(즉, 현재 소프트 클러스터링이 주어졌을 때 최대 우도 클러스터 중심)
즉, 각 클러스터에 대한 가우시안 방정식(52, 54페이지)에 대입하여 p(θc| x)를 계산함

**Page 93**
EM 클러스터링 시각화
◼ k(=2) 초기 클러스터로 시작
(빨간색과 파란색)

**Page 94**
1-1단계: 초기 클러스터에 데이터 포인트 소프트 할당 (E 단계)
참고: 이것은 소프트(확률적) 할당임

**Page 95**
1-2단계: 클러스터 중심 재계산 (M 단계)
클러스터 중심은 포인트로부터 가중치가 적용된 기여를 받음
새로운 클러스터

**Page 96**
k단계: 반복 (2, 5, 20회)

**Page 97**
EM 클러스터링: 장점과 단점
◼ 장점
◼ 소프트 클러스터링은 길게 늘어진 분포의 포인트들에 대해 클러스터링을 가능하게 함 (어느 정도 밀도 기반 클러스터링과 유사함)
◼ 단점
◼ 매개변수 계산에 시간이 오래 걸릴 수 있음
◼ k를 결정하기 어려움
◼ 전역 최소값(global minima)보다는 지역 최소값(local minima)을 취하게 될 수 있음

**Page 98**
EM (가우시안 혼합 모델) 클러스터링에 대한 Scikit-Learn 지원 (1/3)
(링크 생략)
(코드 생략 - 라이브러리 임포트 및 데이터 생성)

**Page 99**
EM (가우시안 혼합 모델) 클러스터링에 대한 Scikit Learn 지원 (2/3)
# GMM 모델 생성 및 훈련
(코드 생략)
# 데이터 클러스터링
(코드 생략)
# 클러스터 플로팅
(코드 생략)

**Page 100**
EM (가우시안 혼합 모델) 클러스터링에 대한 Scikit Learn 지원 (3/3)
# 모델이 수렴한 후, 가중치, 평균, 공분산을 해결함; 이를 출력할 수 있음.
(코드 생략)

**Page 101**
EM 알고리즘

**Page 102**
소개
◼ 기댓값 최대화(Expectation-Maximization) 알고리즘은 잠재(숨겨진, 관찰되지 않은) 변수가 있을 때 모델 매개변수(예: 평균, 표준편차)의 최대 우도 추정(MLE)을 수행하는 방법임.
◼ 구성 요소:
◼ (기댓값/추정 단계 또는 E 단계) 모델의 잠재 변수에 대한 값을 추정함,
◼ (최대화 단계 또는 M 단계) 모델의 추정된 매개변수를 최적화함,
◼ 수렴할 때까지 이 두 단계를 반복함.

**Page 103**
참고
◼ 샘플 데이터셋과 그 데이터셋을 생성했을 수 있는 매개변수(예: 평균, STD)로 표현되는 분포 집합이 주어졌을 때, 우도(likelihood)는 각 매개변수에 주어진 샘플을 관찰할 확률(또는 확률 밀도)을 연관시키는 함수임.
◼ (최대) 우도 추정에 대한 직관적인 설명은 부록을 참조하시오.

**Page 104**
기댓값 최대화에 대한 직관 (1/2)
◼ 주어진 것: 앞면이 나올 확률이 각각 'p'와 'q'인 두 동전 A와 B.
◼ 두 동전 중 하나를 무작위로 선택하여 던짐. 이를 N번 반복함.
◼ 다음과 같은 16번의 동전 던지기 시퀀스가 관찰됨:
(시퀀스 생략)
(HA는 동전 A로 앞면; TB는 동전 B로 뒷면.)
◼ 과제: 관찰된 데이터로부터 'p'와 'q'의 값을 추정하시오.

**Page 105**
기댓값 최대화에 대한 직관 (2/2)
◼ p와 q에 대한 MLE (최대 우도 추정)
◼ p = 동전 A로 나온 앞면 수 / 동전 A로 던진 총 횟수 (= 5/9)
◼ q = 동전 B로 나온 앞면 수 / 동전 B로 던진 총 횟수 (= 4/7)
◼ 쉬움. 그렇다면 문제는 무엇인가?

**Page 106**
숨겨진 변수 문제
◼ 동전의 라벨이 숨겨져 있어서 어떤 던지기에 어떤 동전이 사용되었는지 모른다면 어떨까.
◼ 동전이 선택될 확률이 동일하다고 가정할 때, 매개변수 ‘p’와 ‘q’를 추정할 수 있는가?

**Page 107**
해결책
◼ EM 알고리즘을 채택하여 문제를 반복적으로 해결할 수 있음.
◼ 각 반복마다 2단계가 있음:
◼ E (기댓값) 단계
◼ M (최대화) 단계.

**Page 108**
기댓값(Expectation) 단계
◼ p와 q 값에 대한 무작위 초기 추측으로 시작함.
◼ 동전 던지기가 특정 동전에서 나왔다고 말하는 대신, 동전 A에서 확률 ‘x’로, 동전 B에서 확률 ‘1-x’로 나올 수 있다고 말할 것임.
◼ 각 동전에서 나올 것으로 예상되는 앞면과 뒷면의 수를 계산함.

**Page 109**
최대화(Maximization) 단계
◼ ‘E’ 단계에서 얻은 각 동전의 예상 앞면 및 뒷면 수의 로그 우도(log-likelihood)를 계산함 (MLE 계산과 유사함).
◼ 알 수 없는 매개변수에 대해 로그 우도를 최대화하고 각 동전에 대해 로그 우도가 최대화되는 p와 q의 새로운 값을 재추정함.

**Page 110**
반복(Iteration)
◼ M 단계에서 계산된 새로운 p와 q 값으로 E 단계를 반복함.
◼ p와 q 값이 수렴할 때까지 E 단계와 M 단계를 반복함.

**Page 111**
워크스루 예제
◼ 2개의 (라벨 없는) 동전을 사용하여 5번의 동전 던지기 실험을 했다고 가정함.
◼ 각 실험에서 2개의 동전으로 10번 던짐.
(1) H T T T H H T H T H
(2) H H H H T H H H H H
(3) H T H H H H H T H H
(4) H T H T T T H H T T
(5) T H H H T H H H T H

**Page 112**
E 단계
◼ 알 수 없는 매개변수 p=0.6 및 q=0.5에 대한 무작위 초기 추측으로 시작함.
◼ * 기억할 것: "앞면이 나올 확률이 각각 'p'와 'q'인 두 동전 A와 B가 주어짐.

**Page 113**
M 단계 (1/5)
◼ p와 q를 재계산하기 위해 첫 번째 실험 -- 관찰 S부터 시작해 보자.
◼ 관찰 S가 동전 A에서 나왔을 가능성, 즉 P(A|S)를 추정하고 싶음.
◼ 베이즈 정리(Bayes' Theorem) 사용
P(A|S) = P(S|A) * P(A) / P(S)
◼ 3개의 항 각각을 계산해 보자.

**Page 114**
M 단계 (2/5)
◼ P(A)는 동전 A를 선택할 확률임; 각 동전이 선택될 확률이 동일하므로 0.5임 (P(B)도 마찬가지).
◼ P(S|A)는 동전 A에서 나왔다고 가정할 때 관찰 S의 확률임.
◼ 이항 분포를 사용하여 (S에 5개의 H와 5개의 T가 있으므로) 다음을 추론함
◼ P(S|A) = p^5 * (1-p)^5, 그리고 유사하게
◼ P(S|B) = q^5 * (1-q)^5

**Page 115**
M 단계 (3/5)
◼ P(S)는 관찰의 확률임. 관찰은 동전 A 또는 동전 B 또는 둘 다에서 나올 수 있음. 따라서
◼ P(S) = P(S,A) + P(S,B) = P(S|A) * P(A) + P(S|B) * P(B)
◼ 따라서, 다음을 얻음
◼ P(A|S) = P(S|A) * P(A) / P(S) =
P(S|A) * P(A) / (P(S|A) * P(A) + P(S|B) * P(B))
= p^5*(1-p)^5 * 0.5 /
(p^5*(1-p)^5*0.5 + q^5*(1-q)^5*0.5)
◼ 초기 추측값 p=0.6 및 q=0.5를 대입하면,
◼ P(A|S) = 0.45, 그리고
◼ P(B|S) = 1-P(A|S) = 0.55.

**Page 116**
M 단계 (4/5)
◼ 따라서 관찰 1이 주어졌을 때, 동전 A에서 나왔을 확률은 0.45이고 동전 B에서 나왔을 확률은 0.55임.
◼ 따라서 동전 A에서 나올 것으로 예상되는 앞면 수 = 5*0.45, 뒷면 수 = 5*0.45 (관찰 1에 5 H와 5 T가 있으므로)
◼ 유사하게, 동전 B에서 나올 것으로 예상되는 앞면 수 = 5*0.55, 뒷면 수 = 5*0.55.
◼ 다른 4개의 실험에 대해 동일한 기댓값 단계를 반복하면, 동전 A에서 예상되는 총 앞면 수 = 21.3, 뒷면 수 = 8.6을 얻음.
◼ 유사하게, 동전 B에 대해 예상되는 총 앞면 수 = 11.7, 뒷면 수 = 8.4

**Page 117**
M 단계 (5/5)
◼ 알 수 없는 매개변수 p와 q에 대한 새로운 추정치는 다음과 같음
◼ p = 21.3 / (21.3+8.6) = 0.71
◼ q = 11.7 / (11.7+8.4) = 0.58

**Page 118**
‘E’ & ‘M’ 단계 반복
◼ p와 q 값이 수렴할 때까지 위의 E 및 M 단계를 반복함.
◼ 이 예제에서 p와 q 값은 약 10단계 만에 최종 값 p=0.8 및 q=0.52로 수렴함.
◼ * “수렴”은 이전 반복과의 값 차이가 미미해짐을 의미함.

**Page 119**
그림 요약
(그림 설명: EM 알고리즘의 반복 과정을 통한 매개변수 수렴 과정 시각화)

**Page 120**
필기 과제: (모든 세부 과정을 보여주어야 함.)
◼ 2개의 동전을 사용하여 3번의 동전 던지기 실험을 했다고 가정함.
◼ 각 실험에서 2개의 동전으로 10번 던짐.
(1) H T T T H H T H T H
(2) H H H H T H H H H H
(3) H T H H H H H T H H
◼ 알 수 없는 매개변수 p=0.1 및 q=0.9에 대한 초기 추측으로 시작함.
◼ 매개변수가 수렴할 때까지 EM 반복의 각 E 및 M 단계를 손으로 계산하시오.

**Page 121**
클러스터링을 위한 동기 부여 예제 (1/2)
◼ 2개의 서로 다른 그룹(클러스터)에서 샘플링된 데이터가 있다고 가정함: 빨간색과 파란색.
◼ 각 그룹을 특징짓는 매개변수:
◼ 빨간색 그룹의 평균 – 약 3
◼ 파란색 그룹의 평균 – 약 7
◼ 쉬운 과제
◼ 데이터가 주어졌을 때, 해당 데이터를 가장 잘 설명하는 매개변수(µ 및 σ) 값을 계산하시오.

**Page 122**
클러스터링을 위한 동기 부여 예제 (2/2)
◼ 데이터가 2개의 그룹에서 샘플링되었다는 것은 알지만, 어떤 데이터가 어떤 그룹에서 샘플링되었는지는 모른다고 가정함. (* 숨겨진 변수 *)
◼ 샘플링된 데이터에 가장 잘 맞는 2개 그룹의 평균을 여전히 추정할 수 있는가?
◼ 예, EM을 사용하면 가능함.

**Page 123**
일러스트레이션:
예제 데이터셋
◼ 다음을 설정하여 두 분포로 구성된 데이터셋을 생성함
◼ 빨간색 평균 = 3, 파란색 평균 = 7
◼ 빨간색 STD = 0.8, 파란색 STD = 2
◼ 하지만 색상은 숨길 것임.

**Page 124**
1단계
◼ 각 그룹에 대한 평균과 STD를 추측함:
◼ 빨간색 평균 = 1.1, 파란색 평균 = 9
◼ 빨간색 STD = 2, 파란색 STD = 1.7
◼ 결과: 두 개의 정규 분포 곡선 (즉, 2개의 초기 소프트 클러스터)

**Page 125**
2단계
◼ 1단계 추측을 기반으로 각 데이터 포인트에 대한 (2개 그룹 각각에 속할) 우도(likelihood) 값을 계산함.
◼ 이는 1단계 추측을 기반으로 각 데이터 포인트를 가우시안 방정식(즉, 정규 분포의 확률 밀도 함수)에 대입하여 수행됨.
◼ (예) 1.761에 있는 데이터 포인트(이전 페이지에서 강조됨)의 경우, 빨간색의 우도는 0.189이고 파란색의 우도는 0.00003임.

**Page 126**
3단계
◼ 각 데이터 포인트에 대해 두 우도 값을 가중치로 변환하여 합이 1이 되도록 함:
◼ likelihood_total = likelihood_of_red + likelihood_of_blue
◼ red_weight = likelihood_of_red / likelihood_total
◼ blue_weight = likelihood_of_blue / likelihood_total

**Page 127**
4단계
◼ 현재 추정치와 새로 계산된 가중치를 기반으로 각 그룹의 평균과 STD에 대한 새로운 추정치를 계산함.

**Page 128**
5단계: 2-4단계 반복
◼ 계산의 처음 5회 반복 결과
◼ (더 최근의 반복은 더 진한 색으로 표시됨.)
◼ 평균은 이미 어떤 값으로 수렴하고 있으며, 곡선의 모양(STD에 의해 결정됨)은 안정화되고 있음.

**Page 129**
결과 (즉, k=2에 대한 EM 클러스터링)
◼ 20회 반복 후의 결과 !!
◼ | EM 추측 | 실제 | 차이
----------+----------+--------+-------
red mean | 2.910 | 2.802 | 0.108
red std | 0.854 | 0.871 | -0.017
blue mean | 6.838 | 6.932 | -0.094
blue std | 2.227 | 2.195 | 0.032

**Page 130**
가우시안 혼합 모델 (Gaussian Mixture Model)

**Page 131**
소개
◼ GMM은 데이터 포인트의 k개 가우시안 분포 혼합을 사용하는 확률적 클러스터링 모델임
◼ k개 가우시안 분포는 정규(종 모양) 분포의 k개 클러스터를 의미함.
◼ 즉, 모델은 데이터 포인트의 각 클러스터를 매개변수 u와 σ를 가진 정규 분포로 간주함.
◼ 정규 분포의 k개 클러스터는 겹칠 수 있음 – (소프트 클러스터링의 기초).
◼ 문제 중 하나는 입력 포인트 x를 k개의 정규 분포 각각에서 찾을 확률을 결정하는 것임.

**Page 132**
예시: 2-클래스 (k=2) 가우시안 혼합 모델
(표: 데이터셋 A, B 클래스 및 값)
데이터셋에 대한 2개의 가우시안, 각각 다른 μ와 σ를 가짐
X가 A와 B에 속할 확률 찾기
겹침(overlap)

**Page 133**
형식적 기초

**Page 134**
1차원 가우시안 (1/2)
◼ 1차원 가우시안 분포를 설명하는 함수
(수식 생략)
◼ 이 함수는 주어진 평균 μ와 STD σ (또는 분산 σ^2)를 가진 정규 분포에서 입력 데이터 포인트 x를 찾을 확률을 제공함.

**Page 135**
1차원 가우시안 (2/2)
◼ 가장 높은 확률은 평균에 위치하며, 평균에서 멀어질수록 확률은 0에 가까워짐.
◼ 이것은 확률 분포이므로 종 모양 곡선 아래의 모든 값의 합(즉, 적분)은 1과 같음.

**Page 136**
다변량 (n차원) 가우시안 (1/2)
◼ 다변량을 설명하는 함수
(수식 생략)
공분산은 이 등고선의 모양을 결정함
각 클러스터의 평균(즉, 중심)과 공분산 행렬(즉, 임의의 방향으로 얼마나 퍼져 있는지)을 학습함.

**Page 137**
다변량 (n차원) 가우시안 (2/2)
◼ 입력 데이터 포인트는 이제 스칼라 대신 벡터임.
◼ 평균도 벡터임.
◼ 분산은 공분산 행렬 Σ로 변경됨.
◼ 공분산 행렬은 각 차원의 분산과 입력 간의 관계(즉, x가 변경되면 y는 어떻게 변하는 경향이 있는가?)를 보여줌.

**Page 138**
GMM과 EM (1/3)
◼ 가우시안 혼합 모델의 목표는 데이터에 가장 잘 맞는 평균 μ와 STD σ (즉, 가우시안의 매개변수)를 찾는 것임.
◼ 이를 위해, 이 데이터를 찾을 우도(likelihood)를 최대화하는 매개변수를 찾아야 함.
◼ 다시 말해, 각 포인트를 가우시안 혼합에 의해 생성된 것으로 간주하고 그 확률을 계산함.

**Page 139**
GMM과 EM (2/3)
◼ 다음 공식을 사용할 수 있음:
(수식 생략)
◼ 첫 번째 방정식은 특정 데이터 포인트 x가 k개 가우시안의 선형 결합임을 말해줌.
◼ 각 가우시안에 Φj로 가중치를 부여하며, 이는 해당 가우시안의 강도를 나타냄.
◼ 두 번째 방정식은 가중치에 대한 제약 조건임: 모두 합하여 1이 되어야 함.
(참고: 54페이지의 다변량 가우시안 함수)

**Page 140**
GMM과 EM (3/3)
◼ 세 가지 매개변수를 계산해야 함:
◼ 각 가우시안에 대한 가중치 Φj
◼ 각 가우시안의 평균 μj, 그리고
◼ 각 가우시안의 공분산 Σj.
◼ 가중치, 평균, 공분산을 어떻게 추정할 수 있는가?
◼ 바로 여기서 기댓값 최대화(Expectation Maximization) 알고리즘이 등장함!

**Page 141**
모듈 종료

**Page 142**
부록

**Page 143**
최대 우도 추정 (Maximum Likelihood Estimation)
◼ (링크 생략)
◼ 최대 우도 추정은 모델의 매개변수(예: 평균, STD) 값을 결정하는 방법임.
◼ 매개변수 값은 모델에 의해 설명되는 프로세스가 실제로 관찰된 데이터를 생성했을 우도(likelihood)를 최대화하도록 찾아짐.

**Page 144**
일러스트레이션 (1/4)
◼ 아래와 같이 10개의 데이터 포인트를 관찰했다고 가정해 보자.
◼ 예를 들어, 각 데이터 포인트는 사람이 작업을 완료하는 데 걸리는 시간을 나타낼 수 있음.
(그림 설명: y=0 축 위의 점들)

**Page 145**
일러스트레이션 (2/4)
◼ 데이터를 생성하는 과정을 가장 잘 설명할 수 있는 모델을 알고 싶음.
◼ 이 데이터에 대해 두 개의 매개변수(평균 μ 및 STD σ)를 가진 가우시안(정규) 분포를 가정할 것임.

**Page 146**
일러스트레이션 (3/4)
◼ 이 매개변수들의 서로 다른 값은 서로 다른 곡선을 초래함.
◼ 우리가 관찰한 데이터 포인트를 생성하는 데 가장 책임이 있을 가능성이 높은 곡선이 무엇인지 알고 싶음.
◼ 최대 우도 추정은 데이터에 가장 잘 맞는 곡선을 초래하는 μ와 σ 값을 찾는 방법임.

**Page 147**
일러스트레이션 (4/4)
◼ 데이터가 생성된 실제 분포는 (μ 10, σ 2.25)였으며, 이는 아래 그림의 파란색 곡선임.

**Page 148**
머신 러닝:
클러스터링 알고리즘 –
DBSCAN
Ok-Ran Jeong
2025년 가을

**Page 149**
감사의 말
(참고 자료 링크 생략)

**Page 150**
클러스터링 과제
◼ K-means와 EM-클러스터링은 클러스터링에서 가장 인기 있는 알고리즘임.
◼ 그러나 모든 클러스터링 작업을 처리할 수는 없음: 예: 비-가우시안 데이터
◼ 밀도 기반 클러스터링, 스펙트럼 클러스터링이 이러한 유형의 문제를 해결함.
◼ 연결된 구성 요소 클러스터
◼ (링크 생략)

**Page 151**
비-가우시안 데이터
문제점:
K-Means와 EM은
2개의 연결된 원을 클러스터링할 수 없음.

**Page 152**
해결책: 스펙트럼 클러스터링 (1/2)
(그림 설명: 스펙트럼 클러스터링을 통한 비정형 데이터 클러스터링 예시)

**Page 153**
스펙트럼 클러스터링 (2/2)
(그림 설명: 글자 모양 데이터 클러스터링 예시)

**Page 154**
밀도 기반 클러스터링 방법
◼ 밀도(지역적 클러스터 기준)에 기반한 클러스터링, 예: 밀도-연결된 점 또는 밀도 함수
◼ 주요 특징:
◼ 임의의 모양의 클러스터 발견
◼ 노이즈 처리
◼ 데이터셋을 한 번만 스캔하면 됨
◼ 하지만 밀도 매개변수가 필요함
◼ 여러 방법들
◼ DBSCAN
◼ DENCLUE
◼ OPTICS
◼ CLIQUE

**Page 155**
클러스터 = 밀집된 객체 영역
◼ 클러스터는 데이터 공간에서 밀집된 객체 영역이며, 낮은 객체 밀도 영역으로 분리됨.
◼ 하나의 클러스터에 있는 점들의 집합은 공간적으로 연결되어 있음.

**Page 156**
두 가지 매개변수
◼ 클러스터 내의 어떤 점에 대해서도, 그 점 주변의 지역적 점 밀도가 어떤 임계값을 초과해야 함.
◼ 점 p에서의 지역적 점 밀도는 두 가지 매개변수로 정의됨
◼ ε : 점 p의 이웃 반경:
Nε (p) := {데이터셋 D의 q | dist(p, q) ≤ ε}
◼ MinPts : 주어진 이웃 N(p) 내의 최소 점 개수

**Page 157**
ε-Neighborhood (ε-이웃)
◼ ε-Neighborhood : 객체로부터 반경 ε 내의 객체들.
(수식 생략)
◼ “고밀도” : 객체의 ε-Neighborhood가 적어도 MinPts 개의 객체를 포함함.
(그림 설명: p의 밀도는 "높음" (MinPts = 4), q의 밀도는 "낮음" (MinPts = 3))

**Page 158**
DBSCAN -- 1996
Martin Ester, Hans-Peter Kriegel, Jiirg Sander, Xiaowei Xu
뮌헨 대학교, 독일

**Page 159**
DBSCAN
◼ DBSCAN = Density-Based Spatial Clustering of Applications with Noise (노이즈가 있는 애플리케이션의 밀도 기반 공간 클러스터링)
◼ 밀도 = ε-이웃 내의 점 개수.
◼ 어떤 점이 ε-이웃 내에 MinPts 개 이상의 객체를 가지고 있으면 핵심 점(core point)임. 이들은 클러스터 내부에 있는 점들임.
◼ 경계 점(border point)은 Eps 내에 MinPts 개 미만의 객체를 가지고 있지만, 핵심 점의 이웃에 있는 점임.
◼ 노이즈 점(noise point)은 핵심 점도 아니고 경계 점도 아닌 점임.

**Page 160**
핵심, 경계, 및 노이즈 점
(그림 설명: Core Point, Border Point, Noise Point의 시각적 예시. MinPts = 4)

**Page 161**
예시
◼ M, P, O, R은 핵심 점임. 각각 적어도 3개의 점을 포함하는 ε-이웃에 있기 때문임.
MinPts = 3
Eps = 원의 반경

**Page 162**
클러스터 형성
◼ 클러스터는 핵심 점에서 시작하여 “도달 가능한” 경계 점을 포함하도록 확장됨.
◼ 비-핵심 점은 두 점이 Eps 내에 있으면 핵심 점으로부터 도달 가능함.

**Page 163**
연습문제
◼ MinPts = 4라고 가정.
◼ 데이터 포인트 A, B, C, N은 어떤 유형인가?
◼ 어떤 데이터 포인트들이 클러스터에 포함되는가?

**Page 164**
정답
◼ 점 A와 다른 빨간 점들은 핵심 점임. ε 반경 내의 주변 영역이 적어도 4개의 점(자신 포함)을 포함하기 때문임.
◼ 이들은 서로 도달 가능하므로 하나의 단일 클러스터를 형성함.
◼ 점 B와 C는 경계 점이지만, A로부터 (다른 핵심 점들을 통해) 도달 가능하므로 핵심 점들이 있는 클러스터에 속함.
◼ 점 N은 노이즈 점(이상치)임; 핵심 점도 아니고 직접 도달 가능하지도 않음.

**Page 165**
DBSCAN 추상 알고리즘 (1/2)
◼ 임의의 데이터 포인트 p를 첫 번째 점으로 선택함.
◼ p를 방문함으로 표시함.
◼ 이웃에 있는 모든 점(점으로부터 eps 거리까지)을 추출하고, 이를 집합 nb라고 함.
◼ if len(nb) >= minPts,
a. p를 새 클러스터의 첫 번째 점으로 고려함 (그리고 클러스터에 라벨을 붙임)
b. eps 거리 내의 모든 점(nb의 멤버)을 이 클러스터의 다른 점으로 고려함.
c. nb의 모든 점에 대해 단계 b를 반복함
else p를 노이즈로 라벨링함
◼ 전체 데이터셋이 라벨링될 때까지 위의 단계를 반복함.

**Page 166**
DBSCAN 추상 알고리즘 (2/2)
◼ 알고리즘이 실행된 후, 이상적으로는 데이터셋이 여러 클러스터로 분리되고, 어떤 클러스터에도 속하지 않는 일부 점들은 노이즈로 라벨링되어야 함.

**Page 167**
DBSCAN의 복잡도
◼ 시간 복잡도: O(n^2) — 각 점에 대해 핵심 점인지 확인해야 함
◼ 효율적인 데이터 구조를 사용하여 저차원 공간에서 O(n*log(n))으로 줄일 수 있음
◼ n은 클러스터링할 객체의 수임.
◼ 공간 복잡도: O(n).

**Page 168**
EPS와 MinPts 결정을 돕는 도구
◼ 클러스터 내의 점들은 k번째 가장 가까운 이웃들이 대략 같은 거리에 있음; 반면 노이즈 점들은 k번째 가장 가까운 이웃이 더 먼 거리에 있음
◼ 따라서, 모든 점의 k번째 가장 가까운 이웃까지의 정렬된 거리를 그래프로 그림
◼ 아래에서, k=4 MinPts에 대해, eps를 선택함 (=5? 10?)
(그림 설명: 정렬된 거리 그래프에서 급격히 변하는 지점을 EPS로 선택)

**Page 169**
예시
원본 포인트들
점 유형: 핵심(core), 경계(border), 이상치(outliers)
ε = 10, MinPts = 4

**Page 170**
DBSCAN의 장점
◼ 노이즈에 강함
◼ 다양한 모양과 크기의 클러스터를 처리할 수 있음

**Page 171**
DBSCAN이 잘 작동하지 않는 경우
◼ 데이터가 다양한 밀도를 가지거나 고차원일 때

**Page 172**
DBSCAN: 매개변수에 민감함
(그림 설명: 매개변수 변화에 따른 DBSCAN 결과의 차이)

**Page 173**
DBSCAN 요약
◼ 장점
◼ 클러스터가 임의의 모양과 크기를 가질 수 있음.
◼ 클러스터 수가 자동으로 결정됨.
◼ 주변 노이즈로부터 클러스터를 분리할 수 있음.
◼ 공간 인덱스 구조에 의해 지원될 수 있음.
◼ 단점
◼ 입력 매개변수를 결정하기 어려울 수 있음.
◼ 일부 상황에서 입력 매개변수 설정에 매우 민감함.

**Page 174**
DBSCAN에 대한 Scikit-Learn 지원 (1/6): 모델 임포트
◼ (링크 생략)
# 필요한 라이브러리 임포트
(코드 생략)

**Page 175**
DBSCAN에 대한 Scikit-Learn 지원 (2/6): 데이터 로드 및 전처리
# 데이터 로드
(코드 생략)
# 데이터에서 CUST_ID 컬럼 제거
(코드 생략)
# 결측값 처리
(코드 생략)

**Page 176**
DBSCAN에 대한 Scikit-Learn 지원 (3/6): 데이터 전처리
# 데이터 전처리
# 모든 속성을 비교 가능한 수준으로 만들기 위해 데이터 스케일링
(코드 생략)
# 데이터가 대략적으로 가우시안 분포를 따르도록 정규화
(코드 생략)
# numpy 배열을 pandas DataFrame으로 변환
(코드 생략)

**Page 177**
DBSCAN에 대한 Scikit-Learn 지원 (4/6): 데이터 차원 축소
# 시각화 가능하도록 데이터의 차원 축소
(코드 생략)

**Page 178**
DBSCAN에 대한 Scikit-Learn 지원 (5/6): 모델 구축
# 클러스터링 모델 구축
# 각 데이터 포인트에 할당된 모든 클러스터 레이블의 Numpy 배열
(코드 생략)

**Page 179**
결과 시각화
◼ (* 코드는 참고 자료에 있음 *)
(그림 설명: 클러스터링 결과 산점도)

**Page 180**
모듈 종료

**Page 181**
머신 러닝
추천 시스템 (Recommender Systems)
Ok-Ran Jeong
2025년 가을

**Page 182**
감사의 말: (1/2)
추천 시스템 소개
(참고 자료 링크 생략)

**Page 183**
감사의 말: (2/2)
행렬 분해 (Matrix Factorization)
(참고 자료 링크 생략)

**Page 184**
추천 시스템
◼ 추천 시스템(recommendation systems), 추천 엔진(recommendation engines)이라고도 함.
◼ 추천 시스템은 사용자에게 더 나은 경험을 제공하는 개인화된 웹 기반 시스템의 한 형태임.

**Page 185**
추천의 가치
◼ Netflix
◼ 시청된 영화의 2/3가 추천된 것임
◼ Google News
◼ 추천이 클릭률을 38% 더 발생시킴
◼ Amazon
◼ 매출의 35%가 추천에서 발생함
◼ ChoiceStream
◼ 사람들이 좋아하는 것을 찾으면 28%가 음악을 더 구매할 것임.

**Page 186**
추천 프로세스
(그림 설명: 아이템, 사용자, 피드백 -> 학습 과정 -> 모델/클러스터 -> 결정 과정 -> 추천 아이템. 컨텍스트 정보 포함)
오프라인 / 온라인

**Page 187**
추천에 사용되는 정보 소스
◼ 명시적 정보
◼ 숫자 평점 (예: 5점, 3점 척도 등)
◼ 이진 평점 (좋아요/싫어요)
◼ 암시적 정보
◼ 누가 아이템을 북마크/링크했는가?
◼ 몇 번 조회되었는가?
◼ 몇 개가 팔렸는가?
◼ 사용자가 페이지를 얼마나 오래 읽었는가?
◼ 아이템 설명/특징
◼ 사용자 프로필/선호도

**Page 188**
평점 행렬 (상호작용 행렬)
◼ 사용자와 아이템의 평점을 나타냄.
◼ m개의 사용자 행(또는 열)과 n개의 아이템 열(또는 행)로 구성됨
(그림 설명: 사용자와 아이템 간의 평점 행렬 예시)

**Page 189**
입력 집계 방법
◼ 협업 필터링 (Collaborative filtering)
◼ 콘텐츠 기반 필터링 (Content-based filtering)
◼ 하이브리드 방법
◼ 협업 필터링과 콘텐츠 기반 필터링 방법을 결합함
◼ 두 방법의 단점을 처리하기 위함

**Page 190**
다양한 기타 추천 모델
(표 설명: 다양한 추천 모델과 이를 사용하는 서비스들 - Netflix, Amazon 등 비교)

**Page 191**
로드맵
◼ 협업 필터링
◼ 콘텐츠 기반 필터링

**Page 192**
협업 필터링
◼ 추천을 제공하기 위해 마음이 맞는 사용자들의 평점만 봄
◼ 사용자나 아이템에 대한 정보를 요구하지 않음
◼ 과거에 비슷한 관심사를 표현한 사용자들이 미래에도 공통된 관심사를 공유할 것이라는 아이디어임.
(그림 설명: 앨리스와 밥의 유사성을 기반으로 추천)

**Page 193**
예시
◼ 사용자 집합과 아이템 집합(행렬)이 주어졌을 때, 각 사용자의 알 수 없는 아이템에 대한 평점(선호도)을 예측함.
(표 설명: Marco, Luca, Anna의 영화 평점 예시. ?는 예측해야 할 값)

**Page 194**
평점 예측
◼ 아이템 집합 M을 평가한 사용자 집합 U가 주어졌을 때,
◼ 아직 존재하지 않는 각 평점에 대해, 사용자 ui가 아이템 mj에 부여할 평점 rij를 예측함
◼ RMSE (평균 제곱근 오차) 평가 = 모든 사용자와 예측된 평점에 대해 (예측값 - 실제값)^2 의 합

**Page 195**
협업 필터링 방법:
메모리 기반 및 모델 기반
◼ 메모리 기반 방법
◼ 평점을 사용하여 사용자 또는 아이템 간의 유사성을 계산하고 이를 순차적으로 활용하여 추천을 생성함.
◼ 모델 기반 방법
◼ 평점을 사용하여 모델을 추정하거나 학습한 다음 이 모델을 적용하여 평점 예측을 수행함.

**Page 196**
로드맵
◼ 메모리 기반 방법
◼ 사용자 기반
◼ 아이템 기반
◼ 모델 기반 방법
◼ SVD, 행렬 분해
◼ 머신 러닝 모델, 신경망, 확률적 방법

**Page 197**
두 가지 유형의 메모리 기반 협업 필터링
◼ 둘 다 “메모리”(평점 행렬의 내용)에만 의존하며 수학적으로 매우 유사하지만 개념적으로 다름.
◼ 사용자 기반 CF
◼ 사용자 간 유사성에 기반한 추천
◼ 아이템 기반 CF
◼ 아이템 간 유사성에 기반한 추천

**Page 198**
사용자 기반 CF: 개념
◼ 유사한 선호도를 가진 사용자를 찾아 추천을 수행함.
◼ 예) Tim에게 아이템 1을 추천해야 하는가?
◼ Jane과 Tim은 둘 다 아이템 2를 좋아하고 아이템 3을 싫어했음;
◼ 그들이 유사한 선호도를 가지고 있다고 가정함.
◼ 이것은 아이템 1을 Tim에게 좋은 추천으로 만듦.

**Page 199**
계산 단계
◼ 사용자 유사성 계산
◼ 타겟(활성) 사용자가 평가한 아이템을 평가한 모든 사용자를 식별함.
◼ 타겟 사용자와의 유사성을 계산함.
◼ 가장 가까운 이웃 사용자 결정
◼ 타겟 사용자와 가장 유사한 사용자들을 식별함(즉, 이웃 형성), 유사성 함수에 기반함.
◼ 아이템 점수 계산
◼ 이웃에서 타겟 사용자가 평가하지 않은 아이템을 평가한 사용자를 식별함.
◼ (타겟 사용자가 평가하지 않은) 각 아이템에 대해 예측을 생성함
◼ 추천할 아이템 결정
◼ 1개, 상위 N개, 또는 전체

**Page 200**
유사성 척도
◼ 유클리드 거리, 맨해튼 거리, 민코프스키 거리
◼ 자카드 유사도
◼ 피어슨 상관계수
◼ 코사인 유사도
◼ 두 벡터 사이의 코사인 각도
◼ 내적 (Dot product)
◼ 코사인 각도와 벡터의 크기
◼ 과제: 위의 유사성 척도들을 공부하시오.
◼ 정의, 공간/시간 복잡도, 대상 데이터
◼ 응용, 장점 및 단점

**Page 201**
일러스트레이션 1 (1/5)
◼ (링크 생략)
◼ 4명의 사용자가 5개의 다른 영화에 대해 평가한 간단한 사용자-아이템 행렬이 있다고 가정함.
◼ 또한 우리의 활성 사용자가 영화 중 3개를 평가했다고 가정함.
◼ 평가되지 않은 두 영화 중 어느 것이 활성 사용자에게 추천될지 알아보자.

**Page 202**
일러스트레이션 1 (2/5)
◼ 먼저, 적절한 유사성 척도를 사용하여 활성 사용자가 다른 사용자와 얼마나 유사한지 발견해야 함.
◼ 사용자 유사성은 활성 사용자가 평가한 아이템(예: 이 예제에서는 영화 2, 3, 4)만 고려하여 계산됨.
◼ 활성 사용자와 다른 세 사용자 간의 유사성이 0.7, 0.9, 0.4라고 가정함.

**Page 203**
일러스트레이션 1 (3/5)
◼ 다음으로, 가중 평점 행렬을 생성함
◼ 유사성 가중치와 사용자 평점을 곱하여
◼ 결과는 활성 사용자가 평가하지 않은 2개의 영화에 대해 아래(오른쪽)와 같이 표시됨.

**Page 204**
일러스트레이션 1 (4/5)
◼ 다음으로, 추천 행렬을 생성함
◼ 3명의 사용자가 첫 번째 영화를 평가했고, 2명의 사용자가 두 번째 영화를 평가했음.
◼ 두 영화 각각에 대해 가중 평점의 합을 계산함.
◼ 첫 번째 영화의 경우 합은 8.9이고, 두 번째 영화의 경우 12.1임.

**Page 205**
일러스트레이션 1 (5/5)
◼ 다음으로, 각 영화에 대한 가중 평점 값을 사용자 유사성 지수의 합으로 나누어 정규화함.
◼ 첫 번째 영화의 경우 4.45이고, 두 번째 영화의 경우 7.56임.

**Page 206**
(단계별) 일러스트레이션 2
◼ (링크 생략)
◼ 사용된 데이터셋: UC 버클리 자동화 과학 및 공학 연구소의 Jester 연구 프로젝트 데이터셋 1.
◼ 73,421명의 독자가 100개의 농담에 대해 평가한 평점이 있음. 평점은 -10.00에서 +10.00 사이의 실수 값임 (“99” 값은 “null” = “평가되지 않음”에 해당).
◼ 73,421명의 독자 중 14,116명이 100개의 농담을 모두 평가했으며, 나머지 59,305명은 적어도 15개 이상의 농담을 평가했음.
◼ “농담”을 “아이템”으로 생각하시오.

**Page 207**
5단계
◼ 데이터 정규화
◼ 유사성 계산
◼ 이웃 선택
◼ 아이템 점수 매기기
◼ 아이템 선택

**Page 208**
(1단계) 데이터 정규화
◼ 평점은 사용자의 척도에 크게 영향을 받음.
◼ 정규화는 평점의 척도를 다른 사용자의 평점과 비교 가능하거나 같은 수준이 되도록 조정함.
◼ 정규화 방법
◼ 각 사용자의 평점에서 평점 평균을 단순히 뺌
◼ z 점수

**Page 209**
데이터 정규화 일러스트레이션
◼ 5명의 사용자가 10개의 “농담”(아이템)에 대해 평가한 평점을 단순 방법을 사용하여 정규화함.

**Page 210**
(2단계) 유사성 계산
◼ 이것은 협업 필터링 알고리즘의 주요 작업임.
◼ 피어슨 상관계수 사용
◼ 상관계수는 -1과 +1 사이의 범위임
◼ 사용자 x와 사용자 y 사이의 양의 상관관계는 사용자 x가 아이템을 긍정적으로 평가하면 사용자 y도 같은 아이템을 긍정적으로 평가할 가능성이 높음을 의미함.
◼ 참고: 피어슨 상관계수는 데이터 정규화를 요구하지 않음.

**Page 211**
유사성 행렬 일러스트레이션
◼ 각 사용자 쌍의 유사성(즉, 그들의 평점)을 계산함: (10명의 사용자에 대해)
◼ 사용자 1 대 사용자 2, 사용자 1 대 사용자 3, 사용자 1 대 사용자 4, …
◼ 사용자 2 대 사용자 3, 사용자 2 대 사용자 4, 사용자 2 대 사용자 5, …
◼ …
◼ 사용자 9 대 사용자 10

**Page 212**
(3단계) 이웃 선택
◼ 현재 상용 추천 시스템은 매우 많은 수의 사용자를 보유하고 있음. 따라서 타겟(또는 “활성”) 사용자의 이웃은 허용 가능한 응답 시간을 보장하기 위해 사용자들의 부분집합으로 구성되어야 함.
◼ 이웃 선택은 평점 예측 및 아이템 추천에 직접적인 영향을 미칠 수 있음.
◼ 이웃을 선택하는 4가지 전통적인 접근 방식
◼ 모든 데이터 사용 (데이터셋이 매우 작을 때)
◼ 유사성 점수가 특정 임계값 이상인 데이터 선택
◼ 유사성 점수로 상위 N개 데이터 선택
◼ k-Means와 같은 클러스터링 방법을 사용하여 유사한 클러스터 선택

**Page 213**
이웃 선택 일러스트레이션 (1/2)
◼ 사용자 3 (인덱스=2)을 타겟 사용자로 지정
◼ 사용자는 10개 아이템 중 4개를 평가했음.
◼ 우리의 목표는 나머지 6개 중 어떤 농담이 이 타겟 사용자에게 가장 좋은 추천이 될지 알아내는 것임.
◼ 임계값 방법 사용
◼ (임계값 0.1 사용)

**Page 214**
이웃 선택 일러스트레이션 (2/2)
◼ 임계값 방법을 사용하여 이웃을 선택함
◼ (임계값 +0.1 사용)
◼ 사용자 2에 대해 유사도가 +0.1 이상인 사용자는 3, 4, 6, 9뿐임.

**Page 215**
(4단계) 아이템 점수 매기기 (1/4)
◼ 이웃 평점을 사용하여 아이템 점수를 매기는 것은 협업 필터링에서 필수적임.
◼ 가중 평균은 아이템 점수를 매기는 가장 일반적인 방법 중 하나임.

**Page 216**
아이템 점수 매기기 (2/4)
◼ 먼저, 타겟 사용자가 아직 평가하지 않은 아이템만 선택함.
◼ (이 예제에서는 농담 1, 2, 3, 4, 9, 10)

**Page 217**
아이템 점수 매기기 (3/4)
◼ 그런 다음 선택된 사용자에 대한 이웃 평점과 이웃 유사성을 계산함.
◼ 이것들은 각 농담(아이템)에 대한 점수를 생성하는 데 사용됨.

**Page 218**
아이템 점수 매기기 (4/4)
◼ 다음은 결과 아이템 점수임.
◼ “농담 2”가 가장 높은 점수를 가짐; 농담 4가 가장 낮은 점수를 가짐.

**Page 219**
(5단계) 아이템 선택
◼ 모든 아이템의 점수가 매겨지면, 가장 높은 점수를 가진 아이템이 최고의 추천이 됨.
◼ 따라서 우리 경우에는 joke_2가 타겟 사용자에게 추천될 것임.
◼ 참고: 상위 1개 아이템보다는 상위 N개의 점수가 매겨진 아이템을 추천하는 것이 종종 가장 좋음.

**Page 220**
아이템 기반 CF: 개념
◼ Amazon에 의해 개발됨
◼ 많은 사용자에게 유사한 호소력을 가진 아이템을 찾아 추천을 수행함.
◼ (예) Tim에게 아이템 1을 추천해야 하는가?
◼ Don과 Sandra는 아이템 1과 아이템 4를 모두 좋아했음 (즉, 아이템 4는 아이템 1과 가장 유사함).
◼ 아이템 4를 좋아한 사람들은 아이템 1도 좋아할 것이라고 가정함.
◼ 따라서, Tim이 아이템 4를 좋아하므로 아이템 1이 Tim에게 추천될 것임.

**Page 221**
예측 단계
◼ 타겟(활성) 사용자가 평가한 아이템 집합을 식별함.
◼ 타겟 아이템과 가장 유사한 N개의 아이템 집합을 식별함(즉, 이웃 형성), 유사성 함수에 기반함.
◼ 예측을 생성함, 즉 N개의 유사한 아이템 집합을 기반으로 타겟 사용자가 아이템에 부여할 평점을 예측함.

**Page 222**
아이템 유사성 계산
◼ 아이템 i와 j 사이의 유사성은 두 아이템을 모두 평가한 사용자를 찾고 그들의 평점에 유사성 함수를 적용하여 계산됨.
◼ 코사인 기반 유사성
◼ 아이템은 m차원 사용자 공간의 벡터임
◼ (사용자 간의 평점 척도 차이는 고려되지 않음).

**Page 223**
예측 계산
◼ 타겟 사용자의 평점을 보고 기법 중 하나를 사용하여 예측을 얻음.
◼ (예) 가중 합

**Page 224**
예시
(그림 설명: 영화 포스터와 평점 행렬 예시)

**Page 225**
아이템 기반 협업 필터링:
일러스트레이션 1
◼ (링크 생략)
◼ 샘플 데이터셋: 2명의 사용자, 4개의 아이템(영화)

**Page 226**
아이템 기반 협업 필터링:
일러스트레이션 1
◼ 샘플 데이터셋: 2명의 사용자, 4개의 아이템(영화)
◼ 결측값을 “0”으로 대체함.
◼ ** 참고: 이제 사용자-아이템 행렬을 아이템-사용자 행렬로 표현함.

**Page 227**
1단계: movie-1과 가장 유사한(가장 가까운) 영화 찾기.
◼ 영화 간의 유사성은 모든 사용자에 의해 결정됨.
◼ 예를 들어, movie_1과 movie_3 사이의 유사성은 user_0과 user_1의 평점을 모두 사용하여 계산됨.
◼ (예) 코사인 유사도 사용
◼ movie-1은 movie-3과 가장 가깝고, 그 다음 movie-0, 그 다음 movie-2임.

**Page 228**
2단계: 사용자가 가장 유사한 영화에 대해 부여한 평점의 가중 평균을 계산함.
◼ 사용자는 유사한 영화에 유사한 평점을 줌.
◼ 따라서 사용자의 영화 평점을 예측할 때, 사용자가 유사한 영화에 준 평점의 평균을 사용하는 것이 합리적임.
◼ 가장 가까운 이웃의 수를 2로 설정함. (movie-2 제외)
◼ movie_3과 movie_0을 사용하여 user_1의 movie_1에 대한 평점을 예측함.

**Page 229**
2단계: (계속)
◼ user_1의 movie_3에 대한 평점은 2이고, user_1의 movie_0에 대한 평점은 3임.
◼ movie_3이 movie_1에 더 가깝기 때문에, movie_3에 대한 가중치가 movie_0에 대한 가중치보다 커야 함.
◼ 따라서 movie_1에 대한 예측 평점은 movie_3에 대한 평점에 더 가까울 것임 (movie-3과 movie-0의 중간이 아님).
◼ 코사인 유사도를 가중치로 사용하여 예측된 평점은 2.374임.

**Page 230**
아이템 기반 협업 필터링:
(단계별) 일러스트레이션 2
◼ (링크 생략)
◼ 샘플 데이터셋: 10명의 사용자, 10개의 아이템(영화)
◼ * 참고: 모든 결측값은 “0”으로 변환되었음.

**Page 231**
가장 가까운 이웃 및 유사성 계산 (1/3)
◼ sklearn.neighbors 라이브러리의 NearestNeighbors()를 사용하여 코사인 유사도를 이용해 영화 간의 거리를 계산하고 각 영화에 대한 가장 가까운 이웃을 찾음.
(코드 생략)
◼ 가장 가까운 이웃의 수(n_neighbors)는 3으로 설정됨.

**Page 232**
가장 가까운 이웃 및 유사성 계산 (2/3)
◼ 출력:
◼ 영화로부터 가장 가까운 이웃의 수(3)는 영화 자체와 2개의 가장 가까운 영화를 포함함.
(코드 출력 예시)
◼ * 위에서 [0, 7, 5]는 “영화 0”과 2개의 가장 가까운 이웃(영화 7과 영화 5)을 의미함.

**Page 233**
가장 가까운 이웃 및 유사성 계산 (3/3)
◼ 거리를 사용하여 영화 간의 거리를 보여줌
◼ 숫자가 작을수록 더 가까움을 의미함.
◼ * 각 영화에 대해, 2개의 가장 가까운 이웃까지의 거리:
(코드 출력 예시)

**Page 234**
사용자의 영화 평점 예측 (1/3)
◼ 사용자의 영화 평점을 예측하는 것은 사용자가 유사한 영화에 부여한 평점의 가중 평균을 계산하는 것과 같음.
◼ user_7의 movie_0에 대한 평점을 예측해 보자.
◼ 먼저, NearestNeighbors()를 사용하여 movie_0에 대한 가장 가까운 이웃을 찾음.
(코드 생략)

**Page 235**
사용자의 영화 평점 예측 (2/3)
(코드 생략)
◼ movie_0과 가장 유사한 영화는 movie_7과 movie_5임,
◼ 그리고 movie_0으로부터의 거리는 각각 0.3196과 0.4034임.

**Page 236**
예측 평점 계산 공식
◼ R(m, u) = {∑ ⱼ S(m, j)R(j, u)}/ ∑ ⱼ S(m, j)
◼ R(m, u): 사용자 u의 영화 m에 대한 평점
◼ S(m, j): 영화 m과 영화 j 사이의 유사성
◼ j ∈ J 여기서 J는 영화 m과 유사한 영화들의 집합
◼ 이 공식은 단순히 사용자 u의 영화 m에 대한 예측 평점이 사용자 u가 유사한 영화들에 부여한 평점의 가중 평균임을 의미함.
◼ 각 평점에 대한 가중치 (S(m, k)/∑ ⱼ S(m, j))는 영화 m과 영화 k가 더 가까울수록 커짐.
◼ 이 항의 분모는 모든 가중치의 합을 1로 만듦.

**Page 237**
사용자의 영화 평점 예측 (3/3)
◼ user_7의 movie_0에 대한 평점 R(0,7)을 예측해 보자.
R(0,7)=[S(0,5)∗R(5,7)+S(0,7)∗R(7,7)]/[S(0,5)+S(0,7)]
◼ movie_0과 movie_5 사이, 그리고 movie_0과 movie_7 사이의 거리는 0.4034와 0.3196임. (53페이지의 거리(Out) 참조.)
◼ 따라서 유사성은
◼ S(0,5) = (1 - 0.4034)
◼ S(0,7) = (1 - 0.3196).
◼ R(5,7) = 2이고 R(7,7) = 3이므로 (50페이지 참조), 예측된 R(0,7)은 2.5328임.

**Page 238**
연습문제
◼ (수기 계산) 사용자 기반 협업 필터링을 위한 일러스트레이션 1 (p.21)의 사용자-아이템 평점 행렬을 사용하여 아이템 기반 협업 필터링을 워크스루 하시오.
◼ (프로그래밍) 위 내용을 프로그래밍으로 수행하시오.

**Page 239**
메모리 기반 협업 필터링 방법의 구현
◼ 성능상의 이유로, 방법은 오프라인과 온라인의 두 가지 별도 단계로 나뉨.
◼ 오프라인 단계
◼ 완전히 업데이트된 평점 행렬에 대해 모든 사용자 또는 아이템 유사성 쌍을 계산하고 저장함
◼ 온라인 단계
◼ 미리 계산되어 저장된 사용자 또는 아이템 유사성 쌍을 사용함
◼ 대규모 평점 행렬의 문제점
◼ 오프라인 계산 시간이 엄청날 수 있음.
◼ 효율성을 위해 클러스터링 또는 차원 축소 방법을 사용함.
◼ 사용자 또는 아이템 유사성 쌍을 저장하는 데 큰 메모리 공간을 차지함.

**Page 240**
사용자 기반 방법의 장단점
◼ 장점
◼ 사용자 및 아이템에 대한 정보를 요구하지 않음
◼ 구현하기 쉬움
◼ 단점
◼ 평점 행렬에 사용자가 많을 때 성능이 좋지 않음
◼ 행렬이 희소(sparse)할 때 성능이 좋지 않음.
◼ (콜드 스타트 문제) 새로운 사용자의 경우 사용자 유사성을 계산할 수 없음.

**Page 241**
아이템 기반 방법의 장단점
◼ 장점
◼ (사용자 기반 방법보다) 더 정확함
◼ 일반적으로 아이템이 받는 평균 평점은 사용자가 다른 아이템에 주는 평균 평점만큼 빠르게 변하지 않기 때문임.
◼ (사용자 기반 방법보다) 성능이 더 좋음
◼ 일반적으로 아이템보다 사용자가 더 많기 때문임.)
◼ 단점
◼ 때때로 뻔한 아이템이나 이전 사용자 경험과 다르지 않은(novel하지 않은) 아이템을 추천할 수 있음.

**Page 242**
로드맵
◼ 메모리 기반 방법
◼ k-최근접 이웃
◼ 모델 기반 방법
◼ SVD, 행렬 분해
◼ 딥러닝

**Page 243**
Netflix Prize (1/2)
◼ 2006년 10월 시작
◼ 100만 달러 상금
◼ 훈련 데이터셋: 48만 명의 고객이 1만 8천 개의 영화에 대해 평가한 1억 개의 평점 (1, 2, 3, 4, 5 별점).
◼ 자격 심사 세트 (2,817,131 평점) 구성:
◼ 테스트 세트 (1,408,789 평점), 우승자 결정에 사용됨
◼ 퀴즈 세트 (1,408,342 평점), 리더보드 점수 계산에 사용됨
◼ 목표:
◼ 기존 Netflix 알고리즘을 최소 10% 개선
◼ RMSE를 0.9525에서 0.8572로 줄임

**Page 244**
Netflix Prize (2/2)
◼ 2009년 7월 25일, "The Ensemble"(Bellkor’s Pragmatic Chaos) 팀이 10.09% 향상을 달성함.
◼ 교훈
◼ SVD/행렬 분해는 CF에서 선택받는 방법이 되었음.
◼ 앙상블(Ensemble)은 우승에 결정적임.
◼ 정규화(Regularization)는 과적합(over-fitting)을 완화하는 데 중요함.

**Page 245**
모델 기반 협업 필터링 방법의 분류
(다이어그램: 모델 기반 협업 필터링 -> 차원 축소 방법(SVD, 행렬 분해), 머신 러닝 모델(k-최근접 이웃 클러스터링, 선형 회귀, 로지스틱 회귀, 베이지안 네트워크, 마르코프 모델, 신경망), 확률적 방법(PMF, PLS, LDA))

**Page 246**
SVD, 행렬 분해
◼ 둘 다 원본 행렬의 차원을 축소함.
◼ 둘 다 원본 데이터의 숨겨진 의미를 포착하는 잠재 요인(latent factors)을 생성함.

**Page 247**
로드맵
◼ SVD
◼ 행렬 분해

**Page 248**
로드맵: SVD
◼ 최상위 뷰
◼ 주요 개념
◼ 기술적 세부 사항

**Page 249**
SVD (특이값 분해)
◼ 추천 시스템에서 SVD는 사용자와 아이템을 잠재 특징의 벡터로 모델링하며, 이들의 외적(cross product)이 아이템에 대한 사용자의 평점을 생성함.
◼ SVD를 사용하면 평점 행렬이 행렬의 기본 구조를 노출하는 일련의 선형 근사치로 분해됨.
◼ 기본 구조는 주성분(principal components) 집합임.
◼ 주성분은 관찰된 평점을 설명하는 잠재 특징(요인)임.
◼ SVD는 평점 행렬의 차원을 축소함.
◼ SVD의 응용 분야에는 주성분 분석(PCA), 신호 처리(이미지 압축, 노이즈 감소) 등이 포함됨.

**Page 250**
SVD: 시각화
(링크 생략)
A (입력 행렬): n x d 행렬 (예: n 사용자, d 아이템)
◼ U: A의 왼쪽 직교 행렬
◼ Σ: 잠재 요인의 대각 행렬 (특이값)
(r: 행렬의 랭크 – 0이 아닌 행의 수)
◼ VT: A의 오른쪽 직교 행렬

**Page 251**
SVD에서 Truncated SVD로: 시각화
◼ Unxr : Unxd 행렬은 오른쪽 (n-r) 열을 제거하여 축소됨
◼ Σrxr : Σnxd 행렬은 아래쪽 (n-r) 행과 오른쪽 (d-r) 열을 제거하여 축소됨
◼ VTrxd : VTdxd 행렬은 아래쪽 (n-r) 행을 제거하여 축소됨
(링크 생략)
축소된 SVD (분홍색)

**Page 252**
Truncated A 행렬
◼ Unxr · Σrxr · VTrxd = truncated A
◼ A와 truncated A의 차이는 오차임.
◼ truncated A 행렬은 각 아이템 쌍 간의 유사성을 계산하고 사용자에 대한 아이템의 누락된 평점을 예측하는 데 사용됨.
◼ 행렬 분해는 목적(오차, 손실) 함수, 일반적으로 MSE 또는 RMSE를 최소화해야 함.

**Page 253**
사용자에 대한 아이템 평점 예측
(예: 사용자 1, 아이템 4&5)
(링크 생략)
M (5 x 5)
U (5 x 5)
Σ (5 x 5)
VT (5 x 5)
사용자 데이터
제품 데이터

**Page 254**
로드맵: SVD
◼ 최상위 뷰
◼ 주요 개념
◼ 기술적 세부 사항

**Page 255**
데이터 변환
예시 1: 사용자와 아이템 (영화)
◼ (링크 생략)
◼ 참고: 행렬 A의 “아이템”은 U, Σ, V 행렬에서 “개념(concepts)”으로 변환됨.

**Page 256**
잠재 요인: 시각화
(영화)
◼ 예시: 영화
◼ 두 가지 잠재 요인: (진지함 - 도피성), (남성 지향 - 여성 지향)

**Page 257**
중요 사항
◼ “개념”의 이름은 SVD에 의해 생성된 것이 아님.
◼ U, Σ, VT 행렬을 검토한 후 인간 도메인 전문가에 의해 생성됨.
◼ 이러한 “개념”은 잠재 요인, 즉 원본 평점 데이터에 숨겨진 의미임.
◼ U 및 VT 행렬의 데이터는 원본 데이터에 숨겨진 “의미 있는” 정보를 유지함.
◼ 데이터는 원본 데이터가 다른 좌표(일반적인 X, Y 좌표가 아님)에 투영된 것을 나타내기 때문에 매우 이상하게 보임.
◼ 그러나 변환된 데이터는 원본 데이터보다 알 수 없는 평점을 예측하는 데 어떤 의미에서는 더 유용함.

**Page 258**
이미지 압축에 SVD 적용 (1/2)
◼ (링크 생략)
◼ Σ 행렬에서 낮은 특이값을 제거하면 U 및 VT 행렬이 축소됨.
◼ (예시) 5x5 흑백 이미지 및 A 행렬 인코딩

**Page 259**
이미지 압축에 SVD 적용 (2/2)
◼ U 행렬 Σ 행렬
◼ 처음 두 개의 특이값만 유지함
◼ 잠재 요인: (흰색 – 검은색), (검은색 – 흰색)
◼ 결과적으로 재구성된 A 행렬 (원본 A 행렬과 유사함)

**Page 260**
예시 2 (1/5): 평점 행렬
◼ (링크 생략)
◼ 참고: 각 결측값(NaN)은 “0”으로 채워짐

**Page 261**
참고
◼ A 행렬에 결측값(NaN)이 포함되어 있으면 SVD가 작동하지 않음.
◼ SVD 전에 결측값을 모두 채워야 함.
◼ 0으로 또는
◼ 열 평균 또는 행 평균으로

**Page 262**
예시 2 (2/5): 전체 10x10 U 행렬
◼ 참고: 원본 평점 값은 이제 이상한 숫자로 변환됨.

**Page 263**
예시 2 (3/5): Truncated Σ 행렬
◼ 대각선을 따른 특이값은 내림차순임.
◼ 제거할 열/행의 수를 결정함.
◼ k 계산 = (처음 k개 대각선 값의 제곱합) / (모든 대각선 값의 제곱합)
◼ (예) k >= 0.9이면 k 이후의 모든 대각선을 버림.
◼ k를 넘어서는 열/행은 의미 있는 정보를 많이 기여하지 않음.

**Page 264**
예시 2 (4/5): Truncated U 행렬
◼ U 행렬의 열 순서는 Σ 행렬의 열 순서에 해당함.
◼ 참고: U 행렬에서 세 번째 열 이후의 열은 제거됨.
◼ 참고: 축소된 10x3 U 행렬은 전체 10x10 U 행렬만큼이나 의미 있는 정보를 거의 포함하고 있음.

**Page 265**
예시 2 (5/5): Truncated VT 행렬

**Page 266**
로드맵: SVD
◼ 최상위 뷰
◼ 주요 개념
◼ 기술적 세부 사항

**Page 267**
복습: 내적 (Dot Product)
a · b (2요소 벡터 a와 b의 내적)
a · b = ax × bx + ay × by
a · b (3요소 벡터 a와 b의 내적)
a · b = ax × bx + ay × by + az × bz

**Page 268**
SVD의 기술적 설명 (1/3)
◼ Σ 행렬의 특이값은 내림차순임.
◼ U 행렬은 사용자에 해당하고, V 행렬은 아이템에 해당함.
◼ U 행렬의 각 열은 특이값 벡터이고, VT 행렬의 각 행은 특이값 벡터임.
◼ 가장 큰 고유값과 관련된 벡터는 U의 첫 번째 열과 VT의 첫 번째 행에 있음.

**Page 269**
SVD의 기술적 설명 (2/3)
◼ 실수 행렬 A의 특이값은 대칭 행렬 AAT 또는 AT A의 고유값의 양의 제곱근임.

**Page 270**
SVD의 기술적 설명 (3/3)
◼ U와 V는 직교 행렬임.
◼ 직교 행렬: 전치 행렬과 곱하면 단위 행렬이 됨.
◼ U의 각 열은 A 행렬의 사용자를 Σ 행렬의 해당 축에 투영한 것임.

**Page 271**
SVD의 일러스트레이션:
2x2 행렬 A와 함께
◼ (링크 생략)
◼ (A: 2x2 행렬) (σ1, σ2 : 단위 벡터)
◼ VT : 단위 원판의 회전
◼ Σ : 다른 좌표를 따라 특이값에 의한 스케일링 <σ1 (수평) 및 σ2 (수직)>
◼ U : 회전

**Page 272**
행렬 A를 U, Σ, VT로 분해하는 단계
(링크 생략)
1. AT와 ATA를 계산함.
2. ATA의 고유값을 결정함.
내림차순으로 정렬함.
제곱근을 취하여 A의 특이값을 얻음.
3. 대각 행렬 Σ를 구성함 (특이값을 대각선을 따라 내림차순으로 배치).
Σ-1을 계산함.
4. 오른쪽 직교 행렬 V를 구성함.
(정렬된 고유값을 사용하여 ATA의 고유벡터를 계산하고, 이 고유벡터들을 V의 열을 따라 배치).
VT를 계산함.
5. 왼쪽 직교 행렬 U를 U = AVΣ-1로 구성함.
6. A = UΣVT를 사용하여 SVD를 계산함.

**Page 273**
평점을 예측하는 단계
◼ 평점 행렬 Anxd에 SVD를 적용함
◼ A를 Unxn, Σnxd, VTdxd로 분해함
◼ Truncated SVD 생성
◼ 대각 행렬 Σrxr 생성
◼ Unxn과 VTdxd를 Unxr과 VTrxd로 자름
◼ Unxr, Σrxr, VTrxd를 곱하여 A 행렬의 변환된 버전인 Anxd를 생성함.
◼ Anxd와 Anxd 행렬을 사용하여 사용자 x의 아이템 y에 대한 평점을 예측함.
◼ Anxd를 사용하여 아이템 y와 다른 아이템 간의 유사성을 계산함.
◼ 계산된 유사성을 반영하여 A에서 사용자 x의 아이템 y에 대한 평점을 새로운 평점으로 변경함.

**Page 274**
참고
◼ 원본 행렬 Anxd와 재구성된 버전 사이에는 큰 차이가 있음.
◼ 원본 평점 행렬에는 평점이 포함되어 있음.
◼ 재구성된 행렬에는 “잠재 요인”을 나타내는 이상한 숫자가 포함되어 있음.
◼ 잠재 요인은 평점에 숨겨진 아이템의 특성임; SVD 계산은 이것들을 추출함.
◼ nxd Σ 행렬을 rxr Σ 행렬로 자르는 방법
◼ 전체 A 행렬에서 유지할 최소 정보의 백분율을 지정함 (예: 0.9)
◼ 처음 r개 특이값의 제곱합을 모든 d개 특이값의 제곱합으로 나눈 값이 >= 0.9가 되도록 “r”을 결정함.

**Page 275**
Python 코드 (1/3)
(링크 생략)
(코드 생략 - 라이브러리 임포트 및 함수 정의)

**Page 276**
Python 코드 (2/3)
(코드 생략 - SVD 실행 및 평점 예측 함수)

**Page 277**
Python 코드 (3/3)
(코드 생략 - 추천 함수 및 실행)

**Page 278**
로드맵
◼ SVD
◼ 행렬 분해

**Page 279**
행렬 분해: 개요
◼ SVD는 평점 행렬이 완성되어 있어야 함.
◼ 종종 평점 행렬에는 결측값이 많은 부분이 있음.
◼ 결측값은 미리 채워져야 함.
◼ 행렬 분해는 관찰된 평점에 대해서만 추론함으로써 결측 항목을 미리 채울 필요를 피함.
◼ 행렬 분해는 SVD의 근사치로 간주될 수 있음.
◼ 행렬 분해는 현재 협업 필터링에 대한 최고의 단일 모델 접근 방식으로 간주됨.
◼ Netflix 상금 우승자에 의해 입증됨

**Page 280**
행렬 분해: 시각화
◼ A 행렬을 두 행렬 U와 VT로 분해함 (SVD처럼 U, Σ, VT가 아님)
(그림 설명: 사용자-아이템 행렬을 사용자 잠재 행렬과 아이템 잠재 행렬로 분해)

**Page 281**
행렬 분해 (1/3)
◼ A: m (사용자) x n (아이템) (여기서 m, n은 클 수 있음)
◼ U: m * k
◼ V: n * k
◼ k는 잠재 요인의 수이며 작음
◼ k개의 잠재 요인은 주성분임.
◼ 즉, 평점 행렬 A는 A의 차원보다 훨씬 작은 차원을 가진 행렬 U와 V로 분해됨.
◼ 행렬 분해는 “m x n” 평점 행렬(또는 피드백 행렬, 상호작용 행렬, 효용 행렬)을 훨씬 낮은 랭크의 두 행렬로 축소함.

**Page 282**
행렬 분해 (2/3)
◼ 행렬 U에서, 행 i는 사용자 i에 대한 임베딩이라고 함.
◼ 행렬 V에서, 행 j는 아이템 j에 대한 임베딩이라고 함.
◼ 사용자 i의 아이템 j에 대한 예측(rij)은 Ui와 VTj의 내적으로 얻을 수 있음.

**Page 283**
행렬 분해 (3/3)
◼ U와 VT의 곱셈 결과는 A에 가까움.
◼ 둘 사이의 차이는 오차(손실)임.
◼ 행렬 분해는 목적(손실) 함수, 일반적으로 MSE 또는 RMSE를 최소화함.
◼ 목적 함수의 최소값을 찾기 위해 널리 사용되는 알고리즘은 다음을 포함함
◼ 경사 하강법 (gradient descent)
◼ 가중 교대 최소 제곱 (WALS)
◼ 심층 신경망 (역전파 포함)

**Page 284**
일러스트레이션 1
◼ (링크 생략)
◼ U·VT의 (i,j) 항목은 단순히 사용자 i와 아이템 j의 임베딩의 내적 <Ui, Vj>이며, 이는 Ai,j에 가까워야 함.
◼ 예시 (사용자 2, 아이템 1): <(-1,0), (0.9, -0.2)> = -0.9

**Page 285**
일러스트레이션 2 (1/2)
◼ R: 평점 행렬 (사용자와 아이템)

**Page 286**
일러스트레이션 2 (2/2)
◼ R 행렬 분해됨:

**Page 287**
행렬을 두 행렬로 분해하기
◼ 다양한 알고리즘
◼ (링크 생략)
◼ (링크 생략)

**Page 288**
선형 대수: 행 축소 (가우스 소거법) 방법
◼ (링크 생략)
◼ Python 라이브러리: SYMPY, rref 메서드
◼ A 행렬: 정사각 행렬
◼ L 행렬: 하삼각 행렬
◼ 대각선 위는 모두 0
◼ U 행렬: 상삼각 행렬
◼ 대각선 아래는 모두 0
◼ (* 참고: 이 방법의 확장은 비정사각 A 행렬에서도 작동함.)
◼ (링크 생략)

**Page 289**
워크스루 예제 (1/7)
◼ (예시) 3x3 정사각 행렬
◼ 먼저, U 행렬 계산
◼ A 행렬의 왼쪽 아래 모서리를 0으로 대체함.

**Page 290**
워크스루 예제 (2/7)
◼ 먼저, 4 (행2, 열1)를 0으로 대체함, 다음을 사용하여
◼ (위의 의미는)
◼ 4를 2로 나눔;
(R2C1에 대한 “승수”는 2임.)
◼ 결과(2)를 첫 번째 행 <2|1|3>과 곱함
◼ 두 번째 행에서 첫 번째 행을 뺌.
◼ 두 번째 행을 위의 결과로 대체함.
결과 R2는 <0|-3|-3>임

**Page 291**
워크스루 예제 (3/7)
◼ 다음으로, -2 (행 3, 열 1)를 0으로 대체함, 다음을 사용하여
◼ (위의 의미는)
◼ -2를 2로 나눔;
(R3C1에 대한 “승수”는 -1임.)
◼ 결과(-1)를 첫 번째 행 <2|1|3>과 곱함
◼ 세 번째 행에서 첫 번째 행을 뺌.
◼ 세 번째 행을 위의 결과로 대체함.
결과 R3는 <0|6|8>임
◼ 참고: 첫 번째 행은 동일하게 유지됨.

**Page 292**
워크스루 예제 (4/7)
◼ 다음으로, 6 (행 3, 열 2)을 0으로 대체함, 다음을 사용하여
◼ R3C2에 대한 “승수”는 -2임.
◼ (* 참고: 세 번째 행의 0을 잃지 않기 위해 R1 대신 R2를 사용함.)

**Page 293**
워크스루 예제 (5/7)
◼ U 행렬의 최종 형태

**Page 294**
워크스루 예제 (6/7)
◼ 이제 L 행렬 계산
◼ L 행렬은 에셜론 대각 행렬임
◼ (대각선은 1, 오른쪽 위 모서리는 0)
◼ 나머지 값들은 동일한 (행, 열) 인덱스에 위치한 U 행렬의 승수들임.
(R3C2에 대한 승수는 -2)
(R2C1에 대한 승수는 2)
(R3C1에 대한 승수는 -1)

**Page 295**
워크스루 예제 (7/7)
◼ L 행렬의 최종 형태

**Page 296**
협업 필터링의 장점
◼ 구현하기 간단함.
◼ (특히 잠재 요인 모델은) 아이템의 숨겨진 특성을 포착하며 아이템 콘텐츠에 대한 이해를 요구하지 않음.

**Page 297**
협업 필터링의 문제점
◼ 콜드 스타트
◼ 일치하는 것을 찾기 위해 시스템에 이미 충분한 다른 사용자가 있어야 함.
◼ 희소성 (Sparsity)
◼ 추천할 아이템이 많으면 사용자가 많더라도 사용자/평점 행렬이 희소하여 동일한 아이템을 평가한 사용자를 찾기 어려움.
◼ 첫 번째 평가자 (First rater)
◼ 이전에 평가되지 않은 아이템은 추천할 수 없음.
◼ 새로운 아이템
◼ 소수 취향 아이템
◼ 인기 편향 (Popularity bias)
◼ 독특한 취향을 가진 사람에게 아이템을 추천할 수 없음.
◼ 인기 있는 아이템을 추천하는 경향이 있음.

**Page 298**
로드맵
◼ 협업 필터링
◼ 콘텐츠 기반 필터링

**Page 299**
협업 필터링 대 콘텐츠 기반 필터링
◼ (링크 생략)
◼ 타겟 사용자의 현재 관심 아이템과 유사한 아이템을 추천함.
◼ * 타겟 사용자와 유사한 사용자는 고려하지 않음.

**Page 300**
참고: 협업 필터링 대 콘텐츠 기반 필터링
◼ 협업 필터링
◼ 사용자-아이템 평점에만 기반한 추천.
◼ 사용자나 아이템에 대한 추가 정보 없음.
◼ 콘텐츠 기반 필터링
◼ “콘텐츠”(즉, 사용자 및 아이템에 대한 정보)가 필요함.
◼ 아이템 설명/특징, 그리고 “타겟” 사용자의 프로필 또는 과거 행동에만 기반한 추천.
◼ 머신 러닝 모델 사용

**Page 301**
동기 부여 예제
◼ (링크 생략)
◼ 질문: 타겟 사용자에게 어떤 제품을 추천할 것인가?
◼ 사용자 관심 수준을 측정하기 위해, (예: 내적)을 사용하여 유사성(아이템 특징과 타겟 사용자가 평가한 특징 간)을 측정해 보자.
◼ 아이템 1: 2x1 + 0x0 + 1x1 + 1x2 = 5
아이템 2: 2x0 + 0x1 + 1x4 + 1x0 = 4
아이템 3: 2x3 + 0x0 + 1x0 + 1x1 = 7
◼ 타겟 사용자에게 아이템 3을 추천함.

**Page 302**
워크스루 예제 (1/6)
◼ (링크 생략)
◼ 예제 아이템 행렬
◼ 각 행은 기사의 5가지 속성(특징)의 이진 값을 가짐. (각 행은 아이템(특징) 벡터임.)
◼ 기사 속성의 오른쪽에는 사용자가 기사를 좋아했는지/싫어했는지를 나타내는 두 개의 사용자 열이 있음. (각 열은 사용자(선호도) 벡터임.)
◼ 각 아이템에 대해, 다른 사용자가 좋아한 특징의 수가 있음. (이것은 총 속성 벡터임.)

**Page 303**
워크스루 예제 (2/6)
◼ 먼저, 아이템 행렬을 정규화함
◼ 용어 발생(1 또는 0)을 값이 1인 속성 수의 제곱근으로 나눔.
◼ 예: 기사 1의 경우, 정규화된 속성은 1/sqrt(3)=0.577이 됨
◼ 아이템 행렬이 정규화되고, Excel의 ‘sumproduct’ 함수를 사용하여 User1과 User2에 대한 사용자 프로필이 생성됨.

**Page 304**
워크스루 예제 (3/6)
◼ 각 정규화된 아이템 속성 값에 각 사용자 속성 값을 곱함.
◼ * 이것은 단지 아이템 벡터와 사용자 벡터의 내적임.
◼ * 사용자 프로필은 각 사용자의 선호도를 보여줌.
◼ (예) User1은 “Big Data”에 관한 기사를 가장 좋아하고, 그 다음으로 “Learning Paths”, 그 다음으로 “Machine Learning”을 좋아함.

**Page 305**
워크스루 예제 (4/6)
◼ 기사 벡터와 IDF 벡터의 내적은 각 기사의 가중 점수를 제공함.
◼ ** 텍스트의 벡터 공간 모델(및 TF와 IDF)에 대해서는 이 과정의 나중에 배울 것임.
◼ (예) 기사 1에 대한 가중 점수(위 그림에는 표시되지 않음)는
0.577x0.699 + 0x0.699 + 0.577x0.523 + 0x0.398 + 0.577x0.699 =
0.404 + 0 + 0.302 + 0 + 0.404 = 1.11

**Page 306**
워크스루 예제 (5/6)
◼ 가중 점수는 차례로 사용자 프로필 벡터와의 내적에 사용됨.
◼ (예) User 1과 기사 1의 경우,
0.404x1.284 + 0x(-0.577) + 0.302x0 + 0x0.13 + 0.404x0.577
= 0.519 + 0 + 0 + 0 + 0.233 = 0.752
◼ 이것은 사용자가 특정 기사를 좋아할 확률을 제공함. 기사 1의 경우 확률은 75%임 (위 그림의 “Pred User1” 아래 녹색 부분).

**Page 307**
워크스루 예제 (6/6)
◼ 이 과정을 N개의 기사에 적용하여 사용자가 어떤 기사를 가장 좋아할지 알아낼 수 있음.
◼ 사용자가 아직 읽지 않은 기사를 기반으로 특정 사용자에게 별도의 추천을 할 수 있음.

**Page 308**
콘텐츠 기반 필터링의 장점
◼ 다른 사용자에 대한 데이터가 필요 없음.
◼ 콜드 스타트 또는 희소성 문제 없음.
◼ 단일 사용자와 그 사용자의 기록으로 시작할 수 있음.
◼ 독특한 취향을 가진 사용자에게 추천 가능함.
◼ 새롭고 인기 없는 아이템 추천 가능
◼ 첫 번째 평가자 문제 없음
◼ 아이템이 추천된 원인이 된 콘텐츠 특징을 나열하여 추천 아이템에 대한 설명을 제공할 수 있음.

**Page 309**
콘텐츠 기반 필터링의 단점
◼ 의미 있는 특징으로 인코딩될 수 있는 콘텐츠가 필요함.
◼ 사용자의 취향은 이러한 콘텐츠 특징의 학습 가능한 함수로 표현되어야 함.
◼ 다른 사용자의 품질 판단을 활용할 수 없음.
◼ 이것들이 콘텐츠 특징에 어떻게든 포함되지 않는 한.

**Page 310**
수업 종료

**Page 311**
머신 러닝:
연관 규칙 발견 알고리즘
Ok-Ran Jeong
2025년 가을

**Page 312**
로드맵
◼ 개요
◼ Apriori 알고리즘

**Page 313**
감사의 말
(참고 자료 링크 생략)

**Page 314**
연관 규칙 마이닝
◼ Rakesh Agrawal, Tomasz Imielinski, Arun Swami, Ramakrishnan Srikant에 의해 발명됨
◼ 처음에는 고객이 구매한 아이템들이 어떻게 연관되어 있는지 찾기 위한 장바구니 분석(Market Basket Analysis)에 사용됨.
◼ 범주형 데이터를 가정함.
◼ 수치 데이터에 대한 좋은 알고리즘은 없음.

**Page 315**
애플리케이션
◼ 추천 시스템
◼ 통신
◼ 각 고객은 통화 집합을 포함하는 트랜잭션임.
◼ 신용 카드/은행 서비스
◼ 각 카드/계좌는 고객의 지불 집합을 포함하는 트랜잭션임.
◼ 의료 치료
◼ 각 환자는 질병의 순서 집합을 포함하는 트랜잭션으로 표현됨.
◼ 농구 게임 분석
◼ 각 게임은 공 패스의 순서 집합을 포함하는 트랜잭션으로 표현됨.

**Page 316**
추천 시스템 예시
(그림 설명: 아마존의 "이 상품을 산 고객은 다음 상품도 샀습니다" 예시)

**Page 317**
연관 규칙이란 무엇인가?
◼ “무엇이 무엇과 함께 가는지”에 대한 규칙
◼ “X를 산 고객은 Y도 샀다”
◼ “어떤 증상이 어떤 진단과 함께 가는가”

**Page 318**
예시 트랜잭션 데이터셋:
휴대폰 페이스플레이트 구매
(표: 트랜잭션 ID와 구매한 페이스플레이트 색상)

**Page 319**
대체 데이터 형식: 이진 행렬
(표: 트랜잭션과 각 색상별 구매 여부(1/0))

**Page 320**
예시 트랜잭션 데이터셋:
장바구니
(목록: 각 트랜잭션(t1~t7)별 구매 아이템 목록)

**Page 321**
예시 “트랜잭션 데이터셋”
(문서 데이터셋)
◼ 텍스트 문서 데이터셋. 각 문서는 키워드의 “가방(bag)”으로 취급됨
(목록: 각 문서(doc1~doc7)별 키워드 목록)

**Page 322**
정의 (1/3)
◼ 트랜잭션 (예: 장바구니)
t1: {빵, 치즈, 우유}
t2: {사과, 계란, 소금, 요거트}
◼ 아이템은 트랜잭션 내의 항목/물품임.
◼ 아이템 집합(itemset)은 하나 이상의 아이템 모음임.
◼ (예) {우유, 빵, 기저귀}
◼ k-itemset은 k개의 아이템을 포함하는 아이템 집합임
◼ 트랜잭션은 (함께 구매된) 아이템들의 집합임.
◼ 트랜잭션 데이터셋(또는 데이터베이스)은 트랜잭션들의 집합임.

**Page 323**
정의 (2/3)
◼ 연관 규칙은 아이템 집합 X가 발생할 때, 아이템 집합 Y가 특정 확률로 발생한다는 것을 나타내는 패턴임.
(예: {빵, 치즈}  {우유})
◼ 연관 규칙에서, 아이템 집합 X는 선행(antecedent)이라 하고, 아이템 집합 Y는 후행(consequent)이라 함.

**Page 324**
예시
◼ 주어진 트랜잭션 데이터셋
(표: t1~t7 트랜잭션)
◼ 예시 연관 규칙
{옷} → {우유, 치킨}
{옷, 치킨} → {우유}

**Page 325**
정의 (3/3)
◼ 규칙 강도 척도
◼ 지지도(Support)(X): 아이템 집합 X를 포함하는 트랜잭션의 비율
◼ 신뢰도(Confidence)(XY): 아이템 집합 X를 포함하고 또한 아이템 집합 Y를 포함하는 트랜잭션의 비율.
◼ confidence = 확률(Y | X) = Support(X,Y)/Support(X)
◼ 향상도(Lift)(X  Y) : X와 Y가 함께 있는 것과 Y가 혼자 있는 것 사이의 비율
◼ Lift(XY)= confidence(X  Y) / support(Y)

**Page 326**
지지도와 신뢰도
◼ 트랜잭션 데이터셋
◼ 아이템 집합에 대한 지지도 (트랜잭션 데이터셋 내에서)
{치킨, 옷, 우유} [sup = 3/7]
◼ 아이템 집합에 대한 신뢰도 (트랜잭션 데이터셋 내에서)
{옷} → {우유, 치킨} [conf = 3/3]
{소고기, 치즈} → {치킨} [conf = 2/3]

**Page 327**
향상도 (Lift) (1/2)
 lift(X  Y) = confidence(X  Y) / support(Y)
(예) 규칙 {소고기, 치즈}  {치킨}의 향상도는
(2/3) / (5/7) = 0.93
◼ lift(X  Y)는 Y 단독 판매 비율 대비 X와 Y가 함께 판매되는 비율의 증가를 나타냄.
◼ lift가 1이면, X와 Y의 판매는 아이템 집합 내에서 상관관계가 없음.
◼ lift가 > 1이면, 아이템 집합 내에 양의 상관관계가 있음; 즉, X와 Y는 함께 구매될 가능성이 높음.
◼ lift가 < 1이면, 아이템 집합 내에 음의 상관관계가 있음; 즉, X와 Y는 함께 구매될 가능성이 낮음.

**Page 328**
향상도 (Lift) (2/2)
◼ lift가 <=1이면, 선행과 후행을 포함하는 규칙을 도출할 수 없음.
◼ lift가 > 1이면, 규칙은 미래 데이터셋에서 후행을 예측하는 데 잠재적으로 유용함.

**Page 329**
예시
◼ (링크 생략)
◼ 데이터셋
(표: A, B 값)
◼ 규칙 1: {A}  {0}
◼ 규칙 2: {B}  {1}
◼ 규칙 1에 대한 Lift: (3/4)/(4/7) = 1.31
◼ 규칙 2에 대한 Lift: (2/3)/(3/7) = 1.56

**Page 330**
연관 규칙 마이닝 작업
 트랜잭션 집합 T가 주어졌을 때, 연관 규칙 마이닝의 목표는 다음을 만족하는 모든 규칙을 찾는 것임
◼ 지지도 ≥ 최소 지지도(min-support) 임계값
◼ 신뢰도 ≥ 최소 신뢰도(min-confidence) 임계값

**Page 331**
많은 가능한 연관 규칙들
 (휴대폰 페이스플레이트 구매) 트랜잭션 1 (“red”, “white”, “green”)에서 가능한 규칙들
◼ “빨강이면, 하양” (“빨간 페이스플레이트가 구매되면, 하얀 것도 구매됨”)
◼ “하양이면, 빨강”
◼ “빨강이고 하양이면, 초록”
◼ + 그 외 다수

**Page 332**
빈발 아이템 집합(Frequent Itemset) 생성
◼ 무차별 대입(Brute force) 접근법
◼ 가능한 모든 연관 규칙 나열
◼ 각 규칙에 대한 지지도와 신뢰도 계산
◼ 최소 지지도 및 최소 신뢰도 임계값을 충족하지 못하는 규칙 가지치기(Prune)
⇒ 계산적으로 엄청남!

**Page 333**
일러스트레이션 (1/2)
◼ 트랜잭션 데이터베이스에 i개의 아이템이 주어지면, 2^i개의 가능한 후보 빈발 아이템 집합이 있음.
◼ (아래, i=5)
(그림 설명: 아이템 집합의 격자 구조)

**Page 334**
일러스트레이션 (2/2)
◼ 데이터베이스를 스캔하여 각 후보 빈발 아이템 집합의 지지도를 계산함
◼ 각 트랜잭션을 모든 후보와 대조함
◼ 복잡도 ~ O(NMw) => M = 2^i 이므로 비쌈 !!!

**Page 335**
더 나은 알고리즘이 필요함
 빈발 아이템 집합을 생성하기 위한 무차별 대입 접근법은 허용될 수 없음.
 두 가지 인기 있는 알고리즘이 있음.
 Apriori 알고리즘
 FP (Frequent Pattern) 성장 알고리즘

**Page 336**
로드맵
◼ 개요
◼ Apriori 알고리즘

**Page 337**
주요 관찰
 모든 규칙은 동일한 아이템 집합의 이진 분할임.
(예) {소고기, 치킨, 우유}는 다음을 제공함
{소고기, 치킨}  {우유}, {치킨, 우유}  {소고기},
{우유}  {치킨, 소고기}, 등.
(그 외 무엇이 가능한가?)
 동일한 아이템 집합에서 유래한 규칙들은 동일한 지지도를 갖지만 신뢰도는 다를 수 있음.
 따라서, 지지도와 신뢰도 요구사항을 분리할 수 있음.
 그리고 “빈발 아이템 집합”, 즉 높은 지지도를 가진 아이템 집합만 고려함. (즉, 높은 지지도를 갖지 않는 것들은 가지치기함)

**Page 338**
Apriori 알고리즘
 가장 널리 사용되는 연관 규칙 생성 알고리즘
 사용자가 지정한 지지도와 신뢰도를 충족하는 규칙 생성.
◼ 1단계: 빈발 아이템 집합(충분한 지지도를 가진 것들)을 찾음.
◼ 2단계: 이 아이템 집합들로부터 충분한 신뢰도를 가진 규칙을 생성함.

**Page 339**
일러스트레이션
(그림 설명: 빈발하지 않은 아이템 집합을 가지치기하는 과정)

**Page 340**
빈발 아이템 집합 생성
 k개 아이템에 대해,
 최소 지지도 기준(임계값)을 설정함.
 지지도 기준을 충족하는 1-itemsets 목록을 생성함.
 1-itemsets 목록을 사용하여 지지도 기준을 충족하는 2-itemsets 목록을 생성함.
 2-itemsets 목록을 사용하여 지지도 기준을 충족하는 3-itemsets 목록을 생성함.
 k-itemsets까지 반복함.

**Page 341**
참고
◼ 실제로는 연관 마이닝 알고리즘을 실행하기 전에 숫자 k, 연관 규칙의 최소 아이템 수(min_length)를 지정해야 함. (나중에 Python 코드 예제에서 이를 볼 것임.)

**Page 342**
관찰
◼ k가 증가함에 따라 지지도는 감소하므로, 생성해야 할 후보 아이템 집합의 수를 줄이는 것이 가능함

**Page 343**
예시: 빈발 아이템 집합 생성
(표 설명: 아이템별 카운트, 2-itemsets 카운트, 3-itemsets 카운트)
최소 지지도(minsup) = 3/6
모든 부분집합을 고려한다면,
6C1 + 6C2 + 6C3 = 41
지지도 기반 가지치기를 하면,
6 + 6 + 1 = 13

**Page 344**
k-Itemsets로부터 규칙 생성
◼ 각 규칙은 {item, item,…}  {item, item,..} 형태이며, (선행과 후행의) 총 아이템 수는 k임.
◼ 예를 들어, k = 3이면 다음 규칙들이 가능함
◼ {item1}  {item2, item3}
◼ {item2}  {item1, item3}
◼ {item3}  {item1, item2}
◼ {item1, item2}  {item3}
◼ {item1, item3}  {item2}
◼ {item2, item3}  {item1}

**Page 345**
예시:
아이템 집합으로부터 규칙 생성
아이템 집합: {red, white, green}
규칙 1:
{red, white} -> {green} 신뢰도 = 2/4 = 50%
◼ [(support {red, white, green})/(support {red, white})]
규칙 2:
{red, green} -> {white} 신뢰도 = 2/2 = 100%
◼ [(support {red, white, green})/(support {red, green})]
4개의 추가 규칙 (규칙 3, 4, 5, 6)
신뢰도 100%, 33%, 29% & 100%
신뢰도 기준이 70%라면, 규칙 2, 3, 6만 보고함

**Page 346**
워크스루 예제 (1/6)
◼ (링크 생략)
◼ 트랜잭션 데이터셋 (아래)
◼ 지지도 임계값=50%
◼ 신뢰도 임계값=80%
(표: TID와 아이템 목록)

**Page 347**
워크스루 예제 (2/6)
◼ (* 이 워크스루에서 트랜잭션 데이터베이스가 몇 번 스캔되는지 생각해보시오. *)
◼ 모든 1-item 후보를 생성하고 지지도 테스트를 적용함.
(표: itemset과 support, i4는 drop됨)

**Page 348**
워크스루 예제 (3/6)
◼ 가능한 모든 2-item 후보를 생성하고 지지도 테스트를 적용함.
(표: itemset과 support, i1,i2와 i1,i5는 drop됨)

**Page 349**
워크스루 예제 (4/6)
◼ 가능한 모든 3-item 후보를 생성하고 지지도 테스트를 적용함.
(표: itemset과 support, i2,i3,i5만 남음)

**Page 350**
워크스루 예제 (5/6)
◼ 살아남은 아이템 집합으로부터 가능한 모든 후보 규칙을 생성함.
◼ 그런 다음 신뢰도 테스트를 적용하여 최종 연관 규칙 집합을 결정함.
(표: 규칙, 지지도, 신뢰도. 신뢰도가 낮은 규칙들은 drop됨)

**Page 351**
워크스루 예제 (6/6)
◼ 발견된(마이닝된) 연관 규칙들.
(표: 최종 규칙 목록)

**Page 352**
연습문제
◼ Apriori 알고리즘을 사용하여 다음 트랜잭션 데이터베이스에 대한 연관 규칙을 찾으시오.
◼ 두 번 수행하시오. (규칙을 신뢰도 순으로 나열하시오.)
◼ 첫 번째, min_support = 41%; 그 다음 min_support = 61%.
◼ 각 반복(및 전체)에서 데이터베이스를 몇 번 스캔해야 하는가?

**Page 353**
코드 (1/8)
◼ (링크 생략)
◼ 라이브러리 로드
(코드 생략)

**Page 354**
코드 (2/8)
◼ 데이터 임포트
(코드 생략)

**Page 355**
코드 (3/8)
◼ 데이터 전처리
◼ Apriori는 데이터셋이 리스트의 리스트 형태여야 함.
◼ 현재 데이터는 Pandas 데이터프레임 형태임.
◼ Pandas 데이터 프레임을 리스트의 리스트로 변환하려면 다음 스크립트를 실행하시오:
(코드 생략)

**Page 356**
코드 (4/8)
◼ Apriori 매개변수 지정.
◼ min_support = 0.0053 (한 달에 적어도 40번 구매된 영화만 원한다고 가정. 40/7500 = 0.0053)
◼ min_confidence = 0.2
◼ min_lift = 3
◼ min_length = 2 (규칙에 원하는 최소 아이템 수)

**Page 357**
코드 (5/8)
◼ 다음 스크립트 실행
(코드 생략 - apriori 함수 실행)
# apriori 클래스에서 찾은 규칙을 보기 쉽게 리스트로 변환함.

**Page 358**
코드 (6/8)
◼ 결과 보기.
◼ apriori 클래스에 의해 마이닝된 총 규칙 수 찾기.
(코드 생략)
# 32개의 아이템 각각은 하나의 규칙에 해당함.

**Page 359**
코드 (7/8)
◼ 결과 보기.
◼ association_rules 리스트의 첫 번째 아이템을 출력하여 첫 번째 규칙 확인.
(코드 및 출력 결과 생략)
# 이 규칙은 Red Sparrow와 Green Lantern이 흔히 함께 구매됨을 보여줌.

**Page 360**
코드 (8/8)
◼ 규칙을 데이터 프레임에 더 읽기 쉽게 표시함.

**Page 361**
연습문제
◼ Apriori 알고리즘을 예제 트랜잭션 데이터베이스(52페이지에 표시됨)에서 추적하시오.
◼ 각 반복에서 후보를 보여주시오.
◼ 생성된 연관 규칙을 보여주고 신뢰도별로 정렬하시오.
◼ 각 반복(및 전체)에서 데이터베이스가 몇 번 스캔되는지 명시하시오.
◼ ** 지지도 임계값 = 1/3, 신뢰도 임계값 = 50% 사용.

**Page 362**
연습문제:
트랜잭션 데이터베이스
(표: TID와 아이템 목록)

**Page 363**
모듈 종료

**Page 364**
머신 러닝:
텍스트 처리 (Text Processing)
Ok-Ran Jeong
2025년 가을

**Page 365**
로드맵
◼ 개요
◼ 텍스트 표현의 수준
◼ 문서 벡터 공간 모델

**Page 366**
감사의 말
(참고 자료 링크 생략)

**Page 367**
텍스트 분석
◼ 텍스트 분석 (Text Analytics)
◼ 텍스트 요약 (Text Summarization)
◼ 텍스트 시각화 (Text Visualization)

**Page 368**
텍스트 분석
◼ 통계 및 자연어 처리(NLP) 기술 사용
◼ 단어 빈도 분포 분석
◼ 텍스트 특징 인식
◼ 사람, 조직, 장소,…
◼ 패턴 인식
◼ 전화번호, 이메일 주소, 측정 수치,…
◼ 개체-관계 추출
◼ 명사 참조,…
◼ 단어 동시 발생 분석

**Page 369**
애플리케이션
◼ 인터넷 검색
◼ 온라인 광고 자동 배치
◼ 소셜 미디어 모니터링
◼ 감성 분석
◼ 스팸 필터링
◼ 기계 번역
◼ 다음 단어 또는 단어 문맥 예측
◼ …

**Page 370**
텍스트 전처리
◼ 텍스트는 소프트웨어 알고리즘으로 처리하기 위해 숫자나 벡터로 변환되어야 함.
◼ 텍스트 처리 프레임워크 포함 사항
◼ 노이즈 제거
◼ 토큰화/분할/어휘 분석
◼ 정규화

**Page 371**
토큰화 (Tokenization)
◼ 긴 텍스트 문자열을 더 작은 조각(세그먼트 및 토큰)으로 분할
◼ 문단으로 – 문장으로 – 단어로
◼ 구두점 등은 세그먼트 종료 기호를 식별하기 어렵게 만듦.
◼ 구두점, 한두 글자 단어 제거
◼ 불용어(stop words) 제거
◼ 의미를 더하지 않는 빈번한 단어 (예: ‘a’, ‘the’, ‘in’, ‘of’, …)

**Page 372**
정규화 (Normalization)
◼ 텍스트의 모든 요소를 공통된 기반 위에 놓음
◼ 세 가지 주요 작업
◼ 어간 추출 (word stemming)
◼ 접두사, 접미사 등을 제거하여 단어 어간을 얻음.
◼ running  run, ended  end, unhappy  happy, lightly  light
◼ 표제어 추출 (lemmatization)
◼ 단어를 표준형으로 변환
◼ better  good, ran  run, finest  fine
◼ 그 외 모든 것
◼ 동일한 대소문자로 변환 (대문자, 소문자)
◼ 구두점 제거
◼ 숫자를 단어로 변환 (7  seven)
◼ 불용어 제거 (“a”, “the”, “is”, “are”, …)

**Page 373**
머신 러닝과 텍스트 처리
◼ 텍스트 분류
◼ K-최근접 이웃
◼ 로지스틱 회귀
◼ 서포트 벡터 머신
◼ 나이브 베이지안 분류기
◼ 신경망 (LSTM, BERT, GPT-3)
◼ 텍스트 클러스터링
◼ K-Means 클러스터링
◼ 계층적 병합 클러스터링
◼ EM (가우시안 혼합)

**Page 374**
텍스트 요약
◼ 두 가지 방법: 추출(extraction)과 추상화(abstraction)
◼ 추출 방법
◼ 키프레이즈(KeyPhrase) 방법
◼ 주어진 문서에서 단어와 구를 추출하여 태그 생성
◼ 문서 요약 방법
◼ 주어진 문서에서 문장을 추출하여 조립함
◼ 추상화 방법
◼ 주어진 문서에서 요약 문서를 자동으로 생성함
◼ (매우 어려움)

**Page 375**
예시
◼ 샘플 문서: (영어 원문 생략 - 허리케인 시즌 시작 전 뉴올리언스를 보호하겠다는 부시 대통령의 약속을 지키기 위해 서두르던 육군 공병대가 결함이 있는 홍수 조절 펌프를 설치했다는 내용)
◼ 추출 방법의 결과
◼ "Army Corps of Engineers", "President Bush", "New Orleans", "defective flood-control pumps"
◼ 추상화 방법의 결과
◼ "political negligence" (정치적 태만) 또는 "inadequate protection from floods" (홍수로부터의 부적절한 보호)

**Page 376**
텍스트 시각화
◼ 말뭉치(corpora) 내 주제에 대한 최상위 뷰를 제공함.
◼ 말뭉치 내 주제와 객체 간의 관계를 보여줌.
◼ 텍스트 콘텐츠의 고도로 구조화된 특성을 단순화된 방식으로 보여줌.
◼ 텍스트 문서의 고차원 공간의 주요 차원을 보여줌.

**Page 377**
무엇이 시각화되는가?
◼ 문서 컬렉션
◼ 문서 구조
◼ 검색 결과
◼ 문서 타임라인

**Page 378**
예시: 소셜 미디어 감성 대시보드
(그림 설명: 감성 분석 결과 시각화)

**Page 379**
예시: 의료 진단 데이터 시각화
(그림 설명: 의료 데이터 네트워크 시각화)

**Page 380**
시각화를 지원하는 데 사용되는 일반적인 기술
◼ 텍스트를 단어 가방(bag-of-words)으로 표현하고 클러스터링을 수행하여 구조를 식별한 다음, 이를 2D 또는 3D 공간에 매핑함 (예: MDS – 다차원 척도법 사용).
◼ 단어와 구의 빈번한 동시 발생을 찾아 그래프 등으로 시각화함.

**Page 381**
로드맵
◼ 개요
◼ 텍스트 표현의 수준
◼ 문서 벡터 공간 모델

**Page 382**
텍스트 표현의 수준
◼ 어휘 분석용 (토큰화)
◼ 문자
◼ 단어
◼ 구
◼ 품사 태그
◼ 분류 체계 / 시소러스
◼ 구문 분석용
◼ 벡터 공간 모델
◼ 언어 모델
◼ 전체 파싱
◼ 교차 양상(Cross-modality)
◼ 의미 분석용 (다루지 않음)
◼ 협업 태깅
◼ 템플릿 / 프레임
◼ 온톨로지 / 1차 이론

**Page 383**
어휘 분석 (Lexical Analysis)

**Page 384**
문자 수준 (Character Level)
◼ 텍스트의 문자 수준 표현은 문자들의 시퀀스로 구성됨.
◼ 문서는 시퀀스의 빈도 분포로 표현됨.
◼ 일반적으로 연속된 문자열을 다룸.
◼ 길이 1, 2, 3, ..의 각 문자 시퀀스는 빈도와 함께 특징을 나타냄.

**Page 385**
단어 수준 (Word Level)
◼ 많은 기술에 사용되는 가장 일반적인 텍스트 표현
◼ 텍스트를 단어로 분할하는 많은 토큰화 소프트웨어 패키지가 있음.
◼ 알아두어야 할 중요 사항:
◼ 단어는 서양 언어에서는 잘 정의된 단위임,
◼ 그러나 예: 중국어는 의미 단위의 개념이 다름.

**Page 386**
단어 속성
◼ 단어 표면 형태와 그 의미 간의 관계:
◼ 동음이의어(Homonym): 형태는 같으나 의미가 다름 (예: bank: 강둑, 금융 기관)
◼ 다의어(Polysemy): 형태는 같으나 여러 의미를 가짐 (예: bank: 혈액 은행, 금융 기관)
◼ 동의어(Synonym): 형태는 다르나 의미가 같음 (예: singer, vocalist)
◼ 하의어(Hyponym): 한 단어가 다른 단어의 하위 클래스를 나타냄 (예: breakfast, meal)
◼ 텍스트 내 단어 빈도는 거듭제곱 분포를 가짐:
◼ 매우 빈번한 소수의 단어
◼ 빈도가 낮은 다수의 단어

**Page 387**
불용어 (Stop Words)
◼ 불용어는 비언어적 관점에서 정보를 전달하지 않는 단어임
◼ 주로 기능적인 역할을 함.
◼ 일반적으로 방법의 성능을 높이기 위해 제거함.
◼ 불용어는 언어에 따라 다름: 예시
◼ 영어: a, about, above, across, after, again, against, all, almost, alone, along, already, ...
◼ 네덜란드어: de, en, van, ik, te, dat, die, in, een, hij, het, niet, zijn, is, was, op, aan, met, als, voor, had, er, maar, om, hem, dan, zou, of, wat, mijn, men, dit, zo, ...
◼ 슬로베니아어: a, ah, aha, ali, ampak, baje, bodisi, bojda, bržkone, bržčas, brez, celo, da, do, ...

**Page 388**
어간 추출 (Stemming) (1/2)
◼ 같은 단어의 다른 형태는 텍스트 분석에 문제가 됨. 철자는 다르지만 의미가 비슷하기 때문임 (예: learns, learned, learning,…)
◼ 어간 추출은 단어를 어간(정규화된 형태)으로 변환하는 과정임
◼ 어간 추출은 단어를 병합하는 저렴한 메커니즘을 제공함.

**Page 389**
어간 추출 (2/2)
◼ 영어의 경우 Porter stemmer가 가장 널리 사용됨 (링크 생략)
◼ 영어 Porter stemmer에서 사용되는 계단식 규칙 예시
◼ ational -> ate, relational -> relate
◼ tional -> tion, conditional -> condition
◼ enci -> ence, valenci -> valence
◼ anci -> ance, hesitanci -> hesitance
◼ izer -> ize, digitizer -> digitize
◼ abli -> able, conformabli -> conformable
◼ alli -> al, radicalli -> radical
◼ entli -> ent, differentli -> different
◼ eli -> e, vileli -> vile
◼ ousli -> ous, analogousli -> analogous

**Page 390**
NLTK (Natural Language Tool Kit) 라이브러리를 사용한 텍스트 전처리 (1/3)
(링크 생략)
(코드 생략 - NLTK 임포트, 데이터 로드, 토큰화)

**Page 391**
NLTK (Natural Language Tool Kit) 라이브러리를 사용한 텍스트 전처리 (2/3)
# 단어의 빈도 분포 가져오기
(코드 생략)
# 빈도 분포 정렬 및 상위 50개 빈번한 단어 출력
(코드 생략)
# 출력

**Page 392**
NLTK (Natural Language Tool Kit) 라이브러리를 사용한 텍스트 전처리 (3/3)
# 한 글자 및 두 글자 단어 제거
(코드 생략)
# 불용어 제거
(코드 생략)
# 불용어 제거 후 상위 50개 단어

**Page 393**
구 수준 (Phrase Level)
◼ 단일 단어 대신 구를 다룰 수 있음.
◼ 두 가지 유형의 구를 사용할 수 있음:
◼ 빈번한 연속 단어 시퀀스로서의 구
◼ 빈번한 비연속 단어 시퀀스로서의 구
◼ 두 유형의 구 모두 간단한 동적 프로그래밍 알고리즘으로 식별할 수 있음.
◼ 구를 사용하는 주된 효과는 의미를 더 정확하게 식별하는 것임.

**Page 394**
예시: Google n-grams
(단어 시퀀스 및 빈도 예시 목록)

**Page 395**
품사 수준 (Part-of-Speech Level)
◼ 품사(단어의 범주; 명사, 동사, 형용사, …) 태그를 도입하여 단어의 기능을 구별하는 단어 유형을 도입함.
◼ 텍스트 분석에서 품사 정보는 주로 “정보 추출”에 사용되며, 여기서 우리는 예: 명사구 식별에 관심이 있음.
◼ 또 다른 가능한 용도는 어휘(특징)의 축소임
◼ 명사는 텍스트 문서에서 대부분의 정보를 전달함.
◼ 품사 태거는 일반적으로 수동으로 태그된 데이터에 대해 HMM(은닉 마르코프 모델) 알고리즘으로 학습됨.

**Page 396**
품사 예시
(그림 설명: 문장 내 단어들의 품사 태깅 예시)

**Page 397**
품사 표
(표 설명: 품사, 기능, 예시 단어, 예시 문장)

**Page 398**
분류 체계/시소러스 수준
◼ 시소러스는 같은 의미를 가진 다른 단어 형태를 하나의 의미(동의어)로 연결하는 주요 기능을 가짐
◼ 또한, 상위어(하의어의 반대) 관계를 사용하여 일반적인 단어 의미와 구체적인 단어 의미를 연관시킬 수 있음.
◼ 동의어와 상위어 관계를 사용하여 문서 특징 벡터를 압축할 수 있음.
◼ 가장 널리 사용되는 일반 시소러스는 WordNet이며, 이는 많은 언어로 존재함 (예: EuroWordNet)
◼ (링크 생략)
* 단어 의미(word sense)는 단어의 의미 중 하나임.
* 시소러스 또는 동의어 사전은 단어의 동의어 및 때로는 반의어를 찾기 위한 참조 저작물임.

**Page 399**
WordNet:
어휘 관계 데이터베이스
◼ WordNet은 영어에 대해 가장 잘 개발되고 널리 사용되는 어휘 데이터베이스임.
◼ 4개의 데이터베이스(명사, 동사, 형용사, 부사)로 구성됨
◼ 각 데이터베이스는 의미 항목으로 구성됨 – 각 의미는 동의어 집합으로 구성됨:
예:
◼ musician, instrumentalist, player
◼ person, individual, someone
◼ life form, organism, being
(표: 카테고리별 고유 형태 수 및 의미 수)

**Page 400**
WordNet – 단어 그래프 발췌
(그림 설명: WordNet의 단어 관계 그래프 예시)

**Page 401**
WordNet 관계
◼ 각 WordNet 항목은 관계를 통해 단어 그래프의 다른 항목과 연결됨.
◼ 명사 데이터베이스의 관계:
(표: 관계, 정의, 예시)
Hypernym (상위어): 하위 개념에서 상위 개념으로 (breakfast → meal)
Hyponym (하의어): 개념에서 하위 개념으로 (meal → lunch)
Has-Member: 그룹에서 구성원으로 (faculty → professor)
Member-Of: 구성원에서 그룹으로 (copilot → crew)
Has-Part: 전체에서 부분으로 (table → leg)
Part-Of: 부분에서 전체로 (course → meal)
Antonym (반의어): 반대말 (leader → follower)

**Page 402**
구문 분석 (Syntactic Analysis)

**Page 403**
벡터 공간 모델 수준
◼ 문서를 다루는 가장 일반적인 방법은 먼저 희소 숫자 벡터로 변환한 다음 선형 대수 연산으로 처리하는 것임.
◼ 이를 통해 텍스트 내의 언어적 구조에 대한 모든 것을 잊어버림.
◼ 이 표현은 “단어 가방(Bag-of-Words)” 또는 “벡터 공간 모델(Vector-Space-Model)”이라고 함.
◼ 벡터 공간 모델의 일반적인 작업은 분류, 클러스터링, 시각화 등임.

**Page 404**
언어 모델 수준
◼ 언어 모델링은 단어 시퀀스의 확률을 결정하는 것에 관한 것임.
◼ 작업은 일반적으로 이전 두 단어가 주어졌을 때 다음 단어의 확률을 추정하는 것으로 축소됨 (tri-gram 모델):
(수식 생략)
단어 시퀀스의 빈도

**Page 405**
단어 시퀀스에 대한 확률 분포
◼ 문자열을 생성하는 데 사용할 수 있음
(수식 생략)
◼ 가능한 문장의 순위를 매기는 데 사용할 수 있음
◼ P(“Today is Tuesday”) > P(“Tuesday Today is”)
◼ P(“Today is Tuesday”) > P(“Today is Virginia”)

**Page 406**
애플리케이션
◼ 다음을 포함한 많은 애플리케이션
◼ 음성 인식
◼ OCR (광학 문자 인식)
◼ 필기 인식
◼ 기계 번역
◼ 철자 교정
◼ …

**Page 407**
전체 파싱 수준 (Full-Parsing Level)
◼ 파싱은 문장당 최대 구조 정보를 제공함.
◼ 입력은 문장이고, 출력은 파스 트리(parse tree)임.
◼ 텍스트를 다루는 대부분의 방법에서 파스 트리의 정보는 너무 복잡함.

**Page 408**
교차 양상 수준 (Cross-Modality Level)
◼ 객체가 다른 데이터 유형으로 표현되는 경우가 매우 많음:
◼ 텍스트 문서
◼ 다국어 텍스트 문서
◼ 이미지
◼ 비디오
◼ 소셜 네트워크 데이터
◼ 센서 네트워크 데이터
◼ 목표는 서로 다른 표현 간의 매핑을 생성하고 상관관계를 맺어 동일한 객체에 대해 더 풍부한 정보를 갖는 것임.

**Page 409**
예시: 텍스트와 오디오, 이미지 및 비디오 상관관계
◼ 단어 “tie”는 여러 표현을 가짐.
◼ 텍스트
◼ 다국어 텍스트
◼ 오디오
◼ 이미지:
◼ (링크 생략)
◼ 비디오 (오른쪽 영화)
◼ 각 표현에서 특징 집합을 얻고 상관관계를 맺을 수 있음.
◼ KCCA (커널 상관 분석) 방법은 서로 다른 표현 간의 매핑을 생성하여 “양상 중립적(modality neutral)” 데이터 표현으로 만듦
(그림 설명: 넥타이 이미지와 시각적 단어 매핑)

**Page 410**
로드맵
◼ 개요
◼ 텍스트 표현의 수준
◼ 문서 벡터 공간 모델

**Page 411**
감사의 말
(참고 자료 링크 생략)

**Page 412**
기초

**Page 413**
문서를 단어 가방(및 단어 빈도)으로 표현하기
(그림 설명: 텍스트 문서를 단어 빈도 목록으로 변환하는 과정)

**Page 414**
왜 단어 가방인가?
◼ 단어만으로도 내용에 대해 많은 것을 알 수 있음.
◼ 정보 요구를 설명하는 단어를 떠올리기 비교적 쉬움.
(예시: 검색어와 실제 문장 비교)

**Page 415**
문서 벡터 공간 모델의 요소
◼ 용어(단어) 빈도 (TF)
◼ 용어 빈도 벡터
◼ 로그 용어 빈도
◼ 문서 빈도 (DF)
◼ 역 문서 빈도 (IDF)
◼ 쿼리-문서 매칭 점수

**Page 416**
텍스트를 용어 빈도 벡터로 표현하기
◼ 단어 가방은 벡터로 표현될 수 있음.
◼ 계산 효율성과 조작 용이성을 위해
◼ 벡터는 일관된 순서로 기록된 값들의 집합임.
“The quick brown fox jumped over the lazy dog’s back”
→ [ 1 1 1 1 1 1 1 1 2 ]
(각 위치에 해당하는 단어 설명)

**Page 417**
용어 빈도 tf
◼ 문서 d에서 용어 t의 용어 빈도 tft,d는 t가 d에서 발생하는 횟수로 정의됨.
◼ 쿼리-문서 매칭 점수를 계산할 때 tf를 사용하고 싶음. 하지만 어떻게?
◼ 원시(Raw) 용어 빈도는 우리가 원하는 것이 아님:
◼ 용어가 10번 발생하는 문서는 1번 발생하는 문서보다 더 관련성이 높을 수 있음.
◼ 하지만 10배 더 관련성이 높은 것은 아님.
◼ 관련성은 용어 빈도에 비례하여 증가하지 않음.

**Page 418**
로그 빈도 가중치
◼ d에서 용어 t의 로그 빈도 가중치는 다음과 같음
(수식 생략)
◼ 0 → 0, 1 → 1, 2 → 1.3, 10 → 2, 1000 → 4 등.
◼ 문서-쿼리 (q, d) 쌍에 대한 점수:
◼ q와 d 모두에 있는 용어 t에 대한 합:
◼ score = (수식 생략)
◼ 문서에 쿼리 용어가 하나도 없으면 점수는 0임.

**Page 419**
벡터 공간 모델
ti: 용어
dj: 문서
θ: 문서 간의 유사도
(그림 설명: 벡터 공간에서의 문서 벡터와 각도)

**Page 420**
벡터로서의 문서
◼ 우리는 |V|차원 벡터 공간을 가짐.
◼ 용어는 공간의 축임.
◼ 문서는 이 공간의 점 또는 벡터임.
◼ 이것은 매우 고차원적인 공간임.
◼ 웹 검색 엔진에 적용할 때 수억 차원임.
◼ 또한 매우 희소한 벡터임 (대부분의 항목이 0임).

**Page 421**
문서 빈도
◼ 희귀한 용어는 빈번한 용어보다 더 많은 정보를 제공함.
◼ 불용어를 상기하시오 (즉, 불용어는 정보를 제공하지 않음).
◼ 컬렉션에서 희귀한 쿼리 용어를 고려하시오 (예: arachnocentric). (* arachn = 거미)
◼ 이 용어를 포함하는 문서는 쿼리 arachnocentric과 관련이 있을 가능성이 매우 높음.
◼ 따라서 arachnocentric과 같은 희귀 용어에 더 높은 가중치를 부여해야 함.

**Page 422**
문서 빈도 (계속)
◼ 컬렉션에서 빈번한 쿼리 용어를 고려하시오 (예: high, increase, line).
◼ 이러한 용어를 포함하는 문서는 그렇지 않은 문서보다 관련성이 높을 가능성이 있지만, 관련성의 확실한 지표는 아님.
◼ 빈번한 용어의 경우, high, increase, line과 같은 단어에 대해 양의 가중치를 원하지만 희귀 용어보다는 낮은 가중치를 원함.
◼ 점수에서 이를 포착하기 위해 문서 빈도(df)를 사용할 것임.
◼ df (≤ N)는 용어를 포함하는 문서의 수임.

**Page 423**
idf 가중치
◼ dft는 t의 문서 빈도, 즉 t를 포함하는 문서의 수임.
◼ df는 t의 정보성 척도임.
◼ t의 idf (역 문서 빈도)를 다음과 같이 정의함
(수식 생략)
◼ idf의 효과를 “약화시키기” 위해 N/dft 대신 log N/dft를 사용함.
◼ 로그의 밑은 중요하지 않음.

**Page 424**
idf 예시 (N = 1,000,000일 때)
(표: 용어, dft, idft 값)
컬렉션 내 각 용어 t에 대해 하나의 idf 값이 있음.

**Page 425**
tf-idf 가중치
◼ 용어의 tf-idf 가중치는 tf 가중치와 idf 가중치의 곱임.
◼ 정보 검색에서 가장 잘 알려진 가중치 체계
◼ 참고: tf-idf의 “-”는 하이픈이며 빼기 기호가 아님!
◼ 다른 이름: tf.idf, tf x idf
(수식 생략)
wt,d 문서 d에서 용어 t에 할당된 가중치
tft,d 문서 d에서 용어 t의 발생 횟수
N 전체 컬렉션의 문서 수
dft 용어 t를 가진 문서 수

**Page 426**
참고
◼ 때때로 용어 빈도가 작을 때, 로그 없이 용어 빈도 가중치를 사용함.
◼ (링크 생략)
Wt,d = tft,d x log N / dft

**Page 427**
용어-문서 카운트 행렬
◼ 각 문서에 n개의 용어가 있다면, 각 문서는 길이 n의 벡터로 표현될 수 있음.
◼ 벡터의 각 요소는 (용어, 용어 빈도) 쌍임.
(표: 문서별 단어 빈도 행렬)

**Page 428**
용어 빈도를 tf-idf 가중치로 변환
(표: tf-idf 가중치로 변환된 행렬)
각 문서는 이제 tf-idf 가중치의 실수 값 벡터로 표현됨

**Page 429**
Scikit-learn을 사용한 TF-IDF 행렬 계산 (1/3)
(링크 생략)
# 영화 리뷰를 ‘review’라는 이름의 Pandas 데이터 프레임으로 로드했다고 가정함 (세부 사항은 위 참조; p.27의 이전 코드 참조)
# 리뷰 데이터셋을 감성 분석을 위해 훈련 및 테스트 세트로 분할했다고 가정함:
(코드 생략)

**Page 430**
Scikit-learn을 사용한 TF-IDF 계산 (2/3)
(코드 생략 - TfidfVectorizer 임포트 및 모델 생성, 훈련 데이터 및 테스트 데이터 변환)

**Page 431**
Scikit-learn을 사용한 TF-IDF 계산 (3/3)
# (완전성을 위해, TF-IDF 벡터는 감성 분석에 사용됨)
# 참조는 이 목적을 위해 기본 Naïve Bayes 분류기 모델이 어떻게 훈련되는지 보여줌
(코드 생략 - 모델 훈련 및 예측, 정확도 출력)

**Page 432**
쿼리와 문서 매칭

**Page 433**
쿼리-문서 매칭 점수
◼ 문서가 주어진 쿼리와 얼마나 잘 일치하는지 측정하기 위해 쿼리-문서 쌍에 점수를 할당하는 방법이 필요함.
◼ 쿼리 용어가 문서에 없으면: 점수는 0임.
◼ 문서 내 쿼리 용어가 빈번할수록 점수가 높음.

**Page 434**
벡터 공간 모델
가정: 벡터 공간에서 “가까이 있는” 문서는 같은 것에 대해 “이야기함”
(그림 설명: 벡터 공간에서의 문서 간 거리 및 각도)
따라서, 문서가 쿼리에 얼마나 가까운지(즉, 유사성 ~ “근접성”)에 따라 문서를 검색함

**Page 435**
쿼리와 문서를 어떻게 매칭하는가?
◼ 핵심 아이디어 1: (문서와 마찬가지로) 쿼리를 벡터 공간의 벡터로 표현함.
◼ 핵심 아이디어 2: 이 공간에서 쿼리와의 근접성에 따라 문서의 순위를 매김.
◼ 근접성 = 벡터의 유사성
◼ 덜 관련된 문서보다 더 관련된 문서의 순위를 높게 매김.

**Page 436**
근접성을 어떻게 측정하는가?
◼ 단순히 유클리드 거리를 사용할 수 있는가?
◼ (두 벡터의 끝점 사이의 거리)
◼ 이것은 나쁜 생각임. 왜냐하면 유클리드 거리는 길이가 다른 벡터에 대해 크기 때문임.

**Page 437**
유사성 척도로 각도 사용
◼ 사고 실험:
문서 d를 가져와서 그 자체에 덧붙임.
이 새 문서를 d′라고 부름.
◼ 의미적으로 d와 d′는 같은 내용을 가짐.
◼ 그러나 두 문서 사이의 유클리드 거리는 꽤 클 수 있음.
◼ 두 문서(d와 d’) 사이의 “각도”는 0이며, 이는 최대 유사성에 해당함.
◼ 쿼리와의 각도에 따라 문서의 순위를 매겨보자.

**Page 438**
쿼리(q)와 문서(d) 사이의 유클리드 거리 vs. 각도(θ)
쿼리 q의 용어 분포와 문서 d2의 용어 분포가 매우 유사하더라도 q와 d2 사이의 유클리드 거리는 큼.

**Page 439**
각도에 코사인 사용
◼ 다음 두 개념은 동일함.
◼ 쿼리와 문서 사이의 각도의 내림차순으로 문서 순위 매기기.
◼ cosine(query, document)의 오름차순으로 문서 순위 매기기.
◼ 코사인은 [0°, 180°] 구간에서 단조 감소 함수임.

**Page 440**
Cosine(query, document)
(수식 설명: 코사인 유사도 공식. 내적을 벡터의 크기 곱으로 나눔)
qi는 쿼리에서 용어 i의 tf-idf 가중치임.
di는 문서에서 용어 i의 tf-idf 가중치임.
cos(q, d)는 q와 d의 코사인 유사도임
… 또는 동등하게, q와 d 사이 각도의 코사인임.

**Page 441**
벡터 길이 정규화 필요
◼ 벡터는 각 성분을 길이(크기)로 나누어 정규화할 수 있음.
◼ 이를 위해 L2 노름을 사용함. 즉, 벡터의 길이는 각 성분의 제곱합의 제곱근임:
(수식 생략)
◼ 벡터를 L2 노름으로 나누면 단위(길이) 벡터가 됨.
◼ 두 문서 d와 d′(예: d가 자체에 덧붙여짐)에 미치는 영향: 길이 정규화 후 동일한 벡터를 가짐.

**Page 442**
벡터 길이 정규화:
일러스트레이션
(그림 설명: 4요소 벡터의 정규화 전후 값 비교)

**Page 443**
예시: 3개 문서 간의 코사인 유사도
(표: SaS, PaP, WH 문서의 단어 빈도)
소설들이 얼마나 유사한가?
SaS: Sense and Sensibility (이성과 감성)
PaP: Pride and Prejudice (오만과 편견)
WH: Wuthering Heights (폭풍의 언덕)
참고: idf 가중치는 무시함; 즉, idf=1로 가정함.

**Page 444**
예시 (계속)
로그 빈도 가중치
(표: 로그 가중치 적용 후 값)
정규화 후
(표: 정규화 후 값)
cos(SaS,PaP) ≈ 0.94
cos(SaS,WH) ≈ 0.79
cos(PaP,WH) ≈ 0.69
왜 cos(SaS,PaP) > cos(SAS,WH)인가?

**Page 445**
예시: 4개 문서의 tf-idf
(표: tf 값, idf 값, 계산된 Wi,j 값)

**Page 446**
tf-idf 정규화
(표: 정규화된 W'i,j 값 계산 과정)

**Page 447**
쿼리와 문서 매칭
쿼리: “contaminated, retrieval”
(표: 쿼리 벡터와 문서 벡터 간의 유사도 점수 계산 및 순위)
순위 목록: Doc 2, Doc 4, Doc 1, Doc 3

**Page 448**
가중 검색
쿼리: contaminated(3), retrieval
쿼리 벡터에 다른 용어 가중치를 할당하여 쿼리 용어에 가중치를 둠.
(표: 가중치가 적용된 쿼리 벡터와 문서 벡터 간의 유사도 점수 계산 및 순위)
순위 목록: Doc 2, Doc 1, Doc 4, Doc 3

**Page 449**
워크스루 예제 (1/5)
◼ 3개의 (사소한) 문서가 있음
◼ d1: “new york times”
◼ d2: “new york post”
◼ d3: “los angeles times”

**Page 450**
워크스루 예제 (2/5)
◼ TFs (표)
◼ IDF (계산 값)

**Page 451**
워크스루 예제 (3/5)
◼ TF x IDF (표)

**Page 452**
워크스루 예제 (4/5)
◼ 쿼리: “new york times”
◼ 쿼리의 TF-IDF
◼ ** (angeles los new post times york)에 대해
◼ 0 0 1*0.176=0.176 0 1*0.176=0.176 1*0.176=0.176

**Page 453**
워크스루 예제 (5/5)
◼ 문서의 길이
(계산 생략)
◼ 유사도 값
(계산 생략)

**Page 454**
연습문제
◼ 벡터 공간 모델을 사용하여 다음 쿼리와 일치하는 문서의 순위를 계산하시오.
◼ 쿼리
◼ “fake novel”
◼ 문서
◼ doc-1: “twitter fake”
◼ doc-2: “fake news”
◼ doc-3: “clancy novel”
◼ doc-4: “fake picaso”

**Page 455**
Python 코드 예제 (1/6)
◼ (링크 생략)
◼ Python 모듈 임포트
(코드 생략)

**Page 456**
Python 코드 예제 (2/6)
(코드 생략 - 텍스트 파일 읽기 및 문장 분리)
◼ ‘beatles_biography.txt’ 파일에서 데이터를 가져와 텍스트 파일을 파싱하여 문장을 얻음.
◼ 정규 표현식이 마크를 사용하여 문장을 분리하고, 문장은 sentences 객체에 저장됨.

**Page 457**
Python 코드 예제 (3/6)
(코드 생략 - CountVectorizer 사용)
## CountVectorizer는 텍스트 문서 컬렉션을 토큰 카운트 행렬로 변환함; p.87 참조
## 매개변수는 다음 페이지에 설명됨

**Page 458**
Python 코드 예제 (4/6)
◼ CountVectorizer 메서드의 4가지 매개변수.
◼ stop_words는 많이 발생하지만 필요한 정보를 포함하지 않는 단어를 제거함. 단어를 제거하고 싶지 않으면 ‘None’을 줄 수 있고, 불용어 리스트를 제공할 수도 있음. Scikit-learn에는 영어 불용어 리스트가 내장되어 있음.
◼ min_df는 min_df보다 낮은 문서 빈도를 가진 용어를 무시하는 임계값임.
◼ max_df는 min_df의 반대임. 단어의 문서 빈도가 max_df보다 높으면 무시함.
◼ ngram_range(x,y)는 다른 n-그램에 대한 n 값의 경계를 정의함. x는 최소 n 값, y는 n-그램의 최대 n 값을 나타냄.
◼ fit_transform은 문장의 변환된 버전을 반환함.

**Page 459**
Python 코드 예제 (5/6)
(코드 생략 - TfidfTransformer 사용)
◼ 카운트 행렬을 정규화된 TF 또는 TF-IDF 표현으로 변환하여 가중치를 측정함.
◼ 가장 높은 가중치를 가진 단어가 문서에 대한 더 많은 정보를 제공함.
◼ 변환이 끝나면 용어와 그 순위로 구성된 리스트를 얻음.

**Page 460**
참고
◼ 이 코드에서는 CountVectorizer와 TfidfTransformer 클래스가 사용됨.
◼ CountVectorizer는 텍스트 문서 컬렉션을 토큰 카운트 행렬로 변환함.
◼ TfidfTransformer는 CountVectorizer의 결과(카운트 행렬)를 정규화된 TF 또는 TF-IDF 표현으로 변환함.
◼ p.67의 코드는 TfidfVectorizer를 사용하여 CountVectorizer와 TfidfTransformer의 작업을 수행함.

**Page 461**
Python 코드 예제 (6/6)
(코드 생략 - 상위 10개 단어 출력)
◼ 주어진 문서에서 상위 10개 단어를 출력함.

**Page 462**
프로그래밍 과제
◼ 벡터 공간 모델을 사용하여 다음 쿼리와 일치하는 문서의 순위를 매기시오.
◼ 쿼리
◼ “fake news corona vaccine”
◼ 5개 문서
◼ ML-2025-text-vectorspace-dataset (WORD 파일)
◼ (* 쉽게 붙여넣기 할 수 있도록 별도 제공됨)

**Page 463**
모듈 종료

**Page 464**
머신 러닝:
베이지안 분류기(Bayesian Classifier)와 마르코프 모델(Markov Model)
Ok-Ran Jeong
2025년 가을

**Page 465**
로드맵
◼ 나이브 베이지안 분류기 (Naïve Bayesian Classifier)
◼ 마르코프 모델 (Markov Model)

**Page 466**
베이지안 분류기
◼ 분류를 위한 통계적 방법
◼ 지도 학습 방법
◼ 베이즈 규칙을 기본 확률 모델로 가정함

**Page 467**
감사의 말
(참고 자료 링크 생략)

**Page 468**
베이지안 분류
◼ 분류를 위한 통계적 방법
◼ 지도 학습 방법
◼ 베이즈 규칙을 기본 확률 모델로 가정함

**Page 469**
분류 문제
◼ 문제 진술:
◼ 특징 X1, X2, …, Xn이 주어졌을 때
◼ 레이블 Y를 예측하라
◼ 예시
◼ 특징 X1, X2, X3가 주어짐: 소득이 $40,000이고 신용 등급이 양호한 35세 고객.
◼ Y 예측: 이 고객이 새 컴퓨터를 살 것인가?

**Page 470**
베이즈 규칙에 기초함
◼ 베이즈 규칙 (정리):
(수식 생략)
◼ P(Y|X) : 나이, 신용 등급, 소득을 알고 있을 때 고객이 컴퓨터를 살 확률. (Y의 사후 확률)
◼ P(Y) : 나이, 신용 등급, 소득에 관계없이 고객이 컴퓨터를 살 확률 (Y의 사전 확률)
◼ P(X|Y) : 고객이 우리 컴퓨터를 샀다는 조건 하에, 그 고객이 35세이고 신용 등급이 양호하며 $40,000를 벌 확률 (X의 우도 확률)
◼ P(X) : 우리 고객 집합에서 어떤 사람이 35세이고 신용 등급이 양호하며 $40,000를 벌 확률. (X의 증거 확률)

**Page 471**
참고: 사후 확률과 사전 확률
◼ 사후 확률(Posterior probability)은 모든 증거 또는 배경 정보를 고려한 후 사건이 발생할 확률임.
◼ 사전 확률(Prior probability)은 새로운 증거를 고려하기 전에 사건이 발생할 확률임.

**Page 472**
베이지안 분류기의 요소
◼ D: 튜플(샘플) X의 집합
◼ X: n차원 속성 벡터
{x1,x2,x3,…,xn}, 여기서 xi는 속성 Ai의 값임
◼ m개의 클래스: C1,C2,C3,…,Cm
◼ 베이지안 분류기는 X가 클래스 Ci에 속한다고 예측함 (조건: P(Ci|X) > P(Cj|X), 1 ≤ j ≤ m, j ≠ i 일 때)
◼ 최대 사후 확률 (MAP) 규칙
(수식 생략)
P(X|Ci)P(Ci)를 최대화함, P(X)는 상수이므로.

**Page 473**
나이브 베이지안 모델
◼ 일반적으로 일부 증상 변수(증거, 즉 특징 또는 독립 변수)는 원인에 의존할 뿐만 아니라 서로 의존적임.
◼ 그러나 의존성 그래프가 깊어질수록 조건부 확률 테이블이 감당할 수 없을 정도로 커짐.
◼ 나이브 베이지안 모델은 원인이 주어졌을 때 증상들의 독립성을 가정함.
◼ 나이브 베이지안은 추론을 더 쉽게 만드는 베이지안 네트워크의 특수한 경우임.

**Page 474**
나이브 베이지안 분류기
◼ n(즉, 특징의 수)이 크면 P(X | Ci)를 평가하는 데 비용이 많이 듦
◼ (순진하게) 클래스 조건부 독립성을 가정함
(수식 생략)

**Page 475**
예시 1: 사람이 테니스를 칠지 예측하기
PlayTennis: 훈련 예제
(표: 날씨 조건에 따른 테니스 플레이 여부 데이터)

**Page 476**
튜플, 속성, 클래스
◼ 14개 튜플 (즉, 샘플, 데이터 레코드)
◼ 각 튜플에 대한 4개 속성
◼ outlook(전망), temperature(온도), humidity(습도), wind(바람)
◼ 2개 클래스
◼ PlayTennis-Yes, PlayTennis-No

**Page 477**
예시 1: 학습 단계
(각 속성 대 클래스에 대한 빈도 테이블 구성)
(표: 각 속성별 Yes/No 확률 계산)
P(Play=Yes) = 9/14
P(Play=No) = 5/14

**Page 478**
예시 1: 테스트 단계
- 새로운 인스턴스가 주어졌을 때, 레이블(클래스) 예측
x´=(Outlook=Sunny, Temperature=Cool, Humidity=High, Wind=Strong)
- 학습 단계에서 생성된 테이블 조회
- MAP 규칙을 사용한 의사 결정
(확률 계산 과정 생략)
P(Yes|x´) < P(No|x´) 이므로, x´를 “No”로 라벨링함.

**Page 479**
수업 중 연습문제: 독감 진단
(표: 독감 증상 데이터)
? M Y N N N
(그림: 베이지안 네트워크 구조)

**Page 480**
튜플, 속성, 클래스
◼ 4개 튜플
◼ 각 튜플에 대한 5개 속성
◼ fever(열), sinus(부비동), ache(통증), swell(부기), headache(두통)
◼ 2개 클래스
◼ Flu-Yes, Flu-No

**Page 481**
해결: 학습 단계
(표: 각 증상별 Flu=Y/N 확률 계산)
P(flu=Y) = 3/4 P(flu=N) = 1/4

**Page 482**
해결 (계속)
(확률 계산 과정 생략)
MAP 규칙을 사용한 의사 결정
P(flu=Y|X) > P(flu=N|X) 이므로, X를 “Y”로 라벨링함.

**Page 483**
참고: 라플라스 보정 (Laplace Correction)
◼ 많은 특징을 가진 모델이 있을 때, 특징 중 하나의 값이 0이면 전체 확률이 0이 될 수 있음.
◼ 이를 피하기 위해, 0인 변수의 카운트를 분자에서 작은 값(분자가 크면 보통 1)만큼 증가시켜 전체 확률이 0이 되지 않도록 함.
◼ 이 보정은 프랑스 수학자 피에르-시몽 라플라스(1749-1827)의 이름을 따서 라플라스 보정이라고 함.

**Page 484**
나이브 베이지안의 장점
◼ 알고리즘이 얼마나 확신하는지 알려주는 확률을 반환함
◼ 구현하기 쉽고, 작은 훈련 데이터셋에 대해 종종 좋은 선택임
(그래프: 훈련 세트 크기에 따른 정확도)

**Page 485**
코드 (1/5)
◼ (링크 생략)
◼ 데이터셋 정의
(코드 생략 - 날씨, 온도, 플레이 여부 데이터 정의)

**Page 486**
코드 (2/5)
◼ 특징 인코딩
(코드 생략 - LabelEncoder 사용)

**Page 487**
코드 (3/5)
◼ 유사하게, temp와 play 특징 인코딩
(코드 생략)

**Page 488**
코드 (4/5)
◼ 두 특징(weather와 temp)을 단일 변수(튜플 리스트)로 결합
(코드 생략)

**Page 489**
코드 (5/5)
◼ 모델 생성, 학습 및 예측.
(코드 생략 - GaussianNB 사용)
예측값: [1] # 1: Play

**Page 490**
로드맵
◼ 나이브 베이지안 분류기
◼ 마르코프 모델

**Page 491**
감사의 말
(참고 자료 링크 생략)

**Page 492**
안드레이 안드레예비치 마르코프
1856-1922
안드레이 안드레예비치 마르코프는 확률 과정(stochastic processes)에 대한 연구로 가장 잘 알려진 러시아 수학자였음.
그의 연구의 주요 주제는 나중에 마르코프 체인과 마르코프 과정으로 알려지게 되었음.

**Page 493**
애플리케이션
◼ 음성 인식
◼ 맞춤법 검사
◼ 패턴 인식
◼ 유전자 서열 분석
◼ 주식 시장 분석
◼ …
◼ 구글의 페이지 랭크 알고리즘은 본질적으로 웹 그래프에 대한 마르코프 체인임.

**Page 494**
마르코프 확률(랜덤) 과정
◼ 확률 분포가 현재 상태에 의해서만 결정되는 랜덤 시퀀스.
◼ 관찰 가능한 상태 시퀀스(데이터에서 상태를 알 수 있음)는 마르코프 체인 모델로 이어짐.
◼ 관찰 불가능한 상태는 은닉 마르코프 모델(HMM)로 이어짐.

**Page 495**
마르코프 속성
시간 t+1에서의 시스템 상태는 오직 시간 t에서의 시스템 상태에만 의존함
(수식 및 그림 설명: 상태 전이)

**Page 496**
정상 과정 (Stationary Process)
확률은 t와 무관함
이것은 시스템이 상태 i에 있을 때, t가 무엇이든 상관없이 시스템이 다음에 상태 j로 이동할 확률이 pij임을 의미함

**Page 497**
마르코프 모델/체인
◼ 이산(유한) 시스템:
◼ N개의 구별되는 상태.
◼ 어떤 초기 상태(들)에서 시작함 (시간 t=1).
◼ 각 시간 단계(t=1, 2, …)에서 시스템은 현재 상태와 관련된 전이 확률에 따라 현재 상태에서 다음 상태로 이동함.
◼ 유한(또는 이산) 마르코프 모델이라고 함

**Page 498**
5개 상태를 가진 마르코프 모델 예시
◼ 각 aij는 상태 i에서 상태 j로 이동할 확률을 나타냄
◼ aij는 행렬 A = {aij}로 주어짐
◼ 주어진 상태 i에서 시작할 확률은 pi임.
벡터 p는 이러한 시작 확률을 나타냄.

**Page 499**
예시 1: 중심 편향 무작위 보행 (Center-Biased Random Walk)
◼ 선 위에서의 무작위 보행
◼ 각 단계에서 위치(x)는 +1(오른쪽으로) 또는 -1(왼쪽으로) 변경될 수 있으며, 확률은 다음과 같음
Pmove left = ½ + ½(x/(c+|x|))
Pmove right = 1 – Pmove left
여기서 c는 상수 > 0
◼ (예) c=1일 때, x = -2, -1, 0, +1, +2에서 왼쪽으로 이동할 확률은 각각 1/6, 1/4, 1/2, 3/4, 5/6임.

**Page 500**
예시 2: 나이브 일기 예보 (1/2)
• 오늘 비 옴 -> 내일 비 옴 prr = 0.4
• 오늘 비 옴 -> 내일 비 안 옴 prn = 0.6
• 오늘 비 안 옴 -> 내일 비 옴 pnr = 0.2
• 오늘 비 안 옴 -> 내일 비 안 옴 prr = 0.8

**Page 501**
나이브 일기 예보 (2/2)
전이 행렬 (확률 행렬)
(행렬 P)
참고: 각 행의 합은 1임
행렬의 행과 열이 모두 합하여 1이면, 이중 확률 행렬(doubly stochastic matrix)임

**Page 502**
시퀀스 확률 계산
◼ 마르코프 체인 속성에 의해, 상태 시퀀스의 확률은 다음 공식으로 찾을 수 있음:
(수식 생략)

**Page 503**
수업 중 연습문제
◼ 우리 예제에서 상태 시퀀스 {‘no rain’, ’no rain’, ’rain’, ’rain’}의 확률을 계산하시오.
P({‘no rain’, ’no rain’, ’rain’, rain’} ) = ?

**Page 504**
예시 3: 나이브 일기 예보
◼ 상태 --- 비:1, 흐림:2, 맑음:3
행렬 A
◼ 문제: 1일차(t=1) 날씨가 맑음(3)이라고 주어졌을 때, 아래 관찰에 대한 확률은 얼마인가.
0 = ( sunny, sunny, sunny, rain, rain, sunny, cloudy, sunny )
= ( 3, 3, 3, 1, 1, 3, 2, 3 )
day 1 2 3 4 5 6 7 8

**Page 505**
해결
(계산 과정 생략)
= 1.536 x 10^-4

**Page 506**
예시 4: 주식 시장 분석
◼ 강세(bull) 주간 다음에는 90% 확률로 또 다른 강세 주간이 오고, 7.5% 확률로 약세(bear) 주간이 오며, 나머지 2.5% 확률로 정체(stagnant, 즉 변화 없음) 주간이 옴.

**Page 507**
주식 시장: Bull(강세)과 Bear(약세)
(그림: 프랑크푸르트 증권거래소 앞 황소와 곰 동상)

**Page 508**
전이 행렬
{1 = bull, 2 = bear, 3 = stagnant} 일 때
(행렬 P)

**Page 509**
질문
◼ 시간 n에 시스템이 상태 2(bear)에 있다면, 3번의 시간 기간 후인 시간 n + 3에 확률 분포는 어떻게 되는가
(계산 과정 생략)
= [0.3575 0.56825 0.07425]

**Page 510**
은닉 마르코프 모델(Hidden Markov Models)도 있음

**Page 511**
은닉 마르코프 모델
◼ 이산 마르코프 모델은 상태 시퀀스를 실행하며 신호를 방출함.
◼ “신호 방출”은 단순히 “어떤 데이터를 보여줌”을 의미함
◼ 신호 시퀀스로부터 상태 시퀀스를 결정할 수 없다면, 그 모델을 은닉 마르코프 모델이라고 함.

**Page 512**
동기 부여 예제: 공과 항아리

**Page 513**
동기 부여 (1/2)
◼ 3개의 항아리 X1, X2, X3가 있음.
◼ 각 항아리에는 y1, y2, y3, y4로 라벨이 붙은 공들이 알려진 비율로 들어 있음.
◼ 항아리에서 공 하나를 무작위로 뽑음. 공은 관찰자에게 보여짐. 하지만 항아리는 숨겨져 있음.
◼ 이것이 반복됨.
◼ 그러면 관찰자는 뽑힌 공의 시퀀스를 보지만, 공이 어느 항아리에서 뽑혔는지는 모름.

**Page 514**
동기 부여 (2/2)
◼ 그러나 은닉 마르코프 모델을 사용하면 관찰자가 세 번째 공이 각 항아리에서 나왔을 가능성(likelihood)과 같은 정보를 계산할 수 있음.
◼ ** 이것은 기댓값 최대화(Expectation-Maximization) 알고리즘이 해결하도록 설계된 숨겨진 매개변수 문제와 유사함.

**Page 515**
정의
X — 상태
y — 가능한 관찰
a — 상태 전이 확률
b — 출력 확률

**Page 516**
날씨 추측 게임 (1/2)
◼ 매일 그날 한 일에 대해 이야기하는 두 친구 앨리스와 밥을 고려해 보자.
◼ 밥은 공원 산책, 쇼핑, 아파트 청소에만 관심이 있음.
◼ 무엇을 할지에 대한 선택은 전적으로 그날의 날씨에 의해 결정됨.
◼ 앨리스는 날씨에 대한 확실한 정보는 없지만 일반적인 경향은 알고 있음.
◼ 밥이 무엇을 했는지 말해주는 것을 바탕으로, 앨리스는 날씨가 어땠을지 추측하려고 함.

**Page 517**
날씨 추측 게임 (2/2)
(그림 설명: 날씨 상태(Rainy, Sunny)와 행동(Walk, Shop, Clean) 간의 관계 및 확률)

**Page 518**
추론 (Inferences)
◼ 관찰된 시퀀스의 확률
◼ 모델의 매개변수가 주어졌을 때, 특정 출력 시퀀스의 확률을 가장 좋은 방법으로 계산함
◼ 잠재 변수의 확률
◼ 모델의 매개변수와 관찰 시퀀스가 주어졌을 때, 하나 이상의 잠재 변수(은닉 상태)의 확률을 계산함

**Page 519**
학습 (Learning)
◼ 출력 시퀀스가 주어졌을 때, 최적의 상태 전이 및 방출 확률 집합을 찾음.
◼ 지역 최대 우도는 EM 알고리즘의 특수한 경우인 Baum-Welch 알고리즘을 사용하여 효율적으로 도출할 수 있음.
◼ Viterbi 알고리즘은 가장 가능성 높은 은닉 상태 시퀀스의 확률 추정치를 얻음.

**Page 520**
애플리케이션
◼ 계산 금융
◼ 음성 인식 (Siri 포함)
◼ 음성 합성
◼ 스캔 솔루션에서의 문서 분리
◼ 기계 번역
◼ 유전자 예측
◼ 필기 인식
◼ 바이오 서열 정렬
◼ 시계열 분석
◼ 그 외 다수 ...

**Page 521**
모듈 종료

**Page 522**
베이지안 네트워크

**Page 523**
감사의 말
(참고 자료 링크 생략)

**Page 524**
토마스 베이즈
◼ 토마스 베이즈 (1701–1761)
◼ 영국의 통계학자, 철학자이자 장로교 목사

**Page 525**
베이지안 네트워크
◼ 확률 변수 집합과 그들의 조건부 의존성을 방향성 비순환 그래프(DAG)를 통해 나타내는 통계적 모델의 한 유형임.
◼ 예를 들어, 베이지안 네트워크는 질병과 증상 사이의 확률적 관계를 나타낼 수 있음.
◼ 증상이 주어지면, 네트워크를 사용하여 다양한 질병의 존재 확률을 계산할 수 있음.

**Page 526**
예시
◼ 비는 스프링클러가 작동할지에 영향을 미치고, 비와 스프링클러 모두 잔디가 젖을지에 영향을 미침.
(그림: Rain -> Sprinkler, Rain -> Grass wet, Sprinkler -> Grass wet)

**Page 527**
베이지안 네트워크 (1/2)
◼ 베이지안 네트워크는 노드와 엣지의 방향성 비순환 그래프(DAG) 구조와 각 노드에 대한 조건부 확률 테이블 집합으로 구성됨.
◼ DAG 구조
◼ 노드는 확률 변수를 나타냄.
◼ 엣지는 조건부 의존성을 나타냄.
◼ 연결되지 않은 노드는 서로 조건부 독립인 변수를 나타냄.

**Page 528**
베이지안 네트워크 (2/2)
◼ 조건부 확률 테이블
◼ 각 노드는 확률 함수(테이블)와 연관되어 있으며, 이는 노드의 부모 변수에 대한 값 집합을 입력으로 받아 노드가 나타내는 변수의 확률(또는 확률 분포)을 출력으로 제공함.

**Page 529**
조건부 확률 테이블
◼ 베이지안 네트워크에는 조건부 확률 테이블 집합이 있음.
◼ 베이지안 네트워크의 각 노드 Xi는 부모가 노드에 미치는 영향을 정량화하는 조건부 확률 분포 P(Xi | Parents(Xi))를 가짐.
◼ 매개변수는 이러한 조건부 확률 테이블(CPT)의 확률임.
◼ 예를 들어, 부모 노드가 불리언 변수를 나타내는 경우, 확률 함수는 부모가 참 또는 거짓인 가능한 각 조합에 대해 하나의 항목을 갖는 테이블로 표현될 수 있음.

**Page 530**
일러스트레이션
(그림 및 표: 노드 A, B, C, D 간의 관계와 확률 테이블)

**Page 531**
예시: 비, 스프링클러, 젖은 잔디
◼ X = { C: 흐림, R: 비, S: 스프링클러, W: 젖은 잔디 }
(그림: C -> S, C -> R, S -> W, R -> W)

**Page 532**
예시 (계속)
(그림 및 표: 각 노드에 대한 조건부 확률 테이블)

**Page 533**
머신 러닝:
강화 학습 (Reinforcement Learning)
Ok-Ran Jeong
2025년 가을

**Page 534**
감사의 말
(참고 자료 링크 생략)

**Page 535**
강화 학습이란 무엇인가?
◼ 학습은 에이전트와 세계(환경) 간의 상호 작용의 결과로 발생함.
◼ 학습 배후의 아이디어:
◼ 에이전트가 받는 보상은 행동하는 데뿐만 아니라 목표를 달성하기 위해 미래에 최적으로 행동하는 에이전트의 능력을 향상시키는 데 사용되어야 함.
◼ 에이전트가 환경에 대해 행동할 때, 행동에 대한 평가(강화)를 받지만 목표를 달성하기 위해 어떤 행동이 올바른지는 듣지 못함.

**Page 536**
핵심 아이디어
(그림: 에이전트 <-> 환경 상호작용 루프. 상태 & 보상, 행동)

**Page 537**
애플리케이션
◼ 컴퓨터 클러스터의 자원 관리
◼ 신호등 제어
◼ 로봇 공학
◼ 웹 시스템 구성
◼ 화학
◼ 개인화된 추천
◼ 입찰 및 광고
◼ 게임 (알파고)
◼ 딥러닝

**Page 538**
강화 학습 예시
◼ 게임 플레이
◼ 플레이어는 이기거나 지는 것은 알지만 각 단계에서 다음 수를 알지 못함.
◼ 제어
◼ 교통 시스템은 차량 지연을 측정할 수 있지만 줄이는 방법은 모름.

**Page 539**
동기 부여 예제
◼ 문으로 연결된 건물의 5개 방
◼ 건물 밖은 하나의 큰 방(방 5)임
◼ 문 1과 4는 방 5에서 건물로 이어짐.
◼ 에이전트를 아무 방에나 두고, 그 방에서 건물 밖으로 나가게 하고 싶음.

**Page 540**
동기 부여 예제:
그래프 표현
◼ 각 문은 양방향임
◼ 에이전트는 다른 방에서 들어올 수 있고, 다른 방으로 나갈 수 있음.
◼ 방 5가 우리의 목표(goal) 방이 될 것임.

**Page 541**
기본 용어: 상태(State)와 행동(Action)
◼ 상태 (State)
◼ 우리 예제의 각 방 (외부 포함)
◼ 그래프의 노드로 묘사됨
◼ 행동 (Action)
◼ 한 방에서 다른 방으로의 에이전트 이동
◼ 그래프의 방향성 링크로 묘사됨

**Page 542**
기본 용어: 보상 (Reward)
◼ 방 5를 목표 상태로 설정하기 위해, 각 문에 보상 값을 연관시킬 것임.
◼ 목표로 즉시 연결되는(직접 연결된) 문은 100의 보상을 가짐.
◼ 에이전트가 목표에 도착하면 영원히 그곳에 머물 것임.
◼ 목표에 직접 연결되지 않은 다른 문은 0의 보상을 가짐.

**Page 543**
문제 예시
◼ 에이전트가 방 2에 있고 건물을 빨리 대피해야 한다고 가정함.
◼ 에이전트는 한 방에서 다른 방으로 이동할 수 있지만 환경에 대한 지식이 없으며 어떤 문 시퀀스가 밖으로 이어지는지 모름.

**Page 544**
상태 다이어그램의 그래프 표현 (상태 및 행동)
(그림: 상태 간의 연결 및 보상 값 표시)

**Page 545**
보상 값이 있는 상태 다이어그램의 행렬 표현
◼ 참고: R (보상) 행렬의 “-1”은 null 값을 나타냄
◼ “노드 간에 링크가 없음”

**Page 546**
Q (품질) 행렬 (1/2)
◼ R 행렬의 동반 행렬
◼ Q 행렬은 에이전트가 경험을 통해 배운 기억을 나타냄.
◼ 행: 에이전트의 현재 상태를 나타냄
◼ 열: 다음 상태로 이어지는 가능한 행동(노드 간의 링크)을 나타냄

**Page 547**
Q (품질) 행렬 (2/2)
◼ Q 행렬은 0으로 초기화됨.
◼ Q 행렬에 대한 전이 규칙
◼ Q(state, action) =
R(state, action) +
Gamma * Max[Q(next state, all actions)]
◼ (의미) Q 행렬의 특정 요소에 할당된 값은 R 행렬의 해당 값과 (다음 상태에서의 모든 가능한 행동에 대한 Q의 최대값에 학습 매개변수 Gamma를 곱한 값)의 합과 같음.

**Page 548**
강화 학습 알고리즘
◼ Q-learning
◼ 몬테카를로 (Monte Carlo)
◼ SARSA (state-action-reward-state-action)
◼ DQN (deep Q network)
◼ ….

**Page 549**
Q-Learning
◼ 1989년 Christopher Watkins가 소개함.
◼ 에이전트(프로그램)는 목표에 도달할 때까지 상태에서 상태로 탐색함.
◼ 각 시작부터 끝까지의 탐색을 에피소드라고 함.
◼ 각 에피소드는 에이전트가 초기 상태에서 목표 상태로 이동하는 것으로 구성됨.
◼ 에이전트가 목표 상태에 도착하면 프로그램은 다음 에피소드로 이동함.

**Page 550**
Q-Learning
◼ 이 알고리즘은 에이전트가 경험으로부터 학습하는 데 사용됨.
◼ 각 에피소드는 하나의 훈련 세션과 같음. 각 훈련 세션에서.
◼ 에이전트는 환경(R 행렬로 표현됨)을 탐색하고,
◼ 목표 상태에 도달할 때까지 보상(있는 경우)을 받음.
◼ 훈련의 목적은 Q 행렬로 표현되는 에이전트의 '뇌'를 향상시키는 것임.
◼ 더 많은 훈련은 더 최적화된 Q 행렬을 낳음.
◼ Q 행렬이 향상되면, 여기저기 탐색하고 같은 방을 왔다 갔다 하는 대신, 에이전트는 목표 상태로 가는 가장 빠른 경로를 찾을 것임.

**Page 551**
의사 코드: 동적 프로그래밍 사용
◼ Gamma 매개변수와 R 행렬의 환경 보상을 설정함.
◼ Q 행렬을 0으로 초기화함.
◼ 각 에피소드에 대해
◼ 무작위 초기 상태 선택
◼ 목표 상태에 도달하지 않은 동안 반복
◼ 현재 상태에 대한 모든 가능한 행동 중 하나를 선택함.
◼ 이 가능한 행동을 사용하여 다음 상태로 가는 것을 고려함.
◼ 모든 가능한 행동을 기반으로 이 다음 상태에 대한 최대 Q 값을 얻음.
◼ 계산: Q(state, action) = R(state, action) + Gamma * Max[Q(next state, all actions)]
◼ 다음 상태를 현재 상태로 설정함.
◼ 반복 종료
◼ 반복 종료

**Page 552**
Gamma 매개변수
◼ Gamma는 가치 할인 요소임.
◼ Gamma 매개변수의 범위는 0에서 1 사이임 (0 <= Gamma < 1).
◼ Gamma가 0에 가까우면 에이전트는 즉각적인 보상만 고려하는 경향이 있음.
◼ Gamma가 1에 가까우면 에이전트는 미래의 보상을 더 큰 가중치로 고려하며 보상을 지연시킬 의향이 있음.

**Page 553**
Q 행렬 사용하기
◼ Q 행렬을 사용하기 위해, 에이전트는 단순히 초기 상태에서 목표 상태까지의 상태 시퀀스를 추적함.
◼ 알고리즘은 현재 상태에 대해 Q 행렬에 기록된 가장 높은 보상 값을 가진 행동을 찾음:
◼ Q 행렬 활용 알고리즘:
◼ 1. 현재 상태 = 초기 상태 설정.
◼ 2. 현재 상태에서 가장 높은 Q 값을 가진 행동을 찾음.
◼ 3. 현재 상태 = 다음 상태 설정.
◼ 4. 현재 상태 = 목표 상태가 될 때까지 2단계와 3단계를 반복함.

**Page 554**
워크스루 예제 (1/13)
◼ Gamma 매개변수 값을 0.8로 설정하고 초기 상태를 방 1로 설정함.
◼ Q 행렬 초기화

**Page 555**
워크스루 예제 (2/13)
◼ 예제 R 행렬의 두 번째 행(상태 1)을 보시오.
◼ 현재 상태 1에 대해 두 가지 가능한 행동이 있음.
◼ 상태 3으로 이동
◼ 상태 5로 이동 (이 행동을 무작위로 선택)

**Page 556**
워크스루 예제 (3/13)
◼ 에이전트가 상태 5에 있다면 어떤 일이 일어날지 상상해 보시오.
◼ 보상 행렬 R의 여섯 번째 행(상태 5)을 보시오.
◼ 3가지 가능한 행동이 있음
◼ 상태 1, 4 또는 5로 이동.
◼ Q 값을 계산함:
◼ Q(state, action) = R(state, action) + Gamma * Max[Q(next state, all actions)]
◼ Q(1, 5) = R(1, 5) + 0.8 * Max[Q(5, 1), Q(5, 4), Q(5, 5)] = 100 + 0.8 * 0 = 100
◼ Q 행렬이 여전히 0으로 초기화되어 있으므로 Q(5, 1), Q(5, 4), Q(5, 5)는 모두 0임.
◼ Q(1, 5)에 대한 이 계산 결과는 R(1, 5)의 즉각적인 보상 때문에 100임.

**Page 557**
워크스루 예제 (4/13)
◼ 다음 상태인 5가 이제 현재 상태가 됨.
◼ 5가 목표 상태이므로 하나의 에피소드를 마쳤음.
◼ Q (에이전트의 뇌)는 이제 다음과 같이 업데이트된 Q 행렬을 포함함:

**Page 558**
워크스루 예제 (5/13)
◼ 다음 에피소드를 위해 무작위로 선택된 초기 상태로 시작함.
◼ 이번에는 상태 3을 초기 상태로 함. R 행렬의 네 번째 행을 보시오.
◼ 3가지 가능한 행동이 있음: 상태 1, 2 또는 4로 이동.
◼ 무작위 선택으로 상태 1로 이동을 선택함.
◼ 이제 상태 1에 있다고 상상해 보시오. R 행렬의 두 번째 행(즉, 상태 1)을 보시오.
◼ 2가지 가능한 행동이 있음: 상태 3 또는 상태 5로 이동.
◼ Q 값을 계산함:
◼ Q(state, action) = R(state, action) + Gamma * Max[Q(next state, all actions)]
◼ Q(3, 1) = R(3, 1) + 0.8 * Max[Q(1, 3), Q(1, 5)] = 0 + 0.8 * Max(0, 100) = 80

**Page 559**
워크스루 예제 (6/13)
◼ 지난 에피소드에서 업데이트된 Q 행렬을 사용함.
◼ Q(1, 3) = 0이고 Q(1, 5) = 100임.
◼ 계산 결과는 Q(3, 1) = 80임. 보상이 0이기 때문임.
◼ Q 행렬은 다음과 같이 됨:

**Page 560**
워크스루 예제 (7/13)
◼ 다음 상태인 상태 1이 이제 현재 상태가 됨. 상태 1은 목표 상태가 아니므로 Q 학습 알고리즘의 내부 루프를 반복함.
◼ 따라서 현재 상태 1로 새 루프를 시작하면 두 가지 가능한 행동이 있음:
◼ 상태 3으로 이동하거나 상태 5로 이동. 상태 5가 무작위로 선택됨.

**Page 561**
워크스루 예제 (8/13)
◼ 이제 상태 5에 있다고 상상해 보시오. 세 가지 가능한 행동이 있음: 상태 1, 4 또는 5로 이동.
◼ 이 가능한 행동들의 최대값을 사용하여 Q 값을 계산함.
◼ Q(state, action) = R(state, action) + Gamma * Max[Q(next state, all actions)]
◼ Q(1, 5) = R(1, 5) + 0.8 * Max[Q(5, 1), Q(5, 4), Q(5, 5)] = 100 + 0.8 * 0 = 100
◼ Q 행렬의 업데이트된 항목 Q(5, 1), Q(5, 4), Q(5, 5)는 모두 0임.
◼ Q(1, 5)에 대한 이 계산 결과는 R(1, 5)의 즉각적인 보상 때문에 100임. 이 결과는 Q 행렬을 변경하지 않음.
◼ 5가 목표 상태이므로 이 에피소드를 마침.

**Page 562**
워크스루 예제 (9/13)
◼ 우리 에이전트의 뇌는 이제 업데이트된 Q 행렬을 포함함:

**Page 563**
워크스루 예제 (10/13)
◼ 에이전트가 추가 에피소드를 통해 더 많이 학습하면, 마침내 다음과 같이 Q 행렬의 수렴 값에 도달하게 됨:

**Page 564**
워크스루 예제 (11/13)
◼ 이 Q 행렬은 0이 아닌 모든 항목을 가장 높은 숫자(이 경우 500)로 나누어 정규화(즉, 백분율로 변환)할 수 있음:

**Page 565**
워크스루 예제 (12/13)
◼ Q 행렬이 수렴 상태에 충분히 가까워지면, 에이전트가 목표 상태로 가는 가장 최적의 경로를 학습했음을 알 수 있음.
◼ 최적의 상태 시퀀스를 추적하는 것은 각 상태에서 가장 높은 값을 가진 링크를 따라가는 것만큼 간단함.

**Page 566**
워크스루 예제 (13/13)
◼ 예를 들어, 초기 상태 2에서 에이전트는 Q 행렬을 가이드로 사용할 수 있음:
◼ 상태 2에서 최대 Q 값은 상태 3으로 가는 행동을 제안함.
◼ 상태 3에서 최대 Q 값은 두 가지 대안을 제안함: 상태 1 또는 4로 이동. 임의로 상태 1로 이동을 선택한다고 가정함.
◼ 상태 1에서 최대 Q 값은 상태 5로 가는 행동을 제안함.
◼ 따라서 시퀀스는 2 -> 3 -> 1 -> 5임.

**Page 567**
작업 유형 (1/2)
◼ 연속 작업 (Continuous tasks)
◼ 영원히 계속되는 작업
◼ (예) 자동화된 외환/주식 거래를 수행하는 RL 에이전트.
◼ 에이전트는 최선의 행동을 선택하는 방법을 배워야 하며 동시에 환경과 상호 작용함.
◼ 시작점과 종료 상태가 없음.

**Page 568**
작업 유형 (2/2)
◼ 에피소드 작업 (Episodic tasks)
◼ 시작점과 종료점(종료 상태라고 함)이 있음.
◼ 이것은 에피소드를 생성함: 상태(S), 행동(A), 보상(R)의 리스트.
◼ (예) 카운터 스트라이크 게임 플레이, 여기서 상대를 쏘거나 상대에게 죽임을 당함. 상대를 모두 쏘고 에피소드를 완료하거나 죽임을 당함. 따라서 에피소드를 완료하는 경우는 두 가지뿐임.

**Page 569**
활용(Exploitation)과 탐험(Exploration)
◼ 활용은 보상을 극대화하기 위해 이미 알려진 정보를 이용하는 것임.
◼ 탐험은 환경에 대한 더 많은 정보를 찾는 것에 관한 것임.

**Page 570**
탐험과 활용의 트레이드오프
◼ 예제 게임에서 로봇 쥐는 적당한 양의 작은 치즈(+0.5 각각)를 얻을 수 있음.
◼ 하지만 미로 꼭대기에는 큰 치즈 합계(+100)가 있음. 따라서 활용만 한다면(즉, 가장 가까운 보상에 집중한다면), 로봇 쥐는 결코 큰 치즈 합계에 도달하지 못할 것임.
◼ 하지만 로봇 쥐가 약간의 탐험을 한다면 큰 보상, 즉 큰 치즈를 찾을 수 있음.

**Page 571**
마르코프 결정 과정 모델
◼ MDP 모델 <S,T,A,R>
• S – 상태 집합
• A – 행동 집합
• T(s,a,s’) = P(s’|s,a) – 행동 a가 주어졌을 때 s에서 s’로 전이될 확률
• R(s,a) – 상태 s에서 행동 a를 취했을 때의 기대 보상

**Page 572**
MDP 모델 (2/2)
◼ 간단한 MDP 예시
◼ 3개의 상태(녹색 원)와 2개의 행동(주황색 원), 2개의 보상(주황색 화살표)

**Page 573**
모듈 종료
